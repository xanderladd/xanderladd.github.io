<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-09-27T06:14:41-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Alexander Ladd</title><subtitle>An amazing website.</subtitle><author><name>Alexander Ladd</name><email>zladd@berkeley.edu</email></author><entry><title type="html">Review 38: Inferring Latent Dynamics Underlying Neural Population Activity via Neural Differential Equations</title><link href="http://localhost:4000/reviews/review39/" rel="alternate" type="text/html" title="Review 38: Inferring Latent Dynamics Underlying Neural Population Activity via Neural Differential Equations" /><published>2022-09-24T05:17:13-07:00</published><updated>2022-09-24T05:17:13-07:00</updated><id>http://localhost:4000/reviews/review39</id><content type="html" xml:base="http://localhost:4000/reviews/review39/">&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v139/kim21h/kim21h.pdf&quot;&gt;Inferring Latent Dynamics Underlying Neural Population Activity via Neural Differential Equations&lt;/a&gt; by &lt;a href=&quot;https://timkimd.github.io/&quot;&gt;Timothy Doyeon Kim&lt;/a&gt; and &lt;a href=&quot;http://brodylab.org/&quot;&gt;Carlos D. Brody&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Kim, Timothy D., et al. “Inferring latent dynamics underlying neural population activity via neural differential equations.” International Conference on Machine Learning. PMLR, 2021.
 &lt;!-- -  &lt;img src=&quot;/assets/images/imagery5.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot;/&gt; --&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Notation : I don’t know how to use macro &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\bm&lt;/code&gt; instead of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\mathbf&lt;/code&gt; on this website so vector notation is going out of the window. That can be very confusing… but &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\mathbf&lt;/code&gt; is clunky.&lt;/li&gt;
  &lt;li&gt;Introduction
    &lt;ul&gt;
      &lt;li&gt;Introduces generic latent model of dynamical system of neuron activity.
  \(\dot{z_t} = f(z(t),u(t), t)\)
        &lt;ul&gt;
          &lt;li&gt;this doesn’t not make sense to me because where is $x(t)$, or the spiking activity at time $t$ and what is the difference between $\dot{z_t}$ and $z(t)$?&lt;/li&gt;
          &lt;li&gt;Actually, I think they mean that $\dot{z_t}$ is the subsequent measurement after reading a bit more context.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Gives spike time formulation in terms of Poisson process as in previous post (LFADS).&lt;/li&gt;
      &lt;li&gt;Drawbacks to LFADS
        &lt;ul&gt;
          &lt;li&gt;RNN is high dimensional making it mostly black box until you get factors.&lt;/li&gt;
          &lt;li&gt;requires many trials to train.&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;the initial state of the RNN and the external input stimuli completely determine the state trajectory.&lt;/strong&gt;
            &lt;ul&gt;
              &lt;li&gt;In reality, the same stimuli may not give rise to the same output … the brain is not deterministic.&lt;/li&gt;
              &lt;li&gt;Also different exogenous stimuli can give rise to the same output… not sure if these matter as much here.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;This paper introduces a low dimensional model that uses neural ODES (Chen et al. 2018) to model population dynamics.
        &lt;ul&gt;
          &lt;li&gt;This means we can find the fixed points using the jacobian of the diff. eqs. of this model like Sussillo 2013 (see review 36).&lt;/li&gt;
          &lt;li&gt;Outperforms LFADS in single trial tasks.&lt;/li&gt;
          &lt;li&gt;Latent trajectories are sampled then computed using ODE Solver so they are not deterministic.&lt;/li&gt;
          &lt;li&gt;Model gives phase portraits that can reconstruct flow field (is it flow field or curl field or vector field… IDK terminology here).&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Background
    &lt;ul&gt;
      &lt;li&gt;Poisson Linear Dynamical System (PLDS)
 \(\begin{aligned}
 &amp;amp;z_0 = \mathcal{N}(\mu_{z_0}, Q_0 ) \hspace{20pt} \tiny{\textit{sample initial latent state}} \\
 \eta_t \sim \mathcal{N}(0,Q_t) \tiny{\textit{sample noise?}} \\
 &amp;amp;z_t = Az_{t-1} + Bu_t + \eta_t \tiny{\textit{linear model for next latent state}} \\
 &amp;amp;\lambda_t = exp(C_k z_t + \eta_t) \tiny{\textit{find poisson rate}} \\
 &amp;amp;x_{t,n} = \text{poisson}(\delta t\lambda_{t,n}) \tiny{\textit{sample spike trains}}
 \end{aligned}\)
        &lt;ul&gt;
          &lt;li&gt;though they use $k$ to denote instantaneous measurements instead of $t$.&lt;/li&gt;
          &lt;li&gt;This is solved via EM… is guess on the latent distributions $Q_0$ and $Q_t$ and then on the linear regression weights $A$,$B$, and $C_k$.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;2.2 LFADS - latent factor analysis via dynamical systems. I’ll skip this background since it is covered thoroughly in review 38, (TODO: add links) the previous review.&lt;/li&gt;
      &lt;li&gt;Neural ODE
        &lt;ul&gt;
          &lt;li&gt;Instead of using feed-forward net to solve latent trajectory, one can use ordinary differential equations.&lt;/li&gt;
          &lt;li&gt;Instead of an explicit ODE solve method, (Chen 2018) proposes using adjoint states to approximate the gradient of the loss of the ODES (latent ODEs that is).&lt;/li&gt;
          &lt;li&gt;Adjoint state for latent traj: $a(t) = \frac{d\mathcal{L}}{dz(t)}$
            &lt;ul&gt;
              &lt;li&gt;Respective ODE $\frac{da(t)}{dt}= -a(t) \frac{\partial f_{\psi}(z(t),t)}{\partial z(t)}$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Adjoint state for approx. of loss $a_{\psi}(t) = \frac{d\mathcal{L}}{d{\psi}}$
            &lt;ul&gt;
              &lt;li&gt;Respective ODE $\frac{da_\psi(t)}{dt}= -a(t) \frac{\partial f_{\psi}(z(t),t)}{\partial \psi}$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;2.5. Pulsatile Evidence Accumulation in Perceptual Decision-Making
        &lt;ul&gt;
          &lt;li&gt;Rodent has clicks on the left and right side and is rewarded for choosing what side had the most clicks.&lt;/li&gt;
          &lt;li&gt;Model by 
  \(dz = \lambda z dt + \delta_R(C^R + \eta_R)dt +  \delta_l(C^L + \eta_L)dt + \sigma_z dW\)
            &lt;ul&gt;
              &lt;li&gt;where $\eta_L$ and $\eta_R$ $\sim \mathcal{N}(0,\sigma)$&lt;/li&gt;
              &lt;li&gt;and $C^L$ and $C^R$ represent update frequencies.&lt;/li&gt;
              &lt;li&gt;Do not understand $dW$ (how would there be deriv. w.r.t to W if there’s no W in the eq.??)&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;PLNDS
    &lt;ul&gt;
      &lt;li&gt;log-likelihood function ($p_{\Theta}(t_x \mid u)$) is the likelihood of spike times for N observed neurons and $u$ is the input.&lt;/li&gt;
      &lt;li&gt;parameters of the model are $\Theta = [\theta,\phi]$ where $\theta$ are ODE solver params and $\phi$ are variational params.&lt;/li&gt;
      &lt;li&gt;Then log-lik = 
  \(\begin{equation}
  \mathcal{L} = \mathbb{E}_{q}[p_{\theta}(t_x \mid u, z)] + KL(p_{\theta}(z \mid u, t_x) || q_{\phi}(z \mid t_x,  u)) 
  \end{equation}\)&lt;/li&gt;
      &lt;li&gt;And likelihood is reduced to 
  \(\begin{equation}
  \mathbb{E}_{q}[p_{\theta}(t_x \mid u, z)] = \mathbb{E}_{q}[p_{\theta}(t_x \mid \lambda)] = \sum_{n=1}^{N} \mathbb{E}_{q}[log(p_{\theta}(t_x^{(n)}))] \mid \lambda_n)] \\ 
  \text{  where  }
  \mathbb{E}_{q}[log(p_{\theta}(t_x^{(n)}))] = - \int_{\tau} \lambda_n t dt + \sum_{i=1}^{\alpha(n)} log \lambda_n t_{x,i}^{(n)} 
  \end{equation}\)
        &lt;ul&gt;
          &lt;li&gt;not quite sure how we get the final expansion of log likelihood for $p(\t_x \mid \lambda_t)$. I thought it would be like a binary crossentropy kinda thing but the integral over $\lambda_n$ is throwing me off.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Going to skip the part about computing adjoints and computing the KL Div. for adjoints… I imagine this derivation is from Chen 2018.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Experiments&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/images/PLNDS_fig_2.png&quot; alt=&quot;no alt&quot; width=&quot;1000&quot; height=&quot;1000&quot; align=&quot;left&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;PLNDS accurately reconstructs phase portrait spiral resulting from linear dynamical system of eq. similar to that of Brunton 2016.&lt;/li&gt;
      &lt;li&gt;Fixed points found using Newtons method and autodiff of FNN (fig 2A).&lt;/li&gt;
      &lt;li&gt;PLNDE outperformed LFADS and PLDS in firing rate reconstruction accuracy experiments where number of training trials and firing rates varied (fig 2B / 2C). This is demonstrated in $R^2$ on the right panel and reconstruction of latent trajectories on the left panel for 2B and 2C. The trend here shows a very high correlation for PLNDE with actual firing rate in the early trials for high activity. This drops off for low activity but eventually recovers after many trials. This is not the case for PLDS and LFADS.&lt;/li&gt;
      &lt;li&gt;Paper provides a method for finding the right number of latent dimensions using validation loss.&lt;/li&gt;
      &lt;li&gt;“We found that PLNDE can accurately infer the phase portrait of FitzHugh-Nagumo, capturing the limit cycle and the unstable fixed point. [and] 4.2), PLNDE can infer the phase portrait of the mutual inhibition dynamics, correctly identifying the two stable and one unstable fixed “&lt;/li&gt;
      &lt;li&gt;Next they fit PLNDE to various regions (prelimibic, secondary motor, pre-frontal) of a rat in a decision making task.&lt;/li&gt;
      &lt;li&gt;PLNDE confirms importance of decision making regions while also creating latent space phase portrait. That would be figure B below.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/images/PLNDS_fig4.png&quot; alt=&quot;no alt&quot; width=&quot;800&quot; height=&quot;1000&quot; align=&quot;left&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Discussion
    &lt;ul&gt;
      &lt;li&gt;PLNDE does not provide a measure of confidence in it’s estimate of the phase portrait. Thus a measure of caution should be used in the underlying assumptions about the stationarity of the system and the portrait being used to describe the system.&lt;/li&gt;
      &lt;li&gt;Model has less parameters than LFADS.&lt;/li&gt;
      &lt;li&gt;We may also consider amortizing posterior inference of our model by having, for example, an RNN encoder like (6), ODE-RNN encoder (Rubanova et al., 2019).&lt;/li&gt;
      &lt;li&gt;Final point about hyperparm optimization.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Inferring Latent Dynamics Underlying Neural Population Activity via Neural Differential Equations by Timothy Doyeon Kim and Carlos D. Brody</summary></entry><entry><title type="html">Review 37: Auto-Encoding Variational Bayes</title><link href="http://localhost:4000/reviews/review37/" rel="alternate" type="text/html" title="Review 37: Auto-Encoding Variational Bayes" /><published>2022-09-23T05:17:13-07:00</published><updated>2022-09-23T05:17:13-07:00</updated><id>http://localhost:4000/reviews/review37</id><content type="html" xml:base="http://localhost:4000/reviews/review37/">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1312.6114.pdf&quot;&gt;Auto-Encoding Variational Bayes&lt;/a&gt; by &lt;a href=&quot;http://dpkingma.com/&quot;&gt;Diederik P. Kingma&lt;/a&gt; and &lt;a href=&quot;https://staff.fnwi.uva.nl/m.welling/&quot;&gt;Max Welling&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Kingma, Diederik P., and Max Welling. “Auto-encoding variational bayes.” arXiv preprint arXiv:1312.6114 (2013).
 &lt;!-- -  &lt;img src=&quot;/assets/images/imagery5.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot;/&gt; --&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Notation : I don’t know how to use macro &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\bm&lt;/code&gt; instead of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\mathbf&lt;/code&gt; on this website so vector notation is going out of the window. That can be very confusing… but &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\mathbf&lt;/code&gt; is clunky.&lt;/li&gt;
  &lt;li&gt;Introduction
    &lt;ul&gt;
      &lt;li&gt;They show how a simple reparamterization of the variational lower bound yields a simple differntiable unbiased estimator of the lower bound in SGVB (stochastic gradient variational bayes).&lt;/li&gt;
      &lt;li&gt;The approximate posterior inference model can be used for representation, denoising, recgoniztion, visualization etc. and they call it Variational auto-encoder.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Methods
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;img src=&quot;/assets/images/kingma_fig_1.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;Problem setting
        &lt;ul&gt;
          &lt;li&gt;Consider dataset  $ X = { [x^{(i)}] }^N_{i=1} $ consisting of N iid samples of some contininous or discrete variable $x$.&lt;/li&gt;
          &lt;li&gt;Data is generated by some by some process represented by latent variable $z$ with prior $z \sim p_{\theta^*}(z)$ and likelihood $x \sim p_{\theta^*}(x \mid z)$. Where distribution $\theta^*$ and latent R.V. $z$ are unknown.&lt;/li&gt;
          &lt;li&gt;Paper does not make several assumptions resulting in a setting characterized by:
            &lt;ol&gt;
              &lt;li&gt;Intractability: Assume we cannot explictly compute the integral of the marginal likelihood $p_{\theta}(x)= \int p_{\theta}(x \mid z) p_{\theta}(z) dz$.&lt;/li&gt;
              &lt;li&gt;Dataset is too large to sample solutions to MAP using Monte Carlo EM.&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;So they propose a solution to 3 real world problems in this setting.
            &lt;ol&gt;
              &lt;li&gt;Efficient maximum likelihood (ML) of maximum a posteriori (MAP) of parameters of  $\theta$&lt;/li&gt;
              &lt;li&gt;Inference on latent variable $z$ given $x$ and estimated parameters of $\theta$.&lt;/li&gt;
              &lt;li&gt;Efficient approximate marginal inference of the variable $x$.&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;Introduce a “recognition model” or appromximation of the true posterior $p_{\theta}(z \mid x)$ as $q_{\theta}(z \mid x)$.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Variational Bound
        &lt;ul&gt;
          &lt;li&gt;The likelihood of a given sample is 
  \(log p_{\theta}(x^{(i)}) = KL(q_{\theta}(z \mid x^{(i}) || p_{\theta}(z \mid x^{(i)}) + \mathcal{L}(\theta, \phi ; x^{(i)})\) for $ i = 1 … N$ datapoints.&lt;/li&gt;
          &lt;li&gt;Then we can replace $ \mathcal{L}(\theta, \phi ; x^{(i)}) $ with \(\mathbb{E}_{ q^{\phi}(z \mid x) } [- log q_{ \theta }(z \mid x) + log p_{\theta}(z, x)]\)
            &lt;ul&gt;
              &lt;li&gt;How does this derivation work for the variational lower bound?&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Then the final equation we get for the variatonal lower bound is: 
 \begin{equation}
   log p_{\theta}(x^{(i)}) = KL(q_{\theta}(z \mid x^{(i}) || p_{\theta}(z \mid x^{(i)}) + \ \mathbb{E}_{q^{\phi}(z \mid x)}  [- log q_{ \theta }(z \mid x) + log p_{\theta}(z, x)]]
  \end{equation}&lt;/li&gt;
          &lt;li&gt;Gradient w.r.t. to $\phi$ the recognition model parameters is tricky to compute because you’d have to use naive monte carlo gradient estimator.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The SGVB estimator and the AEVB algorithm
        &lt;ul&gt;
          &lt;li&gt;This is the good part now. They reparameterize $\tilde{z} = q_{\phi}(z \mid x)$ using a differentiable equation $  g_{\phi}(\epsilon, x)$ ! where $\epsilon$ is a random noise variable. So:
  \(\tilde{z} = g_{\phi}(\epsilon, x) \ \text{with} \  \epsilon \sim P(\epsilon)\)&lt;/li&gt;
          &lt;li&gt;Then we can replace $q_{phi}(z \mid x)$ in equation 1 with function $g_{\phi}(\epsilon, x)$. Except now the monte carlo estimate of expectation is conditioned on $p(\epsilon)$ now, because that is the underlying distribution.&lt;/li&gt;
          &lt;li&gt;Now we using stochastic variational estimate: $\tilde{\mathcal{L}}^A(\theta, \phi ; x^{(i)}) $&lt;/li&gt;
          &lt;li&gt;Thus we finally get to the form of the Stochastic Gradient Variational Bayes (SGVB) estimator:
  \begin{equation}
  \tilde{\mathcal{L}}^A(\theta, \phi ; x^{(i)}) = \frac{1}{L} \sum_{l=1}^L log_{p_{\theta}} (x^{(i)}, z^{(i,l)}) - log_{p_{\theta}}(z^{(i,l)} \mid x^{(i)})
  \end{equation} where $z^{(i,l)} = g(\epsilon^{i,l},x^{(i)}) $ and $\epsilon^{l} \sim p(\epsilon)$ .&lt;/li&gt;
          &lt;li&gt;Then there is the regularized version of SGVB which uses KL divergence to ground the variational distribution $q_{\theta}$ with a prior distribution. This has the form:
  \begin{equation}
  \tilde{\mathcal{L}}^A(\theta, \phi ; x^{(i)}) =  KL(q_{\theta}(z \mid x^{(i}) || p_{\theta}(z \mid x^{(i)}) +  \ \frac{1}{L} \sum_{l=1}^L log_{p_{\theta}} (x^{(i)}, z^{(i,l)}) - log_{p_{\theta}}(z^{(i,l)} \mid x^{(i)})
  \end{equation}.&lt;/li&gt;
          &lt;li&gt;The next part of this paper describes how to do minibatch updates using an optimizer like SGD / ADAM because we can now take gradients w.r.t to $\theta$ and $\phi$.&lt;/li&gt;
          &lt;li&gt;In equation 3 the first term serves as a regularizer and the second term serves as a reconstruction loss as it produces a generative model of datapoint $x^{(i)}$ given $z^{(i,l)}$ .&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The reparameterization trick
        &lt;ul&gt;
          &lt;li&gt;If $z$ is a continuous r.v. sampled from $q_{\phi}$(z \mid x)$, then they express $z$ in terms of a deterministic variable $z = g(\epsilon, x)$ with an indpendent marginal $p(\phi)$.&lt;/li&gt;
          &lt;li&gt;Then they provide a proof for why monte carlo estimate of expectation is differentiable w.r.t. $\phi$.&lt;/li&gt;
          &lt;li&gt;But still, the trick is hard to understand intuitively since changing the parameters of $q_{\phi}$ doesn’t change the indpendent marginal $p(\epsilon)$ which is some noise.&lt;/li&gt;
          &lt;li&gt;On that note, the rest of this section goes on to describe the reasonable choices for  $p(\epsilon)$.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Variatonal AutoEncoder
        &lt;ul&gt;
          &lt;li&gt;Start by assuming variational approximate posterior is multivariate gaussian s.t.: $ log q_{\phi}( z \mid x^{(i)}) = \mathcal{N}(z; \mu^{(i)}, \sigma^{2(i)} I)$ where the mean and s.d. of the approximate posterior, $\mu^{(i)}$ and  $\sigma^{i}$ are outputs of the encoding MLP, i.e. nonlinear functions of datapoint $x^{(i)}$ and variatonal parameters $\phi$.&lt;/li&gt;
          &lt;li&gt;Then the resulting estimator is:
  \begin{equation}
  \mathcal{L}(\theta, \phi ; x^{(i)}) \simeq \frac{1}{2} \sum_{j=1}{J} ((log(\sigma_{j}^{(i)})^ 2) + (\mu_{j}^{(i)})^ 2) - (\sigma_{j}^{(i)})^ 2)) + \frac{1}{L} \sum_{l=1}^L p_{\theta}(x^{(i)} \mid z^{(i,l)})
  \end{equation}&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The relational works section is pretty interesting because it shows just how novel this method is. There does seem to have been some work, called wake-sleep, on recognition for latent variable model for an approximation of the true posterior, but certainly it did not involve gradient descent. Besides that, related work is auto-encoders.
   &lt;img src=&quot;/assets/images/kingma_fig_2.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Experiments.
        &lt;ul&gt;
          &lt;li&gt;MNIST
            &lt;ul&gt;
              &lt;li&gt;outperforms wake-sleep benchmark even with only 3 latent variables.&lt;/li&gt;
              &lt;li&gt;lower likelihood than Frey face.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Frey Face
            &lt;ul&gt;
              &lt;li&gt;outperforms wake-sleep benchmark even with only 3 latent variables.&lt;/li&gt;
              &lt;li&gt;much higher likelihood model&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Adding more latent variables never actually decreases evidence lower bound which is kinda crazy given they usee 200 latent variables.
            &lt;ul&gt;
              &lt;li&gt;Something that would be abosolutely impossible if using MCMC approximation.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Figure 3 shows an excellent result w.r.t. to scale. That is simply: using less latent variables they can use MCMC to approximate posterior but the effectiveness does not scale nearly as well with more training data. Showing scalability of the AEVB method is an excellent idea.
  &lt;img src=&quot;/assets/images/kingma_fig_3.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Future work
        &lt;blockquote&gt;
          &lt;p&gt;Kingma and Welling 2013&lt;/p&gt;
          &lt;blockquote&gt;
            &lt;p&gt;there are plenty of future directions: (i) learning hierarchical generative architectures with deep neural networks (e.g. convolutional networks) used for the encoders and decoders, trained jointly with AEVB; (ii) time-series models (i.e. dynamic Bayesian networks); (iii) application of SGVB to the global parameters; (iv) supervised models with latent variables, useful for learning complicated noise distributions.&lt;/p&gt;
          &lt;/blockquote&gt;
        &lt;/blockquote&gt;
        &lt;ul&gt;
          &lt;li&gt;We like (ii)!&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Auto-Encoding Variational Bayes by Diederik P. Kingma and Max Welling</summary></entry><entry><title type="html">Review 38: Latent Factor Analysis via Dynamical Systems (LFADS)</title><link href="http://localhost:4000/reviews/review38/" rel="alternate" type="text/html" title="Review 38: Latent Factor Analysis via Dynamical Systems (LFADS)" /><published>2022-09-23T05:17:13-07:00</published><updated>2022-09-23T05:17:13-07:00</updated><id>http://localhost:4000/reviews/review38</id><content type="html" xml:base="http://localhost:4000/reviews/review38/">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1608.06315.pdf&quot;&gt;LFADS - Latent Factor Analysis via Dynamical
Systems&lt;/a&gt; by &lt;a href=&quot;https://scholar.google.com/citations?user=ebBgMSkAAAAJ&amp;amp;hl=en&quot;&gt;David Sussillo&lt;/a&gt; and &lt;a href=&quot;https://bme.gatech.edu/bme/faculty/Chethan-Pandarinath&quot;&gt;Chethan Pandarinath&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Sussillo, David, et al. “Lfads-latent factor analysis via dynamical systems.” arXiv preprint arXiv:1608.06315 (2016).
 &lt;!-- -  &lt;img src=&quot;/assets/images/imagery5.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot;/&gt; --&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Notation : I don’t know how to use macro &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\bm&lt;/code&gt; instead of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\mathbf&lt;/code&gt; on this website so vector notation is going out of the window. That can be very confusing… but &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\mathbf&lt;/code&gt; is clunky.&lt;/li&gt;
  &lt;li&gt;Introduction
    &lt;ul&gt;
      &lt;li&gt;peri-stimulus time histogram (PTSH) as the common approach to analyzing high dimensional spike train data.&lt;/li&gt;
      &lt;li&gt;LFADS, or latent factor analysis via dynamical systems, takes a sequenetial perspective, as opposed to input -&amp;gt; feedforward -&amp;gt; output), but also models  external inputs.&lt;/li&gt;
      &lt;li&gt;Goal of inferring smooth dynamics of single trial from neural population data.&lt;/li&gt;
      &lt;li&gt;Also provides:
        &lt;ul&gt;
          &lt;li&gt;a set of low-rank latent factors&lt;/li&gt;
          &lt;li&gt;initial conditions&lt;/li&gt;
          &lt;li&gt;and infers inputs.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;“LFADS is designed to infer such inputs on the basis of the recorded data alone.”&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;LFADS Model
    &lt;ul&gt;
      &lt;li&gt;Uses a variational autoencoder (VAE) to model data $x$ and it’s relationship latent variables $z$ using prior $p(z)$ and conditional $p(x \mid z)$ . Naturally need to train approximation $q(z \mid x)$ of true posterior $p(z \mid x)$ using $\frac{p(x \mid z)p(z)}{p(x)}$.&lt;/li&gt;
      &lt;li&gt;$\hat{z}$ is a sample from $q$ which can be seen as an encoded version of data $x$ and the true posterior $p(x \mid x)$ can be seen as the decoder.
        &lt;ul&gt;
          &lt;li&gt;See previous review for more details on VAE and KL divergence as a method for normalization.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Notation:
        &lt;ul&gt;
          &lt;li&gt;$v = W(u)$ is an affine transformation from $u$ to $v$.&lt;/li&gt;
          &lt;li&gt;RNN update is $state_t = RNN(state_{t-1}, input_t)$.&lt;/li&gt;
          &lt;li&gt;Data is $x_{1:t}$ spike trains from D neurons and auxilliary set of observed variables $a_{1:t}$.&lt;/li&gt;
          &lt;li&gt;Assuming $x_{1:t}$  are sampled from Poisson process  with rates $r_{1:t}$. Latent factors are $f_{1:t}$.&lt;/li&gt;
          &lt;li&gt;Inferred input to network $u_{1:t}$
            &lt;ul&gt;
              &lt;li&gt;$ z = {g_0,u_{1:t}}$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;LFADS generator / decoder
        &lt;ul&gt;
          &lt;li&gt;rates are determined as $r_{1:t} = W^{\text{rate}}(exp(f_{1:t}))$.&lt;/li&gt;
          &lt;li&gt;start by sampling intitial state $\tilde{g_0}$ from prior $p(g_0)$ then:&lt;/li&gt;
        &lt;/ul&gt;

\[\begin{aligned} 
  \hat{u} \sim P(u) \hspace{20pt} \tiny{\textit{sample input}} \\ 
  &amp;amp;g_t = RNN^{gen}(g_{t-1}, \hat{u})  \hspace{20pt} \tiny{\textit{generate next hidden state}} \\ 
  &amp;amp;f_t = W^{fac}g_t \hspace{20pt} \tiny{\textit{affine transform to factors}} \\
  &amp;amp;r_t = exp(W^{rate}(f_t)) \hspace{20pt} \tiny{\textit{infer rate from factors}} \\
  &amp;amp;x_t \sim Poisson(x_t \mid r_t) \hspace{20pt} \tiny{\textit{sample spike outpts / decode}}
  \end{aligned}\]
      &lt;/li&gt;
      &lt;li&gt;LFADS encoder
        &lt;ul&gt;
          &lt;li&gt;both $g_0$ and $u_t$ are diagonal gaussians with mean and var.&lt;/li&gt;
          &lt;li&gt;$Q(g_{0} \mid x, a)$ with mean and var in terms of $E$:
  \(\begin{aligned}
  &amp;amp;\mu^{g_0} = W^{\mu_{g_0}}(E)
  &amp;amp;\sigma^{g_0} = exp(\frac{1}{2}W^{\sigma^{g_0}}(E))
  \end{aligned}\)
            &lt;ul&gt;
              &lt;li&gt;So far this is my weakest point of understanding: it seems like E is a forwards/backwards trajectory and that distribution Q is defined by an affine transformation to that state.
                &lt;ul&gt;
                  &lt;li&gt;This is where I think Neural ODE and Latent ODE have application since the affine transformation is not a principled way to from positions $E$ to distribution $q$.&lt;/li&gt;
                  &lt;li&gt;Same thing with the controller.&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;E $[e_1^{b}, e_{T}^{f}]$ is obtained through forward $e_{t}^{b}$ and backward $e_{t}^{f}$ RNN passes.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Then $u_t$ is defined in a similar way, (but also include a RNN controller?), and different trainable parameters. Thus giving $\tilde{E}_t$. Notice that it is no longer a pair of ending states of backward/forwards pass but a continuous trajectory over time $t$.
            &lt;ul&gt;
              &lt;li&gt;Previously we generated $g_0$ as an initial condition.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;$\tilde{E}_t$ and latent factor $f_t$ then pass through controller :
  \(c_t = RNN^{conn}(c_{t-1}, [\tilde{E}_t, f_{t-1}])\).&lt;/li&gt;
          &lt;li&gt;Finally inferred input $\hat{u}_t$ is drawn from a distribution parameterized by an affine transformation of the controller network state $c_t$ defined in the bullet above.
  \(\begin{aligned}
  &amp;amp;\hat{u}_t \sim Q(u_t \mid \mu_t^u, \sigma_t^u) \\
  &amp;amp;\mu_t^u = W^{\mu^u} c_t \\ 
  &amp;amp;\sigma_t^u = exp(\frac{1}{2} W^{\sigma^u} c_t)
   \end{aligned}\)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Ok now lets put the whole thing together in one set of eq.
   \(\begin{align}
  &amp;amp;c_t = RNN^{conn}(c_{t-1}, [ \tilde{E}_t,f_{t-1} ]) \hspace{20pt} \tiny{\textit{get controller state from RNN}} \\
  &amp;amp;\mu_t^u = W^{\mu^u} c_t  \hspace{20pt} \tiny{\textit{affine transformation to controller state for  } \mu_t^u}\\ 
  &amp;amp;\sigma_t^u = exp(\frac{1}{2} W^{\sigma^u} c_t) \hspace{20pt} \tiny{\textit{affine transformation to controller state for } \sigma_t^u} \\ 
  &amp;amp;\hat{u}_t \sim Q(u_t \mid \mu_t^u, \sigma_t^u) \hspace{20pt} \tiny{\textit{sample input}} \\
  &amp;amp;g_t = RNN^{gen}(g_{t-1}, \hat{u})  \hspace{20pt} \tiny{\textit{generate next hidden state}} \\ 
  &amp;amp;f_t = W^{fac}g_t \hspace{20pt} \tiny{\textit{affine transform to factors}} \\
  &amp;amp;r_t = exp(W^{rate}(f_t)) \hspace{20pt} \tiny{\textit{infer rate from factors}} \\
  &amp;amp;x_t \sim Poisson(x_t \mid r_t) \hspace{20pt} \tiny{\textit{sample spike outpts / decode}}
  \end{align}\)&lt;/li&gt;
      &lt;li&gt;technically this isn’t the whole thing, just the generative process since encoder isn’t parameterized here.&lt;/li&gt;
      &lt;li&gt;just figured out how to left align these equations on this website and it’s so satisfying. Previously they were center aligned.
 &lt;img src=&quot;/assets/images/LFADS_fig_2.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Loss function
    &lt;ul&gt;
      &lt;li&gt;$ log P(x_{1:T}) \geq \mathcal{L} = \mathcal{L}^x - \mathcal{L}^{kl} $&lt;/li&gt;
      &lt;li&gt;$\mathcal{L}^{kl} $ is two KL divergence terms.
        &lt;ul&gt;
          &lt;li&gt;one on the approximated posterior distribution of the inputs $u_t$ .&lt;/li&gt;
          &lt;li&gt;and one on the starting point state $g_0$ .&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;$\mathcal{L}^x = \sum_{t=1}^{T} log(\text{Poisson}(x_t \mid r_t)$.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Previous work
    &lt;ul&gt;
      &lt;li&gt;Kalman filters, VRAE (recurrent VAE).&lt;/li&gt;
      &lt;li&gt;Generalized Linear Model with Poisson Process.&lt;/li&gt;
      &lt;li&gt;Gaussian Process Factor Analysis.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Results
    &lt;ul&gt;
      &lt;li&gt;Experiments include:
        &lt;ul&gt;
          &lt;li&gt;Lorenz system
            &lt;ul&gt;
              &lt;li&gt;LFADS latents do the best in reconstruction of 3 dimensional state space $y_1,y_2, y_3$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Inferring dynamics of chaotic RNN&lt;/li&gt;
          &lt;li&gt;Inferring inputs of chaotic RNN
            &lt;ul&gt;
              &lt;li&gt;Trials with $\gamma$ controlling how chaotic activity is.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Next directions
    &lt;blockquote&gt;
      &lt;p&gt;Sussilo 2016&lt;/p&gt;
      &lt;blockquote&gt;
        &lt;p&gt;There are some obvious extensions and future directions to explore. First, an emissions model relevant to calcium imaging would be extremely useful for inferring neural firing rate dynamics underlying calcium signals. Second, in this contribution we implemented LFADS as a “smoother”, in Kalman filter language, that cannot run in real time. It would be interesting to adapt LFADS as a “filter” that could. Third, the LFADS generator could clearly be strengthed by stacking recurrent layers or adding a feed-forward deep net before the emissions distribution at each time step. Another extension would be to learn the dimensions of the inferred input and temporal factors automatically, instead of having them specified as predetermined hyper-parameters (e.g. nuclear norm minimization on the respective matrices). Finally, we can imagine an LFADS-type algorithm that leans more towards the feed-forward side of computation, but still has some recurrence. An application would be, for example, to explain short-term effects in visual processing. In this setting, the information transfer along the temporal dimension could be limited while expanding the information flow in the feed-forward direction.&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">LFADS - Latent Factor Analysis via Dynamical Systems by David Sussillo and Chethan Pandarinath</summary></entry><entry><title type="html">Review 36: Opening the Black Box: Low-Dimensional Dynamics in High-Dimensional Recurrent Neural Networks</title><link href="http://localhost:4000/reviews/review36/" rel="alternate" type="text/html" title="Review 36: Opening the Black Box: Low-Dimensional Dynamics in High-Dimensional Recurrent Neural Networks" /><published>2022-07-13T05:17:13-07:00</published><updated>2022-07-13T05:17:13-07:00</updated><id>http://localhost:4000/reviews/review36</id><content type="html" xml:base="http://localhost:4000/reviews/review36/">&lt;p&gt;&lt;a href=&quot;https://direct.mit.edu/neco/article-abstract/25/3/626/7854/Opening-the-Black-Box-Low-Dimensional-Dynamics-in&quot;&gt;Opening the Black Box: Low-Dimensional Dynamics
in High-Dimensional Recurrent Neural Networks&lt;/a&gt; by &lt;a href=&quot;https://scholar.google.com/citations?user=ebBgMSkAAAAJ&amp;amp;hl=en&quot;&gt;David Sussillo&lt;/a&gt; and &lt;a href=&quot;https://scholar.google.com/citations?user=6BrZ2isAAAAJ&amp;amp;hl=en&quot;&gt;Omri Barak&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Sussillo, David, and Omri Barak. “Opening the black box: low-dimensional dynamics in high-dimensional recurrent neural networks.” Neural computation 25.3 (2013): 626-649.
 &lt;!-- -  &lt;img src=&quot;/assets/images/imagery5.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot;/&gt; --&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Notation : I don’t know how to use macro &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\bm&lt;/code&gt; instead of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\mathbf&lt;/code&gt; on this website so vector notation is going out of the window. That can be very confusing… but &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\mathbf&lt;/code&gt; is clunky.&lt;/li&gt;
  &lt;li&gt;Introduction
    &lt;ul&gt;
      &lt;li&gt;View of RNN as a non-linear dynamical system (NLDS).&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Phase space&lt;/strong&gt;: Just a more specifc term than state space, instead of general description of all possible states, phase space defines a state as a set of coordinates.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Fixed points&lt;/strong&gt;: Coordinates in the phase space that exhibit zero motion. extends to &lt;strong&gt;Slow points&lt;/strong&gt;.
        &lt;ul&gt;
          &lt;li&gt;Stable or unstable (or attractor v. repeller), meaning system converges towards or away from these points.&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;mode&lt;/strong&gt;: independent pattern of activity that arises around fixed point when the linear system is diagonalized.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Hypothesis is that RNN == NLDS, but at slow points, linearization is valid. Paper provides principled approach to finding regions with slow points, then linearizes arround each slow point, and then relates interaction between regions.&lt;/li&gt;
      &lt;li&gt;Technique introduced allows id. of attractors, repellers, and saddle ponts.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Linear approximations
    &lt;ul&gt;
      &lt;li&gt;a system of diff. eqs.: $ \dot{x} = F(x) $ and trying to find points, $ x^{*} $ such that $ | F(x^{*}) \partial x | \geq F(x^{*}) $ and $ | F(x^{*}) \partial x | \geq  | \frac{1}{2}  \partial x  F’‘(x^{*}) \partial x | $.&lt;/li&gt;
      &lt;li&gt;The way I understand this is that perturbations induce a linear rate of change in the value of the system and the rate of change in the system.&lt;/li&gt;
      &lt;li&gt;Speed, or kinetic energy, of the system is : $ q(x) = \frac{1}{2}|F(x)|^2  $, which is useful because it is a scalar that can be optimized,  q = 0 only at fixed points, and gradient and hessian of q are amenable to finding minimum values that are not fixed points (so they are saddle points?).
        &lt;ul&gt;
          &lt;li&gt;don’t fully understand how the conditions for minimum are derived but moving on for now.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;2 - d example:
        &lt;ul&gt;
          &lt;li&gt;defined as dynamical system:
  \begin{equation}
  \dot{x_1} = (1 - x_1^2)x_2
  \end{equation}
  \begin{equation}
  \dot{x_2} = x_1 / 2 - x_2
  \end{equation}&lt;/li&gt;
          &lt;li&gt;The system has three fixed points: a saddle at (0, 0) and two attractors at (1, 1/2) and (−1, −1/2).&lt;/li&gt;
          &lt;li&gt;Here is the figure used to describe this dynamical system. I find it useful because it shows how differnt ICs (inital conditions) can converge to different fixed points and does a decent job of showing the difference between saddle and fixed point.
  &lt;img src=&quot;/assets/images/sussillo_2013_fig1.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;RNN formulation
        &lt;ul&gt;
          &lt;li&gt;$\mathbf{x}$ is the vector of activations and $\r(x_i)$ is the firing rate for neuron $i$
  \begin{equation}
  \dot{x_i} = -x_i \sum_{k}^N j_{ik}r_k + \sum_{k}{N} B_{ik}u_k
  r_i = h(x_i)
  \end{equation}&lt;/li&gt;
          &lt;li&gt;The recurrence of the network is defined by the matrix J, and the network receives the I-dimensional input u through the synaptic weight matrix B.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;3 bit flip flop
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;&lt;em&gt;TODO&lt;/em&gt;&lt;/strong&gt; I do not understand many things about the 3 bit task. So I just write open questions here instead.
            &lt;ul&gt;
              &lt;li&gt;Do the 3 units have a sequential relationship?&lt;/li&gt;
              &lt;li&gt;The input pulses are real valued? How are they thresholded?&lt;/li&gt;
              &lt;li&gt;In figure 2, are the inputs colored or the outputs? Seem like the outputs are colored, but it’s still hard to relate them.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Still, I need to give best description of the system so we’ll go ahead.&lt;/li&gt;
          &lt;li&gt;$2^3 = 8$ possible memories. Random impulses hit each bit and either confirm the sign (because it matched +1,-1) or flip sign from +1 to -1.&lt;/li&gt;
          &lt;li&gt;modeled with echostate RNN trained using FORCE (Sussillo &amp;amp; Abbot 2007) and trained using random init. weights and 600 different starting points (ICs). Fixed point finder resulted in 26 distinct fixed points and then they analyze these w/ linear stabiility anaylsis described above.&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;important&lt;/strong&gt; there are 8 attractors for every memory state.&lt;/li&gt;
          &lt;li&gt;&lt;img src=&quot;/assets/images/sussillo_2013_fig3.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;
            &lt;blockquote&gt;
              &lt;p&gt;Sussillo and Barak 2013&lt;/p&gt;
              &lt;blockquote&gt;
                &lt;p&gt;Figure 3: Low-dimensional phase space representation of 3-bit flip-flop task. (Left) The eight memory states are shown as black x. In blue are shown all 24 1-bit transitions between the eight memory states of the 3-bit flip-flop. The saddle fixed points with one unstable dimension are shown with green x. A thick red line denotes the dimension of instability of these saddle points. In thin red are the network trajectories started just off the unstable dimensions of the saddle points. These are heteroclinic orbits between the saddles that decide the boundaries and the attractor fixed points that represent the memories. Finally, the pink x show other fixed points, all with four unstable dimensions. Thick red lines show these dimensions of instability, and thin red lines show network trajectories started just off the fixed points in these unstable dimensions. (Right) Demonstration that a saddle point mediates the transitions between attractors. The input for a transition (circled region in left panel) was varied from 0 to 1, and the network dynamics are shown (blue for normal input pulse and cyan for the rest). As the input pulse increased in value, the network came ever closer to the saddle and then finally transitioned to the new attractor state.&lt;/p&gt;
              &lt;/blockquote&gt;
            &lt;/blockquote&gt;
          &lt;/li&gt;
          &lt;li&gt;System uses saddle points to mediate transition from one memory to another.&lt;/li&gt;
          &lt;li&gt;Though most transition from memory states are fairly straightforward, there are some unstable trajectories that appear to serve no purpose (pink fixed points).&lt;/li&gt;
          &lt;li&gt;Without explicit design of a network for a particular phase space, there can be redundant or multiple fixed points between two attractor states.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Sine wave generator
        &lt;ul&gt;
          &lt;li&gt;Network that produces a target sine wave for a given frequency from 1-51 frequency values.&lt;/li&gt;
          &lt;li&gt;linearized system had only two unstable dimensions.&lt;/li&gt;
          &lt;li&gt;Is it a surprising result that there is a fixed point corresponding to the 51 freq. values? Obviously we know some of them still result in regions of interest, but is the 1-1 correspondence implied by the task or not?
            &lt;ul&gt;
              &lt;li&gt;These regions are rigorously verified by norm of linear term agreeing with conditions (idk the eq. # above, but it’s the ones under “linear approximations” section).&lt;/li&gt;
              &lt;li&gt;So I guess that is not necessarily implied by the fixed point analysis.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Beyond fixed points
        &lt;ul&gt;
          &lt;li&gt;saddle points found by $q$ (“linear approximations” section) also provide insight system because linear term is dominating even if zero order of taylor expansion != 0. They term these points ghost points (or slow points) and state that even if they are not mediating transitions directly like fixed points, they are influencing the tracjectory of the system as shown below.
            &lt;ul&gt;
              &lt;li&gt;I thought zero-order term was linear? And first or second order might not = 0.&lt;/li&gt;
              &lt;li&gt;&lt;img src=&quot;/assets/images/sussillo_2013_fig5.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;paper includes some examples and formalizaiton of linear dynamics around this point.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Approximate plane attractor
        &lt;ul&gt;
          &lt;li&gt;This example further demonstrates the utility of finding saddle points using $q$. Because this is a summary I won’t explain the approximate plane attractor in too much detail.&lt;/li&gt;
          &lt;li&gt;The gist is that it is a 2 point moving average task which means two values need to be stored in memory.&lt;/li&gt;
          &lt;li&gt;100dim. RNN slow points ($q \leq 1e-4$) actually created a two dimensional manifold.&lt;/li&gt;
          &lt;li&gt;“Ablation study” so to speak done by replacing slow points with linear time-varying dynamical system (LTVDS) with very low mean squared error on transition states.&lt;/li&gt;
          &lt;li&gt;finally, they show the method is robust to perturbations in RNN and doesn’t rely on a finely tuned RNN.
            &lt;ul&gt;
              &lt;li&gt;This is important to show (something a reviewer might have asked for), but I will not cover it here.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Discussion
        &lt;ul&gt;
          &lt;li&gt;Open points for future work include
            &lt;ul&gt;
              &lt;li&gt;generalization to higher dimensional inputs and tasks.&lt;/li&gt;
              &lt;li&gt;May provide insight into observed experimental findings of low-dim. dynamics of experimental neuroscience.
                &lt;ul&gt;
                  &lt;li&gt;This is the one I am interested in!&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;Applying this technique to spiking models.
                &lt;ul&gt;
                  &lt;li&gt;Also this…&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Opening the Black Box: Low-Dimensional Dynamics in High-Dimensional Recurrent Neural Networks by David Sussillo and Omri Barak</summary></entry><entry><title type="html">Review 35: Cortical activity during motor execution, motor imagery, and imagery-based online feedback</title><link href="http://localhost:4000/reviews/review35/" rel="alternate" type="text/html" title="Review 35: Cortical activity during motor execution, motor imagery, and imagery-based online feedback" /><published>2022-07-13T05:17:13-07:00</published><updated>2022-07-13T05:17:13-07:00</updated><id>http://localhost:4000/reviews/review35</id><content type="html" xml:base="http://localhost:4000/reviews/review35/">&lt;p&gt;&lt;a href=&quot;&quot;&gt;Cortical activity during motor execution, motor imagery, and imagery-based online feedback&lt;/a&gt; by &lt;a href=&quot;https://www.mayoclinic.org/biographies/miller-kai-j-m-d-ph-d/bio-20456021&quot;&gt;Kai Miller&lt;/a&gt; and &lt;a href=&quot;https://www.rajeshpnrao.com/&quot;&gt;Rajesh P.N. Rao&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Miller, Kai J., et al. “Cortical activity during motor execution, motor imagery, and imagery-based online feedback.” Proceedings of the National Academy of Sciences 107.9 (2010): 4430-4435.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Hey Neuromatch friends!! Since we are using this dataset I thought I’d take out two birds with one stone and review it on my website too. Let’s get started.&lt;/li&gt;
  &lt;li&gt;Introduction
    &lt;ul&gt;
      &lt;li&gt;Many of the same areas involved in motor skill execution are involved in planning.
        &lt;ul&gt;
          &lt;li&gt;medial supplemental motor area&lt;/li&gt;
          &lt;li&gt;premotor cortex&lt;/li&gt;
          &lt;li&gt;dorsolateral prefrontal cortex (LFPC)&lt;/li&gt;
          &lt;li&gt;posterior parietal cortex (PPC)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Previous papers show motor function is revealed in high frequency band (HFB) of ECoG (electrocorticography) cortical surface potential of power spectral density (PSD).
        &lt;ul&gt;
          &lt;li&gt;Independent dynamics of fingers can be resolved at 20ms time scale in single electrodes by using changes in PSD.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;$\alpha$ and $\beta$ rythms spatially overlap &lt;em&gt;in LFPC&lt;/em&gt; between overt movement and imagery but also overlap for different movement types as well. On the other hand, high frequency component did overlap between overt / imagery but did not overlap for movement types.
        &lt;ul&gt;
          &lt;li&gt;Thus there are shared representations for movement and imagery at the population level.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Results
    &lt;ul&gt;
      &lt;li&gt;Low freq. band (LFB) decreases during movement and HFB increases.&lt;/li&gt;
      &lt;li&gt;&lt;img src=&quot;/assets/images/imagery1.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Figure 1
        &lt;ul&gt;
          &lt;li&gt;A: PSD for hand movement movement (red) v.s. rest (blue). Left is during movement and right is during imagery. Notice the gap between PSD in for HFB and LFB is tighter for imagery.
            &lt;ul&gt;
              &lt;li&gt;Caveat: PSDs are for primary motor electrode (see paper to find where this is, it’s also circled in B).&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;B: Electrode positions. Blue = hand, pink = tongue.&lt;/li&gt;
          &lt;li&gt;C: normalized HFB activation maps.&lt;/li&gt;
          &lt;li&gt;D same as C but LFB.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;img src=&quot;/assets/images/imagery2.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Figure 2
        &lt;ul&gt;
          &lt;li&gt;A: Geometric mean of PSD of electrodes during imagery v.s. movement.&lt;/li&gt;
          &lt;li&gt;B:  For subjects 2–5, the overlap is quantified between hand and tongue movement (yel- low), hand movement and imagery (light blue), and tongue movement and imagery (light pink). ø, significance, P &amp;gt; 0.01 (by reshuffling).&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;38 electrodes selected to quantify activity using signifigance. 21 elec. for tongue and 17 for hand. Relative change in PSD for imagery (to movement) in HFB was 25% and relative change in PSD for LFB was 46%.&lt;/li&gt;
      &lt;li&gt;Spatial overlap in HFB and LFB was signifcant for imagery v.s. movement but not movement v.s. movement.&lt;/li&gt;
      &lt;li&gt;Fairly high rates of using motor imagery to control a cursor. Magnitude of HFB increases as patients move cursor.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Discussion
    &lt;ul&gt;
      &lt;li&gt;α/β desynchronization captured by LFB reflects an aspect of cortical processing that is fundamentally nonspecific. It may represent feedback between cortical and subcortical structures.&lt;/li&gt;
      &lt;li&gt;Recent findings suggest PSD amp. changes are corr. with neuronal firing rate. Thus suggest 25% change in imagery means population is either a) firing 4x more during movement or b) 4x more active neurons during movement. Or some combination of both.&lt;/li&gt;
      &lt;li&gt;&lt;img src=&quot;/assets/images/imagery5.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Cortical activity during motor execution, motor imagery, and imagery-based online feedback by Kai Miller and Rajesh P.N. Rao</summary></entry><entry><title type="html">Review 34: The Role of Population Structure in Computations Through Neural Dynamics</title><link href="http://localhost:4000/reviews/review34/" rel="alternate" type="text/html" title="Review 34: The Role of Population Structure in Computations Through Neural Dynamics" /><published>2022-07-10T05:17:13-07:00</published><updated>2022-07-10T05:17:13-07:00</updated><id>http://localhost:4000/reviews/review34</id><content type="html" xml:base="http://localhost:4000/reviews/review34/">&lt;p&gt;&lt;a href=&quot;&quot;&gt;The Role of Population Structure in Computations Through Neural Dynamics&lt;/a&gt; by &lt;a href=&quot;&quot;&gt;Alexis Dubreuil&lt;/a&gt; &lt;a href=&quot;&quot;&gt;Adrian Valente&lt;/a&gt; and &lt;a href=&quot;&quot;&gt;Srdjan Ostojic&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;todo-citation-needed&quot;&gt;TODO CITATION NEEDED&lt;/h2&gt;
&lt;h2 id=&quot;todo-j-a-gallego-m-g-perich-l-e-miller-and-s-a-solla-neural-manifolds-for-the-control-of-movement-neuron&quot;&gt;TODO: J. A. Gallego, M. G. Perich, L. E. Miller, and S. A. Solla. Neural manifolds for the control of movement. Neuron,&lt;/h2&gt;
&lt;h2 id=&quot;todo-l-duncker-l-driscoll-k-v-shenoy-m-sahani-and-d-sussillo-organizing-recurrent-network-dynamics-by-task-computation-to-enable-continual-learning-advances-in-neural-information-processing-systems-33-2020&quot;&gt;TODO L. Duncker, L. Driscoll, K. V. Shenoy, M. Sahani, and D. Sussillo. Organizing recurrent network dynamics by task-computation to enable continual learning. Advances in Neural Information Processing Systems, 33, 2020.&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;This is a longer paper than I noramlly read, so I will need to read less content or else I will be reading forever. I usually read at least 75% of the sentences in a paper but for this one I will scale back to 50%. As a consolation, I’ll focus a bit more on the figures and the overall message.&lt;/li&gt;
  &lt;li&gt;Introduction
    &lt;ul&gt;
      &lt;li&gt;Two antagonistic approaches are represented: 1. functional populations by cell categorization and 2. low dimensional trajectories of population dynamics. 1. is challenged by the fact that function and neuron subtype are seemingly random at higher level cortical areas. 2. Is fairly new, but can be well understood through Vyas et al. 2020 computation throud dynamics framework (see review ? TODO: figure out what review).&lt;/li&gt;
      &lt;li&gt;Two studies [Hirokawa et al., 2019] and [Raposo et al., 2014] study posterior parietal cortex (PPC) and try to look for statistically verifiable measures of population activity and come to opposite conclusions about whether activity is entirely multiplexed or if there is some non-random population structure in selective responses.&lt;/li&gt;
      &lt;li&gt;To reconcile, this study trains recurrent neural networks (RNNs) on a range of systems neuroscience tasks and finds that random population structure can accomplish most tasks but some tasks required non-random sub-population structure in terms of connectivity (study also looks for structure in selectivity).&lt;/li&gt;
      &lt;li&gt;They focus on a class of low-rank models that have latent dynamics understood through a minimal intrinsic dimension and number of sub-populations.
        &lt;ul&gt;
          &lt;li&gt;I have no clue what this means. I get the part about a minimal dimension and subpopulations but I have no idea what a low-rank model is. I think it is probably something I am familiar mathemtically with but the terminology is being mixed around here and thus entirely lost on me.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Results
    &lt;ul&gt;
      &lt;li&gt;RNNs trained on 5 systems neuroscience task:
        &lt;ul&gt;
          &lt;li&gt;perceptual decision making (DM)&lt;/li&gt;
          &lt;li&gt;working memory (WM)&lt;/li&gt;
          &lt;li&gt;multi-sensory decision making (MDM)&lt;/li&gt;
          &lt;li&gt;contextual decision making (CDM)&lt;/li&gt;
          &lt;li&gt;delay match to sample (DMS)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Each task has 100 RNNs trained with different random initializations.&lt;/li&gt;
      &lt;li&gt;Rough description of mathemtical network:
  \(\gamma \frac{dx_i}{dt} = -x_i + \sum^N_{j=1}J_{i,j}\phi(x_j) + \sum^{N_{in} }_{s=1}I_i^{ (s) } u_s(t) + \eta_i(t)\)
        &lt;ul&gt;
          &lt;li&gt;component 1: sum of nonlinearity activation units ($\phi(x_j) $) times recurrent netowrk connectivity matrices over all neurons $J_{i,j}$.&lt;/li&gt;
          &lt;li&gt;component 2: Sum of feedforward weights  $I_i^{(s)}$ times inputs $u_s(t)$ plus some noise $\eta_i(t)$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Selectivity structure
        &lt;ul&gt;
          &lt;li&gt;selectivity space defined by 2-4 dimensional where each axis was given by the linear regression coefficient $\Beta^{v}_{i}$ of neural firing rate with respect to a task variable v such as stimulus, decision or context. Gaussian isotropic distribution in this space reprsents random population selectivity (v. non-random mixed selectivity).&lt;/li&gt;
          &lt;li&gt;2/5 tasks show non-random mixed selectivity.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Population structure
        &lt;ul&gt;
          &lt;li&gt;Low rank structure means high dim. neural connectivity matrix projected onto smaller subspace using a few parameters. Thien they use the same bonferroni corrected ePAIRS  (defined in STAR methods but also by Hirokawa and Raposo studies TODO: make this a footnote) signfigance test against isotropic Gaussian.
            &lt;ul&gt;
              &lt;li&gt;Now we know that our “low-rank” models are just projections of connectivity matrices $J_{i,j}$. Specifically they are models of rank R (decomposition of $J_{i,j}$ by sequence of vector products $m_{i}^{ {1) }n_{j}^{ {1) } + … m_{i}^{ (R) }n_{j}^{(R)}$. There are aso $N_{in}$ inputs. This leads to each neuron connectivity being parameterized by 2R + $N_{in}$ + 1. 1 readout weight and 2R because there are $m$ and $n$ terms in $J_{i,j}$.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;CDM and DMS taks show networks converging to have structure in terms of both selectivity and connectivity. But this is just correlational evidence. Love to see the authors push for causal evidence using resampling strategy.
        &lt;ul&gt;
          &lt;li&gt;They resample using mvn Gaussian matching low rank RNN to get new connectivity weights and see if performance on input / output task becomes scrambled due to scrambling potential population structure. Indeed CDM and DMS outputs are scrambled.
  -&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">The Role of Population Structure in Computations Through Neural Dynamics by Alexis Dubreuil Adrian Valente and Srdjan Ostojic</summary></entry><entry><title type="html">Review 33: High-density Single-unit Human Cortical Recordings Using the Neuropixels Probe</title><link href="http://localhost:4000/reviews/review33/" rel="alternate" type="text/html" title="Review 33: High-density Single-unit Human Cortical Recordings Using the Neuropixels Probe" /><published>2022-07-10T05:16:13-07:00</published><updated>2022-07-10T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review33</id><content type="html" xml:base="http://localhost:4000/reviews/review33/">&lt;p&gt;&lt;a href=&quot;&quot;&gt;High-density Single-unit Human Cortical Recordings Using the Neuropixels Probe&lt;/a&gt; by &lt;a href=&quot;&quot;&gt;Jason Chung&lt;/a&gt; and &lt;a href=&quot;&quot;&gt;Edward F. Chang&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;todo-citation-needed&quot;&gt;TODO CITATION NEEDED&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;I’ve reviewed the Neuropixels and Neuropixels 2.0 probes recently but this review is interesting because it translates the capacity of the Neuropixels probe to record from thousands of neurons in animal models to hundreds of neurons in humans undergoing neurosurgical procedures.&lt;/li&gt;
  &lt;li&gt;Highlights
    &lt;ul&gt;
      &lt;li&gt;8 human patients&lt;/li&gt;
      &lt;li&gt;596 putative neuron units&lt;/li&gt;
      &lt;li&gt;First spike takes longer in anesthesized subjects&lt;/li&gt;
      &lt;li&gt;Motion of electrode array inversely correlated with yield&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Introduction
    &lt;ul&gt;
      &lt;li&gt;Microelectrode array recordings (MEA) have many use cases during neursurgical procedures for identifying cell types and structure in the basal ganglia and thalamus, however, these small targets means that probe movement of even 1-2mm can cause potential issues.&lt;/li&gt;
      &lt;li&gt;The number of neurons that can be recorded from simultaneously is a severe limtation.
        &lt;ul&gt;
          &lt;li&gt;Sharp metal MEA records 1 neuron at a time.&lt;/li&gt;
          &lt;li&gt;Microwire can yield up to 3 neurons but normally 1-2.&lt;/li&gt;
          &lt;li&gt;Utah arrays have 96 channels but take awhile to calibrate and cannot sample across cortical depth.
            &lt;ul&gt;
              &lt;li&gt;I wonder how many electrodes utah arrays can record from?&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Recent advances in microfabrication have revealed much about the spatial and temporal scales of neural circuit activity but “[ inability of ] translation of methods for recording fundamental computational units [ such as ] single neurons and ensembles ha led to an increasing gap between what can be learned in animal models and how these detailed principles apply to the human brain,”.
        &lt;ul&gt;
          &lt;li&gt;I paraphrase here because I don’t quite understand how these methods can record from a circuit but not neurons/ensembles of neurons.&lt;/li&gt;
          &lt;li&gt;Also, it is not naturally clear to me how this issue affects translation of insights between animal and human brains.&lt;/li&gt;
          &lt;li&gt;TODO: investigate&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Looking at table 1:
        &lt;ul&gt;
          &lt;li&gt;I think it’s surprising that 4 probes broke but I don’t know if it’s surprisingly high or surpsignly low. I think it is probably low when we consider the fact that device bio-compatiblity with the brain must be very difficult to accomplish. I’d be curious to know the key factors that break these devices.&lt;/li&gt;
          &lt;li&gt;Also, I had no idea that most patients were actually awake for these procedures!&lt;/li&gt;
          &lt;li&gt;NP11 and NP06 are interested since probe is inserted into motor cortex.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;It looks like they are using Neurpixels 1.0, but see Review 23 (*TODO: add link) to see how CMOS tech + multichannel recording and high density MEA enable lightweight recording from 1000s of electrodes.&lt;/li&gt;
      &lt;li&gt;960 12 x 12 $\mu$m contacts, 384 channels, 10 mm shanks. (*TODO add picture)&lt;/li&gt;
      &lt;li&gt;
        &lt;ul&gt;
          &lt;li&gt;TODO: check out twin study by Paulk&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Final pargraph just formally recaps the info from the highlights section in the body of the paper. However, they do add some interesting extra info on the extensiblity of impalnting in different regions and feasiblity for use during craniotomy.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Results
    &lt;ul&gt;
      &lt;li&gt;First pargraph details the insertion procedure. I found this part interestnig:
        &lt;blockquote&gt;
          &lt;p&gt;(Chung 2022)&lt;/p&gt;
          &lt;blockquote&gt;
            &lt;p&gt;The insertion locations were at the center of a gyrus, away from surface vasculature, that was going to be resected in the same surgical procedure (Figure 1B).&lt;/p&gt;
          &lt;/blockquote&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;My best geuss is that there is an insertion tract lesion of .25 mm in width and about 3mm long.&lt;/li&gt;
      &lt;li&gt;In figure 1D the light yellow dots are very hard to see. A different color scheme or dot labeling scheme would have worked better.&lt;/li&gt;
      &lt;li&gt;They were able to improve functionality by:
        &lt;ul&gt;
          &lt;li&gt;reducing noise from AC to get better SNR ratio.&lt;/li&gt;
          &lt;li&gt;Increasing reducing positive end expiratory pressure patients to help reduce amplitude of brain pulsations.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Spiking increases for the first several minutes of insertion.&lt;/li&gt;
      &lt;li&gt;75% of all units of device were active at 2mins in.&lt;/li&gt;
      &lt;li&gt;11 recordsings with length 10-23 mins and 596 units identified in total with $54 +/- 24 SD$.&lt;/li&gt;
      &lt;li&gt;Figure 2 looks nice. It shows rasters, recordings snippets, time to first spike CDF and # of units against recording length.
        &lt;ul&gt;
          &lt;li&gt;The  # of units against recording length is not super positively correlated which maybe shows a limit to how variable population activity is over time. If those regions do not fire in 10 minutes, they are likely not going to fire for awhile. I wonder if they’d fire after 2hours? Gonna be hard pressed to get an answer to that one though.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;ul&gt;
          &lt;li&gt;TODO what are cluster metrics in STAR.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The authors discuss stabilization as a major limitation of recording technique and discuss using a stabilization algorithm in kilosort that uses spike foot[rint across a few channels to correct for motion.&lt;/li&gt;
      &lt;li&gt;They quantify motion by using higher freq. and amplitude units as spatial markers to discover 251 +- 112 $\mu$m or movement.&lt;/li&gt;
      &lt;li&gt;Cell Pair Coordination index (TODO: what is this) increases with cross-correleogram pairs under 50ms compared to those CCH pairs over 50ms.&lt;/li&gt;
      &lt;li&gt;Figure 3: noise increases (SNR decreases) with amplitude of signal ($\mu$V) and the ISI 1ms violations increase. Histogram truncation is minimal when spike amplitude is around 200 $\muV$, making a U shaped curve.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Discussion
    &lt;ul&gt;
      &lt;li&gt;Elimating all AC current devices attached to patient was important for reducing SNR.&lt;/li&gt;
      &lt;li&gt;First comparison between animal and human neurpixels due to clustering and other metrics reported.&lt;/li&gt;
      &lt;li&gt;I’m glad they bring up that neurpixels 2.0 actually has a motion stabilization algorithm. Really shows the alignment of objectives between Steinmetz et al. and applicaiton of Neurpixels.&lt;/li&gt;
      &lt;li&gt;Timeline of recording advances:
        &lt;ul&gt;
          &lt;li&gt;Earliest single unit recordings (Ward and Thomas 1955)&lt;/li&gt;
          &lt;li&gt;90 units over 17 patients (Wyler 1982)&lt;/li&gt;
          &lt;li&gt;Utah aray enables BCI-control of a cursor (Hochberg et al. 2006) and robotic limb (Alfalo 2015)&lt;/li&gt;
          &lt;li&gt;Longitudal recording of up to 1500 days (Hughes et al. 2021) and noted immune response + structural reorganization.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Advice on ethical considerations
        &lt;ul&gt;
          &lt;li&gt;TODO: note and cite Chiong et al. (2018) and Feinsinger et al. (2022) f&lt;/li&gt;
          &lt;li&gt;Clinical care and safety should never be comprimised for research.&lt;/li&gt;
          &lt;li&gt;Team includes treating physicians and non treating researchers.&lt;/li&gt;
          &lt;li&gt;Assesment for appropriateness and ability to participate in the study.&lt;/li&gt;
          &lt;li&gt;Continous monitoring and consent for patient participation in the study.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;blockquote&gt;
      &lt;p&gt;Chung 2022&lt;/p&gt;
      &lt;blockquote&gt;
        &lt;p&gt;The major advance demonstrated here is recording in human brain with densely spaced high channel count simultaneously acquired across the cortical thickness.&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/blockquote&gt;

    &lt;ul&gt;
      &lt;li&gt;Challenges / Lessons Learned:
        &lt;ul&gt;
          &lt;li&gt;Minimize patient movement&lt;/li&gt;
          &lt;li&gt;Turn off non-essential electrical device to minmize noise&lt;/li&gt;
          &lt;li&gt;Remove AC devices on the patient&lt;/li&gt;
          &lt;li&gt;The positive airflow intutabation thing&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Really points to motion correction for future work.&lt;/li&gt;
      &lt;li&gt;Suggests longer recordings.&lt;/li&gt;
      &lt;li&gt;Warns against shank breaking in deeper structures and then needing to retrieve (with forceps?).&lt;/li&gt;
      &lt;li&gt;Neuropixels does not allow stimulation.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">High-density Single-unit Human Cortical Recordings Using the Neuropixels Probe by Jason Chung and Edward F. Chang</summary></entry><entry><title type="html">Review 32: Living Science: Maintaining the Joy of Discovery</title><link href="http://localhost:4000/reviews/review32/" rel="alternate" type="text/html" title="Review 32: Living Science: Maintaining the Joy of Discovery" /><published>2022-07-08T05:16:13-07:00</published><updated>2022-07-08T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review32</id><content type="html" xml:base="http://localhost:4000/reviews/review32/">&lt;p&gt;&lt;a href=&quot;https://elifesciences.org/articles/80711&quot;&gt;Living Science: Maintaining the Joy of Discovery&lt;/a&gt; by &lt;a href=&quot;https://www.brandeis.edu/biology/faculty/marder-eve.html&quot;&gt;Eve Marder&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Marder, Eve. “Living Science: Maintaining the joy of discovery.” Elife 11 (2022): e80711.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;DISCLAIMER: these are my reading notes, not my personal opinion&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Marder 2022&lt;/p&gt;
  &lt;blockquote&gt;
    &lt;p&gt;Changes in science over the past 50 years have reduced the chances of trainees experiencing the joy of discovery.&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Writing starts out with using “you get out what you put in” as the hook but then cites increasing authorship, price, time, and complexity behind important breakthroughs as the reason young scientists may not be able to engage with science the same way she did.&lt;/li&gt;
  &lt;li&gt;The longer turnaround time for analysis and having others analyze your data can damper the joy of discovery.&lt;/li&gt;
  &lt;li&gt;Suggests doing data analysis contemporaneously with generating data.&lt;/li&gt;
  &lt;li&gt;Massive amount of literature available and differing SEO policies on gScholar make orienting oneself if the literature challenging.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Marder 2022&lt;/p&gt;
  &lt;blockquote&gt;
    &lt;p&gt;Oftentimes, I finally understood the potential significance of a piece of work while writing the paper.&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Large-scale collaboration can separate the student from the actual piece of work. Doesn’t always work this way.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Takeaways
    &lt;ul&gt;
      &lt;li&gt;You get out what you put in.&lt;/li&gt;
      &lt;li&gt;gScholar SEO biases search results. Needs to be a better way of orienting oneself in the field.&lt;/li&gt;
      &lt;li&gt;Read / write more.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;My opinion:
    &lt;ul&gt;
      &lt;li&gt;I picked this writing up after I saw &lt;a href=&quot;https://twitter.com/drugmonkeyblog/status/1544559316140584961&quot;&gt;this tweet&lt;/a&gt; calling it a “handwringer”.&lt;/li&gt;
      &lt;li&gt;Upon reflection, I don’t find anything here that concerning.&lt;/li&gt;
      &lt;li&gt;Firstly, I don’t agree with the premise that there isn’t as much low-hanging fruit as there used to be. The low-hanging fruit isn’t the same anymore in terms of conducting very basic science and running a simple and quick analysis of the data; it has changed. With the advent of repositories of open data sets and open-source statistical tools / other tools for data analysis, the low-hanging fruit has just shifted to an entirely different format.
        &lt;ul&gt;
          &lt;li&gt;This is mildly concerning for young researchers who hate stats and don’t have any coding experience but at the end of the day, the reason these methods are prominent is that they provide the most efficient interface with science. Undoubtedly, there is an aspect of gatekeeping here. But what other alternative is there? Removing the systems that perpetuate this is atavistic.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Secondly, the point about contemporaneous analysis is a really good one. I just don’t see why analysis should ever take days or weeks to turn around, that’s just ineffective design.
        &lt;ul&gt;
          &lt;li&gt;I realized this &lt;em&gt;very&lt;/em&gt; recently but IMO you should never find yourself just sitting around waiting for analysis to complete.&lt;/li&gt;
          &lt;li&gt;In my own experience, every time I am sitting around waiting for the analysis to complete there is always a simpler way to break either the data or the analysis into parts and analyze each component very quickly. I argue that learning to break complex analyses into small chunks that can be turned around and verified quickly is an essential skill. It also makes this point a non-factor if you are good enough at it.&lt;/li&gt;
          &lt;li&gt;I’ve yet to see a single analysis not amenable to this treatment in some way.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Third, the point about SEO optimization and the pitfalls of modern literature search is &lt;strong&gt;absolutely valid&lt;/strong&gt;. But mitigating this is just not that hard. There are a million ways to do so:
        &lt;ul&gt;
          &lt;li&gt;Collaborative annotated citations&lt;/li&gt;
          &lt;li&gt;Keyword hacking on gScholar&lt;/li&gt;
          &lt;li&gt;Follow citation trails&lt;/li&gt;
          &lt;li&gt;Follow author trails&lt;/li&gt;
          &lt;li&gt;Articles with over 1k citations are categorically prominent works in the field&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;However, on the point about not feeling like an expert because of the overwhelming amount of papers available: this is the big fish small pond problem. When there are only a few journals you &lt;em&gt;feel&lt;/em&gt; like an expert and you &lt;em&gt;feel&lt;/em&gt; like you are engaging with your field but the actual engagement is much less than you perceive. On the other hand, in the new age, you never feel like an expert but you are much more informed than you feel. If you can’t enjoy science without feeling like an expert by dwarfing the literature available then you bite your nose to spite your face. The information hose (the internet) is just going to keep blasting and it is empirically a good thing. New experts just understand how to distill the deluge of papers, like &lt;a href=&quot;https://arxiv-sanity-lite.com/&quot;&gt;arxiv sanity&lt;/a&gt; or online journal clubs.&lt;/li&gt;
      &lt;li&gt;Finally I wholeheartedly agree with the point about appreciating the impact of the work through writing and I think that oppurtunity is now more accessible than ever!
        &lt;ul&gt;
          &lt;li&gt;Writing small articles for arxiv&lt;/li&gt;
          &lt;li&gt;Writing blog posts (like this!)&lt;/li&gt;
          &lt;li&gt;Tweetprints&lt;/li&gt;
          &lt;li&gt;Posting your work on your website&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;So in conclusion:
        &lt;ul&gt;
          &lt;li&gt;I feel that finding the joy in science isn’t &lt;em&gt;harder&lt;/em&gt; per say it’s just different.&lt;/li&gt;
          &lt;li&gt;But the lead message of this paper is still poignant: &lt;strong&gt;you get out what you put in&lt;/strong&gt;.
            &lt;ul&gt;
              &lt;li&gt;If you let the deluge of papers stop you from reading then you are worse off.&lt;/li&gt;
              &lt;li&gt;If you let the big project you are working on prevent you from releasing your own conference workshop paper for example then yes you are being restricted from writing.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;It’s not easy because in my opinion there are some worse pitfalls for young scientists but they are broader concerns for young professionals in general.&lt;/li&gt;
          &lt;li&gt;But I believe that research has not become overall less or more fulfilling. The opportunity is always just a few small steps away. We just need to get out of our own way first.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Living Science: Maintaining the Joy of Discovery by Eve Marder</summary></entry><entry><title type="html">Review 31: Noninvasive Brain–Machine Interfaces for Robotic Devices</title><link href="http://localhost:4000/reviews/review31/" rel="alternate" type="text/html" title="Review 31: Noninvasive Brain–Machine Interfaces for Robotic Devices" /><published>2022-06-11T05:16:13-07:00</published><updated>2022-06-11T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review31</id><content type="html" xml:base="http://localhost:4000/reviews/review31/">&lt;p&gt;&lt;a href=&quot;https://spectrum.ieee.org/brain-implant&quot;&gt;Noninvasive Brain–Machine Interfaces for Robotic Devices&lt;/a&gt; by &lt;a href=&quot;https://scholar.google.com/citations?user=U2N9FlcAAAAJ&amp;amp;hl=en&quot;&gt;Luca Toning&lt;/a&gt; and &lt;a href=&quot;https://www.ece.utexas.edu/people/faculty/jose-del-r-millan&quot;&gt;José del R. Millán&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Tonin, Luca, and José del R. Millán. “Noninvasive brain–machine interfaces for robotic devices.” Annual Review of Control, Robotics, and Autonomous Systems 4 (2021): 191-214.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;First this from the abstract: “. We found that BMIs are used mostly to drive devices for navigation (e.g., telepresence mobile robots), with BMI paradigms based mainly on exogenous stimulation, and the majority of brain-actuated robots adopt a discrete control strategy,”.&lt;/li&gt;
  &lt;li&gt;Introduction
    &lt;ul&gt;
      &lt;li&gt;Main focus of brain-machine interfaces, or BMIs, is to restore motor functions for those with damaged pathways or motor dysfunction.
eg; brain-controlled cursor movement, keyboards + typing, remote-controlled devices.&lt;/li&gt;
      &lt;li&gt;Not just a plug and play engineering problem, we should think about how to generate effective control signals as well.&lt;/li&gt;
      &lt;li&gt;Paper roadmap: introduce closed-loop system -&amp;gt; turn to main modalities of interaction/control -&amp;gt; provide an overview of 86 works over the past 15 years -&amp;gt; lay out challenges and future directions.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The Closed Loop of a Brain-Machine Interface: A Mutual Learning Interaction
    &lt;ul&gt;
      &lt;li&gt;Here is a high level description of Fig 1.
        &lt;ul&gt;
          &lt;li&gt;Brain activity is elicited and recorded.
            &lt;ul&gt;
              &lt;li&gt;Endogenous: user voluntarily engages activity in some mental task.&lt;/li&gt;
              &lt;li&gt;Exogenous: user is presented stimuli and correlates of brain activity are measured during this task.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Features are extracted.&lt;/li&gt;
          &lt;li&gt;Control.
            &lt;ul&gt;
              &lt;li&gt;This block in the flow is complicated. Suffice it to say that this part is a signal handed to a robotic device.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Online feedback.
            &lt;ul&gt;
              &lt;li&gt;User &lt;em&gt;sees&lt;/em&gt; behavior and deems it rewarding / not rewarding.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Rinse and Repeat.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Two key considerations for this loop to work:
        &lt;blockquote&gt;
          &lt;p&gt;Toning 2021&lt;/p&gt;
          &lt;blockquote&gt;
            &lt;p&gt;Two concepts therefore become essential in the design of the BMI closed loop: a fast response by the robot to the user’s intention, in order to allow fine and reactive control over the device (Section 4), and a bidirectional interaction between the robot and BMI, in order to trigger and exploit the robot intelligence and thus support the user in performing complex actions (Section 5).&lt;/p&gt;
          &lt;/blockquote&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;Ultimately this seems like communication bandwidth between the human/animal (affector) and the controlled device (effector).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Invasive and Noninvasive Acquisition Techniques
    &lt;ul&gt;
      &lt;li&gt;Noninvasive BMIs can access either electrocorticogram signals (EEG) or hemodynamic activity (bloodflow) like seen in fMRIs.
        &lt;ul&gt;
          &lt;li&gt;EEG has an advantage temporally but fMRI has an advantage spatially.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Signal Processing and Feature Extraction
    &lt;ul&gt;
      &lt;li&gt;Lots of filtering happens in non-invasive BCI so that we can increase signal to noise ratio.
        &lt;ul&gt;
          &lt;li&gt;Filter DC component.&lt;/li&gt;
          &lt;li&gt;Spatial filters.&lt;/li&gt;
          &lt;li&gt;Low dimensional reductions of data.&lt;/li&gt;
          &lt;li&gt;Hilbert transform, FFT transform, wavelet decomposition.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Feature Selection and Classification Algorithms
    &lt;ul&gt;
      &lt;li&gt;16 channels with 4-48hz resolution result in 340+ features to potentially consider.&lt;/li&gt;
      &lt;li&gt;During calibration channels that are discriminative or particularly relevant to functional neural correlates are selected in feature selection.&lt;/li&gt;
      &lt;li&gt;After online/control phase, the decoder is then used for offline discriminant classification.
        &lt;ul&gt;
          &lt;li&gt;SVM, Gaussian +/ kernel models.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Human-In-The-Loop: Interaction Modalities in Brain-Machine Interfaces
    &lt;ul&gt;
      &lt;li&gt;Exogenous paradigms
        &lt;ul&gt;
          &lt;li&gt;Steady-state evoked potential (SSEP) based BMIs: present several visual stimuli to target (like a flashing light) and the user can guide control by fixing their eyes on a specific target, which corresponds to an action in a remote-controlled robotic device.&lt;/li&gt;
          &lt;li&gt;P300 signals are evoked after some anomalistic pattern is observed. It’s hard to see how users picking out infrequent patterns or letters can lead to goal-directed control of a robotic arm. I’d have to look into the Farwell–Donchin spellers task.&lt;/li&gt;
          &lt;li&gt;Error-related signals can be used to increase robustness for BMI applications.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Endogenous Paradigms
        &lt;ul&gt;
          &lt;li&gt;Event-related localized changes in frequency, or an increment or decrement in EEG.
            &lt;ul&gt;
              &lt;li&gt;$\mu$ and $\beta$ bands of activity specifically related to motor imagination.&lt;/li&gt;
              &lt;li&gt;Event-related synchronization or desynchronization.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Task-specific modulation is represented as a marker on a screen, which is important because the capacity for the user to receive continuous feedback about cursor position.&lt;/li&gt;
          &lt;li&gt;Figure 2 quick jot.
            &lt;ul&gt;
              &lt;li&gt;Surprisingly, relative fisher scores for features were very stable over different frequencies.&lt;/li&gt;
              &lt;li&gt;Also 12hz ($\mu$ band) was particularly identifiable.&lt;/li&gt;
              &lt;li&gt;Quadratic boundary used for foot movement v.s. hand movement discrimination.
                &lt;ul&gt;
                  &lt;li&gt;This is also surprising as the feature representation is projected to a $\mathbb{R}^2$ subspace which is very compact. Yet a basic quadratic discrimator works!&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;Signal trajectory needs to converge past boundary to be classified. In one trajectory, neither hand nor foot is detected.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Control strategies
    &lt;ul&gt;
      &lt;li&gt;BMI control is often combined with a corresponding control strategy from the stimulated device.&lt;/li&gt;
      &lt;li&gt;While most systems use discrete control in continuous v.s. discrete control, there is the potential for both.
        &lt;ul&gt;
          &lt;li&gt;Discrete is slower and has lower bandwidth.&lt;/li&gt;
          &lt;li&gt;Continuous control is interesting but not as studied.
            &lt;ul&gt;
              &lt;li&gt;One of the interesting apps is as a continuous driving signal. The other app is the stabilization of discrete commands.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;EEG patterns are non-stationary.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Robot in the Loop: Sharing the Intelligence
    &lt;ul&gt;
      &lt;li&gt;Since many tasks (eg; robotic arm) reaching with non-invasive (and invasive?) BMI is pretty difficult, the devices are often equipped with (or learn) fine level control and stabilization.&lt;/li&gt;
      &lt;li&gt;Two approaches to machine autonomous control: 1. user looks at a spot and the machine takes responsibility for guiding it there using whatever control sequences it pleases or 2. user can offer more granular directions, like turning a wheelchair using a finite state machine (Iturrate et al. (52) qtd. in Toning 2021).
        &lt;ul&gt;
          &lt;li&gt;I am looking forward to hearing what the challenges for 2 are where. There seems to be a bottleneck in terms of how much bandwidth there is for control, just like in the case of continuous decoding.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Sequential control passed between human and robotic arm during grasping task. Human uses menu-based assistance to guide arm and then uses BMI to complete grasping action.&lt;/li&gt;
      &lt;li&gt;Shared control ultimately seems like a nice future direction since humans can have higher-level control and robot can have lower-level control.&lt;/li&gt;
      &lt;li&gt;Subversion of explicit BMI signaling using detection of error-related signals in BMI.
        &lt;ul&gt;
          &lt;li&gt;An error-based override allows the robot to re-interpret the signal.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Current Applications
    &lt;ul&gt;
      &lt;li&gt;Devices, Interaction Modalities, and Control Strategies
        &lt;ul&gt;
          &lt;li&gt;Here the authors give a nice breakdown of mobile control studies: “ brain-controlled mobile robots for telepresence are the type that is most common in the literature (Figure 4a), representing 38.4% of the reviewed studies, followed by powered wheelchairs (22.1%), robotic arms (19.8%), lower limb and upper limb exoskeletons (9.3% and 7.0%, respectively), and quadcopters (3.5%).” (Toning 2021).&lt;/li&gt;
          &lt;li&gt;See figure:
   &lt;img src=&quot;/assets/images/tonin1.png&quot; alt=&quot;bmi overview&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/li&gt;
          &lt;li&gt;Brain-controlled robotic arms are studied in several different studies.&lt;/li&gt;
          &lt;li&gt;Surprisingly only 16.3% of studies included participants that had motor defecits.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Open Challenges and Future Directions
    &lt;ul&gt;
      &lt;li&gt;Integration between BMI and robots is in early days. Normally, the robot is just seen as an actuator.&lt;/li&gt;
      &lt;li&gt;Overcoming commitment to exogenous systems and developing endogenous and self-paced systems has more deploy-ability but comes with challenges for calibration and user mental capacity to focus on this kind of control.&lt;/li&gt;
      &lt;li&gt;The biggest challenge is that most studies are not conducted in coordination with the end-users.
        &lt;ul&gt;
          &lt;li&gt;Which biases the design of the device and calibration/training strategies.&lt;/li&gt;
          &lt;li&gt;A lot of the time, training phases can take weeks.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Applications in navigation and manipulation may not be the most prioritized use case for the end-user. It would be best to coordinate with patients whom BMI researchers aim to help in order to re-contextualize what their priorities are in order to get better alignment.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Noninvasive Brain–Machine Interfaces for Robotic Devices by Luca Toning and José del R. Millán</summary></entry><entry><title type="html">Review 30: Eavesdropping on the Brain With 10,000 Electrodes</title><link href="http://localhost:4000/reviews/review30/" rel="alternate" type="text/html" title="Review 30: Eavesdropping on the Brain With 10,000 Electrodes" /><published>2022-06-05T05:16:13-07:00</published><updated>2022-06-05T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review30</id><content type="html" xml:base="http://localhost:4000/reviews/review30/">&lt;p&gt;&lt;a href=&quot;https://spectrum.ieee.org/brain-implant&quot;&gt;Eavesdropping on the Brain With 10,000 Electrodes&lt;/a&gt; by &lt;a href=&quot;https://www.imecitf.com/2021/health/speakers/barun-dutta-chief-scientist-sts-imec&quot;&gt;Barun Dutta&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Dutta, Barun. “Eavesdropping on the Brain With 10,000 Electrodes.” IEEE Spectrum (2022)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;This is interesting because this article is released by Barun Dutta, one of the principal investigators of the neuropixels devices.&lt;/li&gt;
  &lt;li&gt;The hook begins with the infamous brain-computer metaphor.
    &lt;ul&gt;
      &lt;li&gt;This “brain is a computer” comparison is tired, but this hook works well anyway because it points to the really astounding fact that the brain only requires 20 watts of power.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The introduction sets the stage for introducing &lt;a href=&quot;https://www.imec-int.com/en&quot;&gt;Imec&lt;/a&gt; importance of large-scale recordings of individual neurons and a freely moving animal. This company does some really awesome things with nano and digital technologies.&lt;/li&gt;
  &lt;li&gt;The name “neuropixels” is explained as a field potential recording system that relies on signal processing, kind of like a camera.&lt;/li&gt;
  &lt;li&gt;We also see that neuropixels aims to tackle some of the issues located physically deeper in the brain.&lt;/li&gt;
  &lt;li&gt;Neuropixels 1.0 has a single shank and 1000 electrodes.&lt;/li&gt;
  &lt;li&gt;Neuropixels 2.0 has four shanks with 1280 electrodes.&lt;/li&gt;
  &lt;li&gt;With 3.0 they claim they are moving along an exponential growth curve for BCI recording.&lt;/li&gt;
  &lt;li&gt;It is encouraging to see Imec’s efforts in materials sciences in CMOS fabrication.
    &lt;ul&gt;
      &lt;li&gt;low impedance electro-ceramic shanks sound more durable and much less likely to have electrical discharge.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;I find this quote surprising:
    &lt;blockquote&gt;
      &lt;p&gt;Dutta (2022)&lt;/p&gt;
      &lt;blockquote&gt;
        &lt;p&gt;“the thousandfold difference in elasticity between CMOS shanks and brain tissue”&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/blockquote&gt;

    &lt;ul&gt;
      &lt;li&gt;because I had no idea that even the most flexible shanks are still this level of magnitude more rigid than brain tissue. This  highlights the importance of these efforts in materials sciences and electrical engineering.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;2D readouts help power stabilization algorithm that allows the long-term tracking of specific neurons.&lt;/li&gt;
  &lt;li&gt;The new neuropixels device also features a smaller head-stage.&lt;/li&gt;
  &lt;li&gt;30 kilohertz sampling rate is very high. I wonder if anyone makes the argument that a higher sampling rate could ever be needed. I think at this resolution one could even analyze fast activating channel dynamics.&lt;/li&gt;
  &lt;li&gt;The “pixel” or neuron recording count is predicted to leap 50,000 - 100,000 neurons.
    &lt;ul&gt;
      &lt;li&gt;Big if true.&lt;/li&gt;
      &lt;li&gt;Neuropixels 1 has 1000 recording sites and then Neuropixels 2 has 6000 recording sites, so a projection of 50k is bold.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Overall, the pace of development is astounding but in my opinion “Moore’s law” is a mischaracterization. Here’s why:
    &lt;ul&gt;
      &lt;li&gt;So far we’ve observed one cycle and there was a 6x increase in recording sites, which is technically in line with the trend. However, this characterization of exponential growth would need to be sustained over multiple cycles… I think it is just too early to call.&lt;/li&gt;
      &lt;li&gt;Also, 1.0 and 2.0 don’t have that much of a difference in recording fidelity. 2.0 gets the increase in recording sites using more shanks and better tracking algorithms.&lt;/li&gt;
      &lt;li&gt;While the advent of these areas of development is notable, I wonder if we see sustained progress in these domains or if new features can be added that will enable increasing recording sites in other ways.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Eavesdropping on the Brain With 10,000 Electrodes by Barun Dutta</summary></entry></feed>