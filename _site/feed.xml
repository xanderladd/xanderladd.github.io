<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-09-18T16:11:42-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Alexander Ladd</title><subtitle>An amazing website.</subtitle><author><name>Alexander Ladd</name><email>zladd@berkeley.edu</email></author><entry><title type="html">Review 36: Opening the Black Box: Low-Dimensional Dynamics in High-Dimensional Recurrent Neural Networks</title><link href="http://localhost:4000/reviews/review36/" rel="alternate" type="text/html" title="Review 36: Opening the Black Box: Low-Dimensional Dynamics in High-Dimensional Recurrent Neural Networks" /><published>2022-07-13T05:17:13-07:00</published><updated>2022-07-13T05:17:13-07:00</updated><id>http://localhost:4000/reviews/review36</id><content type="html" xml:base="http://localhost:4000/reviews/review36/">&lt;p&gt;&lt;a href=&quot;https://direct.mit.edu/neco/article-abstract/25/3/626/7854/Opening-the-Black-Box-Low-Dimensional-Dynamics-in&quot;&gt;Opening the Black Box: Low-Dimensional Dynamics
in High-Dimensional Recurrent Neural Networks&lt;/a&gt; by &lt;a href=&quot;https://scholar.google.com/citations?user=ebBgMSkAAAAJ&amp;amp;hl=en&quot;&gt;David Sussillo&lt;/a&gt; and &lt;a href=&quot;https://scholar.google.com/citations?user=6BrZ2isAAAAJ&amp;amp;hl=en&quot;&gt;Omri Barak&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Sussillo, David, and Omri Barak. “Opening the black box: low-dimensional dynamics in high-dimensional recurrent neural networks.” Neural computation 25.3 (2013): 626-649.
 &lt;!-- -  &lt;img src=&quot;/assets/images/imagery5.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot;/&gt; --&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Notation : I don’t know how to use macro &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\bm&lt;/code&gt; instead of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\mathbf&lt;/code&gt; on this website so vector notation is going out of the window. That can be very confusing… but &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\mathbf&lt;/code&gt; is clunky.&lt;/li&gt;
  &lt;li&gt;Introduction
    &lt;ul&gt;
      &lt;li&gt;View of RNN as a non-linear dynamical system (NLDS).&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Phase space&lt;/strong&gt;: Just a more specifc term than state space, instead of general description of all possible states, phase space defines a state as a set of coordinates.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Fixed points&lt;/strong&gt;: Coordinates in the phase space that exhibit zero motion. extends to &lt;strong&gt;Slow points&lt;/strong&gt;.
        &lt;ul&gt;
          &lt;li&gt;Stable or unstable (or attractor v. repeller), meaning system converges towards or away from these points.&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;mode&lt;/strong&gt;: independent pattern of activity that arises around fixed point when the linear system is diagonalized.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Hypothesis is that RNN == NLDS, but at slow points, linearization is valid. Paper provides principled approach to finding regions with slow points, then linearizes arround each slow point, and then relates interaction between regions.&lt;/li&gt;
      &lt;li&gt;Technique introduced allows id. of attractors, repellers, and saddle ponts.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Linear approximations
    &lt;ul&gt;
      &lt;li&gt;a system of diff. eqs.: $ \dot{x} = F(x) $ and trying to find points, $ x^{*} $ such that $ | F(x^{*}) \partial x | \geq F(x^{*}) $ and $ | F(x^{*}) \partial x | \geq  | \frac{1}{2}  \partial x  F’‘(x^{*}) \partial x | $.&lt;/li&gt;
      &lt;li&gt;The way I understand this is that peturbations induce a linear rate of change in the value of the system and the rate of change in the system.&lt;/li&gt;
      &lt;li&gt;speed, or kinetic energy of the systm is : $ q(x) = \frac{1}{2}|F(x)|^2  $, which is useful becuase it is a scalar that can be optimized,  q = 0 only at fixed points, and gradient and hessian of q are amenable to finding minumum values that are not fixed points (so they are saddle points?).
        &lt;ul&gt;
          &lt;li&gt;don’t fully understand how the conditions for minmimum are derived but moving on for now.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;2 - d example:
        &lt;ul&gt;
          &lt;li&gt;defined as dynamical system:
  \begin{equation}
  \dot(x_1) = (1 - x_1^2)x_2
  \dot(x_2) = x_1 / 2 - x_2
  \end{equation}&lt;/li&gt;
          &lt;li&gt;The system has three fixed points: a saddle at (0, 0) and two attractors at (1, 1/2) and (−1, −1/2).&lt;/li&gt;
          &lt;li&gt;Here is the figure used to describe this dynamical system. I find it useful because it shows how differnt ICs (inital conditions) can converge to different fixed points and does a decent job of showing the difference between saddle and fixed point.
  &lt;!-- &lt;img src=&quot;/assets/images/sussillo_2013_fig1.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot;/&gt;  --&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;RNN formulation
        &lt;ul&gt;
          &lt;li&gt;$\mathbf{x}$ is the vector of activations and $\r(x_i)$ is the firing rate for neuron $i$
  \begin{equation}
  \dot{x_i} = -x_i \sum_{k}^N j_{ik}r_k + \sum_{k}{N} B_{ik}u_k
  r_i = h(x_i)
  \end{equation}&lt;/li&gt;
          &lt;li&gt;The recurrence of the network is defined by the matrix J, and the network receives the I-dimensional input u through the synaptic weight matrix B.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;3 bit flip flop
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;&lt;em&gt;TODO&lt;/em&gt;&lt;/strong&gt; I do not understand many things about the 3 bit task. So I just write open questions here instead.
            &lt;ul&gt;
              &lt;li&gt;Do the 3 units have a sequential relationship?&lt;/li&gt;
              &lt;li&gt;The input pulses are real valued? How are they thresholded?&lt;/li&gt;
              &lt;li&gt;In figure 2, are the inputs colored or the outputs? Seem like the outputs are colored, but it’s still hard to relate them.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Still, I need to give best description of the system so we’ll go ahead.&lt;/li&gt;
          &lt;li&gt;$2^3 = 8$ possible memories. Random impulses hit each bit and either confirm the sign (because it matched +1,-1) or flip sign from +1 to -1.&lt;/li&gt;
          &lt;li&gt;modeled with echostate RNN trained using FORCE (Sussillo &amp;amp; Abbot 2007) and trained using random init. weights and 600 different starting points (ICs). Fixed point finder resulted in 26 distinct fixed points and then they analyze these w/ linear stabiility anaylsis described above.&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;important&lt;/strong&gt; there are 8 attractors for every memory state. 
  &lt;!-- -  &lt;img src=&quot;/assets/images/sussillo_2013_fig3.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot;/&gt;  --&gt;
            &lt;blockquote&gt;
              &lt;p&gt;Sussillo and Barak 2013&lt;/p&gt;
              &lt;blockquote&gt;
                &lt;p&gt;Figure 3: Low-dimensional phase space representation of 3-bit flip-flop task. (Left) The eight memory states are shown as black x. In blue are shown all 24 1-bit transitions between the eight memory states of the 3-bit flip-flop. The saddle fixed points with one unstable dimension are shown with green x. A thick red line denotes the dimension of instability of these saddle points. In thin red are the network trajectories started just off the unstable dimensions of the saddle points. These are heteroclinic orbits between the saddles that decide the boundaries and the attractor fixed points that represent the memories. Finally, the pink x show other fixed points, all with four unstable dimensions. Thick red lines show these dimensions of instability, and thin red lines show network trajectories started just off the fixed points in these unstable dimensions. (Right) Demonstration that a saddle point mediates the transitions between attractors. The input for a transition (circled region in left panel) was varied from 0 to 1, and the network dynamics are shown (blue for normal input pulse and cyan for the rest). As the input pulse increased in value, the network came ever closer to the saddle and then finally transitioned to the new attractor state.&lt;/p&gt;
              &lt;/blockquote&gt;
            &lt;/blockquote&gt;
          &lt;/li&gt;
          &lt;li&gt;System uses saddle points to mediate transition from one memory to another.&lt;/li&gt;
          &lt;li&gt;Though most transition from memory states are fairly straightforward, there are some unstable trajectories that appear to serve no purpose (pink fixed points).&lt;/li&gt;
          &lt;li&gt;Without explicit design of a network for a particular phase space, there can be redundant or multiple fixed points between two attractor states.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Sine wave generator
        &lt;ul&gt;
          &lt;li&gt;Network that produces a target sine wave for a given frequency from 1-51 frequency values.&lt;/li&gt;
          &lt;li&gt;linearized system had only two unstable dimensions.&lt;/li&gt;
          &lt;li&gt;Is it a surprising result that there is a fixed point corresponding to the 51 freq. values? Obviously we know some of them sill result in regions of interest, but is the 1-1 correspondence implied by the task or not?
            &lt;ul&gt;
              &lt;li&gt;These regions are rigoursly verified by norm of linear term agreeing with conditions (idk the eq. # above, but it’s the ones under “linear approximations” section).&lt;/li&gt;
              &lt;li&gt;So I guess that is not necessarily implied by the fixed point analysis.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Beyond fixed points
        &lt;ul&gt;
          &lt;li&gt;saddle points found by $q$ (“linear approximations” section) also provide insight system because linear term is dominating even if zero order of taylor expansion != 0. They term these points ghost points (or slow points) and state that even if they are not mediating transitions directly like fixed points, they are influencing the tracjectory of the system as shown below.
            &lt;ul&gt;
              &lt;li&gt;I thought zero-order term was linear? And first or second order might not = 0.
  &lt;!-- -  &lt;img src=&quot;/assets/images/sussillo_2013_fig5.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot;/&gt;  --&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;paper includes some examples and formalizaiton of linear dymamics around this point.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Approximate plane attractor
        &lt;ul&gt;
          &lt;li&gt;This example further demonstrates the utility of finding saddle points using $q$. Because this is a summary I won’t explain the approximate plane attractor in too much detail.&lt;/li&gt;
          &lt;li&gt;The gist is that it is a 2 point moving average task which means two values need to be stored in memory.&lt;/li&gt;
          &lt;li&gt;100dim. RNN slow points ($q \leq 1e-4$) actually created a two dimensional manifold.&lt;/li&gt;
          &lt;li&gt;“Ablation study” so to speak done by replace slow points with  linear time-varying dynamical system (LTVDS) with very low mean squared error on transition states.&lt;/li&gt;
          &lt;li&gt;finally, they show the method is robust to peturbations in RNN and doesn’t rely on a finely tuned RNN.
            &lt;ul&gt;
              &lt;li&gt;This is important to show (something a reviewer might have asked for), but I will not cover it here.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Discussion
        &lt;ul&gt;
          &lt;li&gt;Open points for future work include
            &lt;ul&gt;
              &lt;li&gt;generalization to higher dimensional inputs and tasks.&lt;/li&gt;
              &lt;li&gt;May provide insight into observed experimental findings of low-dim. dynamics of experimental neuroscience.
                &lt;ul&gt;
                  &lt;li&gt;This is the one I am interested in!&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;Applying this technique to spiking models.
                &lt;ul&gt;
                  &lt;li&gt;Also this…&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Opening the Black Box: Low-Dimensional Dynamics in High-Dimensional Recurrent Neural Networks by David Sussillo and Omri Barak</summary></entry><entry><title type="html">Review 35: Cortical activity during motor execution, motor imagery, and imagery-based online feedback</title><link href="http://localhost:4000/reviews/review35/" rel="alternate" type="text/html" title="Review 35: Cortical activity during motor execution, motor imagery, and imagery-based online feedback" /><published>2022-07-13T05:17:13-07:00</published><updated>2022-07-13T05:17:13-07:00</updated><id>http://localhost:4000/reviews/review35</id><content type="html" xml:base="http://localhost:4000/reviews/review35/">&lt;p&gt;&lt;a href=&quot;&quot;&gt;Cortical activity during motor execution, motor imagery, and imagery-based online feedback&lt;/a&gt; by &lt;a href=&quot;https://www.mayoclinic.org/biographies/miller-kai-j-m-d-ph-d/bio-20456021&quot;&gt;Kai Miller&lt;/a&gt; and &lt;a href=&quot;https://www.rajeshpnrao.com/&quot;&gt;Rajesh P.N. Rao&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Miller, Kai J., et al. “Cortical activity during motor execution, motor imagery, and imagery-based online feedback.” Proceedings of the National Academy of Sciences 107.9 (2010): 4430-4435.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Hey Neuromatch friends!! Since we are using this dataset I thought I’d take out two birds with one stone and review it on my website too. Let’s get started.&lt;/li&gt;
  &lt;li&gt;Introduction
    &lt;ul&gt;
      &lt;li&gt;Many of the same areas involved in motor skill execution are involved in planning.
        &lt;ul&gt;
          &lt;li&gt;medial supplemental motor area&lt;/li&gt;
          &lt;li&gt;premotor cortex&lt;/li&gt;
          &lt;li&gt;dorsolateral prefrontal cortex (LFPC)&lt;/li&gt;
          &lt;li&gt;posterior parietal cortex (PPC)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Previous papers show motor function is revealed in high frequency band (HFB) of ECoG (electrocorticography) cortical surface potential of power spectral density (PSD).
        &lt;ul&gt;
          &lt;li&gt;Independent dynamics of fingers can be resolved at 20ms time scale in single electrodes by using changes in PSD.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;$\alpha$ and $\beta$ rythms spatially overlap &lt;em&gt;in LFPC&lt;/em&gt; between overt movement and imagery but also overlap for different movement types as well. On the other hand, high frequency component did overlap between overt / imagery but did not overlap for movement types.
        &lt;ul&gt;
          &lt;li&gt;Thus there are shared representations for movement and imagery at the population level.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Results
    &lt;ul&gt;
      &lt;li&gt;Low freq. band (LFB) decreases during movement and HFB increases.&lt;/li&gt;
      &lt;li&gt;&lt;img src=&quot;/assets/images/imagery1.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Figure 1
        &lt;ul&gt;
          &lt;li&gt;A: PSD for hand movement movement (red) v.s. rest (blue). Left is during movement and right is during imagery. Notice the gap between PSD in for HFB and LFB is tighter for imagery.
            &lt;ul&gt;
              &lt;li&gt;Caveat: PSDs are for primary motor electrode (see paper to find where this is, it’s also circled in B).&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;B: Electrode positions. Blue = hand, pink = tongue.&lt;/li&gt;
          &lt;li&gt;C: normalized HFB activation maps.&lt;/li&gt;
          &lt;li&gt;D same as C but LFB.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;img src=&quot;/assets/images/imagery2.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Figure 2
        &lt;ul&gt;
          &lt;li&gt;A: Geometric mean of PSD of electrodes during imagery v.s. movement.&lt;/li&gt;
          &lt;li&gt;B:  For subjects 2–5, the overlap is quantified between hand and tongue movement (yel- low), hand movement and imagery (light blue), and tongue movement and imagery (light pink). ø, significance, P &amp;gt; 0.01 (by reshuffling).&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;38 electrodes selected to quantify activity using signifigance. 21 elec. for tongue and 17 for hand. Relative change in PSD for imagery (to movement) in HFB was 25% and relative change in PSD for LFB was 46%.&lt;/li&gt;
      &lt;li&gt;Spatial overlap in HFB and LFB was signifcant for imagery v.s. movement but not movement v.s. movement.&lt;/li&gt;
      &lt;li&gt;Fairly high rates of using motor imagery to control a cursor. Magnitude of HFB increases as patients move cursor.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Discussion
    &lt;ul&gt;
      &lt;li&gt;α/β desynchronization captured by LFB reflects an aspect of cortical processing that is fundamentally nonspecific. It may represent feedback between cortical and subcortical structures.&lt;/li&gt;
      &lt;li&gt;Recent findings suggest PSD amp. changes are corr. with neuronal firing rate. Thus suggest 25% change in imagery means population is either a) firing 4x more during movement or b) 4x more active neurons during movement. Or some combination of both.&lt;/li&gt;
      &lt;li&gt;&lt;img src=&quot;/assets/images/imagery5.png&quot; alt=&quot;no alt&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Cortical activity during motor execution, motor imagery, and imagery-based online feedback by Kai Miller and Rajesh P.N. Rao</summary></entry><entry><title type="html">Review 34: The Role of Population Structure in Computations Through Neural Dynamics</title><link href="http://localhost:4000/reviews/review34/" rel="alternate" type="text/html" title="Review 34: The Role of Population Structure in Computations Through Neural Dynamics" /><published>2022-07-10T05:17:13-07:00</published><updated>2022-07-10T05:17:13-07:00</updated><id>http://localhost:4000/reviews/review34</id><content type="html" xml:base="http://localhost:4000/reviews/review34/">&lt;p&gt;&lt;a href=&quot;&quot;&gt;The Role of Population Structure in Computations Through Neural Dynamics&lt;/a&gt; by &lt;a href=&quot;&quot;&gt;Alexis Dubreuil&lt;/a&gt; &lt;a href=&quot;&quot;&gt;Adrian Valente&lt;/a&gt; and &lt;a href=&quot;&quot;&gt;Srdjan Ostojic&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;todo-citation-needed&quot;&gt;TODO CITATION NEEDED&lt;/h2&gt;
&lt;h2 id=&quot;todo-j-a-gallego-m-g-perich-l-e-miller-and-s-a-solla-neural-manifolds-for-the-control-of-movement-neuron&quot;&gt;TODO: J. A. Gallego, M. G. Perich, L. E. Miller, and S. A. Solla. Neural manifolds for the control of movement. Neuron,&lt;/h2&gt;
&lt;h2 id=&quot;todo-l-duncker-l-driscoll-k-v-shenoy-m-sahani-and-d-sussillo-organizing-recurrent-network-dynamics-by-task-computation-to-enable-continual-learning-advances-in-neural-information-processing-systems-33-2020&quot;&gt;TODO L. Duncker, L. Driscoll, K. V. Shenoy, M. Sahani, and D. Sussillo. Organizing recurrent network dynamics by task-computation to enable continual learning. Advances in Neural Information Processing Systems, 33, 2020.&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;This is a longer paper than I noramlly read, so I will need to read less content or else I will be reading forever. I usually read at least 75% of the sentences in a paper but for this one I will scale back to 50%. As a consolation, I’ll focus a bit more on the figures and the overall message.&lt;/li&gt;
  &lt;li&gt;Introduction
    &lt;ul&gt;
      &lt;li&gt;Two antagonistic approaches are represented: 1. functional populations by cell categorization and 2. low dimensional trajectories of population dynamics. 1. is challenged by the fact that function and neuron subtype are seemingly random at higher level cortical areas. 2. Is fairly new, but can be well understood through Vyas et al. 2020 computation throud dynamics framework (see review ? TODO: figure out what review).&lt;/li&gt;
      &lt;li&gt;Two studies [Hirokawa et al., 2019] and [Raposo et al., 2014] study posterior parietal cortex (PPC) and try to look for statistically verifiable measures of population activity and come to opposite conclusions about whether activity is entirely multiplexed or if there is some non-random population structure in selective responses.&lt;/li&gt;
      &lt;li&gt;To reconcile, this study trains recurrent neural networks (RNNs) on a range of systems neuroscience tasks and finds that random population structure can accomplish most tasks but some tasks required non-random sub-population structure in terms of connectivity (study also looks for structure in selectivity).&lt;/li&gt;
      &lt;li&gt;They focus on a class of low-rank models that have latent dynamics understood through a minimal intrinsic dimension and number of sub-populations.
        &lt;ul&gt;
          &lt;li&gt;I have no clue what this means. I get the part about a minimal dimension and subpopulations but I have no idea what a low-rank model is. I think it is probably something I am familiar mathemtically with but the terminology is being mixed around here and thus entirely lost on me.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Results
    &lt;ul&gt;
      &lt;li&gt;RNNs trained on 5 systems neuroscience task:
        &lt;ul&gt;
          &lt;li&gt;perceptual decision making (DM)&lt;/li&gt;
          &lt;li&gt;working memory (WM)&lt;/li&gt;
          &lt;li&gt;multi-sensory decision making (MDM)&lt;/li&gt;
          &lt;li&gt;contextual decision making (CDM)&lt;/li&gt;
          &lt;li&gt;delay match to sample (DMS)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Each task has 100 RNNs trained with different random initializations.&lt;/li&gt;
      &lt;li&gt;Rough description of mathemtical network:
  \(\gamma \frac{dx_i}{dt} = -x_i + \sum^N_{j=1}J_{i,j}\phi(x_j) + \sum^{N_{in} }_{s=1}I_i^{ (s) } u_s(t) + \eta_i(t)\)
        &lt;ul&gt;
          &lt;li&gt;component 1: sum of nonlinearity activation units ($\phi(x_j) $) times recurrent netowrk connectivity matrices over all neurons $J_{i,j}$.&lt;/li&gt;
          &lt;li&gt;component 2: Sum of feedforward weights  $I_i^{(s)}$ times inputs $u_s(t)$ plus some noise $\eta_i(t)$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Selectivity structure
        &lt;ul&gt;
          &lt;li&gt;selectivity space defined by 2-4 dimensional where each axis was given by the linear regression coefficient $\Beta^{v}_{i}$ of neural firing rate with respect to a task variable v such as stimulus, decision or context. Gaussian isotropic distribution in this space reprsents random population selectivity (v. non-random mixed selectivity).&lt;/li&gt;
          &lt;li&gt;2/5 tasks show non-random mixed selectivity.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Population structure
        &lt;ul&gt;
          &lt;li&gt;Low rank structure means high dim. neural connectivity matrix projected onto smaller subspace using a few parameters. Thien they use the same bonferroni corrected ePAIRS  (defined in STAR methods but also by Hirokawa and Raposo studies TODO: make this a footnote) signfigance test against isotropic Gaussian.
            &lt;ul&gt;
              &lt;li&gt;Now we know that our “low-rank” models are just projections of connectivity matrices $J_{i,j}$. Specifically they are models of rank R (decomposition of $J_{i,j}$ by sequence of vector products $m_{i}^{ {1) }n_{j}^{ {1) } + … m_{i}^{ (R) }n_{j}^{(R)}$. There are aso $N_{in}$ inputs. This leads to each neuron connectivity being parameterized by 2R + $N_{in}$ + 1. 1 readout weight and 2R because there are $m$ and $n$ terms in $J_{i,j}$.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;CDM and DMS taks show networks converging to have structure in terms of both selectivity and connectivity. But this is just correlational evidence. Love to see the authors push for causal evidence using resampling strategy.
        &lt;ul&gt;
          &lt;li&gt;They resample using mvn Gaussian matching low rank RNN to get new connectivity weights and see if performance on input / output task becomes scrambled due to scrambling potential population structure. Indeed CDM and DMS outputs are scrambled.
  -&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">The Role of Population Structure in Computations Through Neural Dynamics by Alexis Dubreuil Adrian Valente and Srdjan Ostojic</summary></entry><entry><title type="html">Review 33: High-density Single-unit Human Cortical Recordings Using the Neuropixels Probe</title><link href="http://localhost:4000/reviews/review33/" rel="alternate" type="text/html" title="Review 33: High-density Single-unit Human Cortical Recordings Using the Neuropixels Probe" /><published>2022-07-10T05:16:13-07:00</published><updated>2022-07-10T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review33</id><content type="html" xml:base="http://localhost:4000/reviews/review33/">&lt;p&gt;&lt;a href=&quot;&quot;&gt;High-density Single-unit Human Cortical Recordings Using the Neuropixels Probe&lt;/a&gt; by &lt;a href=&quot;&quot;&gt;Jason Chung&lt;/a&gt; and &lt;a href=&quot;&quot;&gt;Edward F. Chang&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;todo-citation-needed&quot;&gt;TODO CITATION NEEDED&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;I’ve reviewed the Neuropixels and Neuropixels 2.0 probes recently but this review is interesting because it translates the capacity of the Neuropixels probe to record from thousands of neurons in animal models to hundreds of neurons in humans undergoing neurosurgical procedures.&lt;/li&gt;
  &lt;li&gt;Highlights
    &lt;ul&gt;
      &lt;li&gt;8 human patients&lt;/li&gt;
      &lt;li&gt;596 putative neuron units&lt;/li&gt;
      &lt;li&gt;First spike takes longer in anesthesized subjects&lt;/li&gt;
      &lt;li&gt;Motion of electrode array inversely correlated with yield&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Introduction
    &lt;ul&gt;
      &lt;li&gt;Microelectrode array recordings (MEA) have many use cases during neursurgical procedures for identifying cell types and structure in the basal ganglia and thalamus, however, these small targets means that probe movement of even 1-2mm can cause potential issues.&lt;/li&gt;
      &lt;li&gt;The number of neurons that can be recorded from simultaneously is a severe limtation.
        &lt;ul&gt;
          &lt;li&gt;Sharp metal MEA records 1 neuron at a time.&lt;/li&gt;
          &lt;li&gt;Microwire can yield up to 3 neurons but normally 1-2.&lt;/li&gt;
          &lt;li&gt;Utah arrays have 96 channels but take awhile to calibrate and cannot sample across cortical depth.
            &lt;ul&gt;
              &lt;li&gt;I wonder how many electrodes utah arrays can record from?&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Recent advances in microfabrication have revealed much about the spatial and temporal scales of neural circuit activity but “[ inability of ] translation of methods for recording fundamental computational units [ such as ] single neurons and ensembles ha led to an increasing gap between what can be learned in animal models and how these detailed principles apply to the human brain,”.
        &lt;ul&gt;
          &lt;li&gt;I paraphrase here because I don’t quite understand how these methods can record from a circuit but not neurons/ensembles of neurons.&lt;/li&gt;
          &lt;li&gt;Also, it is not naturally clear to me how this issue affects translation of insights between animal and human brains.&lt;/li&gt;
          &lt;li&gt;TODO: investigate&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Looking at table 1:
        &lt;ul&gt;
          &lt;li&gt;I think it’s surprising that 4 probes broke but I don’t know if it’s surprisingly high or surpsignly low. I think it is probably low when we consider the fact that device bio-compatiblity with the brain must be very difficult to accomplish. I’d be curious to know the key factors that break these devices.&lt;/li&gt;
          &lt;li&gt;Also, I had no idea that most patients were actually awake for these procedures!&lt;/li&gt;
          &lt;li&gt;NP11 and NP06 are interested since probe is inserted into motor cortex.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;It looks like they are using Neurpixels 1.0, but see Review 23 (*TODO: add link) to see how CMOS tech + multichannel recording and high density MEA enable lightweight recording from 1000s of electrodes.&lt;/li&gt;
      &lt;li&gt;960 12 x 12 $\mu$m contacts, 384 channels, 10 mm shanks. (*TODO add picture)&lt;/li&gt;
      &lt;li&gt;
        &lt;ul&gt;
          &lt;li&gt;TODO: check out twin study by Paulk&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Final pargraph just formally recaps the info from the highlights section in the body of the paper. However, they do add some interesting extra info on the extensiblity of impalnting in different regions and feasiblity for use during craniotomy.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Results
    &lt;ul&gt;
      &lt;li&gt;First pargraph details the insertion procedure. I found this part interestnig:
        &lt;blockquote&gt;
          &lt;p&gt;(Chung 2022)&lt;/p&gt;
          &lt;blockquote&gt;
            &lt;p&gt;The insertion locations were at the center of a gyrus, away from surface vasculature, that was going to be resected in the same surgical procedure (Figure 1B).&lt;/p&gt;
          &lt;/blockquote&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;My best geuss is that there is an insertion tract lesion of .25 mm in width and about 3mm long.&lt;/li&gt;
      &lt;li&gt;In figure 1D the light yellow dots are very hard to see. A different color scheme or dot labeling scheme would have worked better.&lt;/li&gt;
      &lt;li&gt;They were able to improve functionality by:
        &lt;ul&gt;
          &lt;li&gt;reducing noise from AC to get better SNR ratio.&lt;/li&gt;
          &lt;li&gt;Increasing reducing positive end expiratory pressure patients to help reduce amplitude of brain pulsations.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Spiking increases for the first several minutes of insertion.&lt;/li&gt;
      &lt;li&gt;75% of all units of device were active at 2mins in.&lt;/li&gt;
      &lt;li&gt;11 recordsings with length 10-23 mins and 596 units identified in total with $54 +/- 24 SD$.&lt;/li&gt;
      &lt;li&gt;Figure 2 looks nice. It shows rasters, recordings snippets, time to first spike CDF and # of units against recording length.
        &lt;ul&gt;
          &lt;li&gt;The  # of units against recording length is not super positively correlated which maybe shows a limit to how variable population activity is over time. If those regions do not fire in 10 minutes, they are likely not going to fire for awhile. I wonder if they’d fire after 2hours? Gonna be hard pressed to get an answer to that one though.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;ul&gt;
          &lt;li&gt;TODO what are cluster metrics in STAR.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The authors discuss stabilization as a major limitation of recording technique and discuss using a stabilization algorithm in kilosort that uses spike foot[rint across a few channels to correct for motion.&lt;/li&gt;
      &lt;li&gt;They quantify motion by using higher freq. and amplitude units as spatial markers to discover 251 +- 112 $\mu$m or movement.&lt;/li&gt;
      &lt;li&gt;Cell Pair Coordination index (TODO: what is this) increases with cross-correleogram pairs under 50ms compared to those CCH pairs over 50ms.&lt;/li&gt;
      &lt;li&gt;Figure 3: noise increases (SNR decreases) with amplitude of signal ($\mu$V) and the ISI 1ms violations increase. Histogram truncation is minimal when spike amplitude is around 200 $\muV$, making a U shaped curve.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Discussion
    &lt;ul&gt;
      &lt;li&gt;Elimating all AC current devices attached to patient was important for reducing SNR.&lt;/li&gt;
      &lt;li&gt;First comparison between animal and human neurpixels due to clustering and other metrics reported.&lt;/li&gt;
      &lt;li&gt;I’m glad they bring up that neurpixels 2.0 actually has a motion stabilization algorithm. Really shows the alignment of objectives between Steinmetz et al. and applicaiton of Neurpixels.&lt;/li&gt;
      &lt;li&gt;Timeline of recording advances:
        &lt;ul&gt;
          &lt;li&gt;Earliest single unit recordings (Ward and Thomas 1955)&lt;/li&gt;
          &lt;li&gt;90 units over 17 patients (Wyler 1982)&lt;/li&gt;
          &lt;li&gt;Utah aray enables BCI-control of a cursor (Hochberg et al. 2006) and robotic limb (Alfalo 2015)&lt;/li&gt;
          &lt;li&gt;Longitudal recording of up to 1500 days (Hughes et al. 2021) and noted immune response + structural reorganization.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Advice on ethical considerations
        &lt;ul&gt;
          &lt;li&gt;TODO: note and cite Chiong et al. (2018) and Feinsinger et al. (2022) f&lt;/li&gt;
          &lt;li&gt;Clinical care and safety should never be comprimised for research.&lt;/li&gt;
          &lt;li&gt;Team includes treating physicians and non treating researchers.&lt;/li&gt;
          &lt;li&gt;Assesment for appropriateness and ability to participate in the study.&lt;/li&gt;
          &lt;li&gt;Continous monitoring and consent for patient participation in the study.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;blockquote&gt;
      &lt;p&gt;Chung 2022&lt;/p&gt;
      &lt;blockquote&gt;
        &lt;p&gt;The major advance demonstrated here is recording in human brain with densely spaced high channel count simultaneously acquired across the cortical thickness.&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/blockquote&gt;

    &lt;ul&gt;
      &lt;li&gt;Challenges / Lessons Learned:
        &lt;ul&gt;
          &lt;li&gt;Minimize patient movement&lt;/li&gt;
          &lt;li&gt;Turn off non-essential electrical device to minmize noise&lt;/li&gt;
          &lt;li&gt;Remove AC devices on the patient&lt;/li&gt;
          &lt;li&gt;The positive airflow intutabation thing&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Really points to motion correction for future work.&lt;/li&gt;
      &lt;li&gt;Suggests longer recordings.&lt;/li&gt;
      &lt;li&gt;Warns against shank breaking in deeper structures and then needing to retrieve (with forceps?).&lt;/li&gt;
      &lt;li&gt;Neuropixels does not allow stimulation.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">High-density Single-unit Human Cortical Recordings Using the Neuropixels Probe by Jason Chung and Edward F. Chang</summary></entry><entry><title type="html">Review 32: Living Science: Maintaining the Joy of Discovery</title><link href="http://localhost:4000/reviews/review32/" rel="alternate" type="text/html" title="Review 32: Living Science: Maintaining the Joy of Discovery" /><published>2022-07-08T05:16:13-07:00</published><updated>2022-07-08T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review32</id><content type="html" xml:base="http://localhost:4000/reviews/review32/">&lt;p&gt;&lt;a href=&quot;https://elifesciences.org/articles/80711&quot;&gt;Living Science: Maintaining the Joy of Discovery&lt;/a&gt; by &lt;a href=&quot;https://www.brandeis.edu/biology/faculty/marder-eve.html&quot;&gt;Eve Marder&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Marder, Eve. “Living Science: Maintaining the joy of discovery.” Elife 11 (2022): e80711.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;DISCLAIMER: these are my reading notes, not my personal opinion&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Marder 2022&lt;/p&gt;
  &lt;blockquote&gt;
    &lt;p&gt;Changes in science over the past 50 years have reduced the chances of trainees experiencing the joy of discovery.&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Writing starts out with using “you get out what you put in” as the hook but then cites increasing authorship, price, time, and complexity behind important breakthroughs as the reason young scientists may not be able to engage with science the same way she did.&lt;/li&gt;
  &lt;li&gt;The longer turnaround time for analysis and having others analyze your data can damper the joy of discovery.&lt;/li&gt;
  &lt;li&gt;Suggests doing data analysis contemporaneously with generating data.&lt;/li&gt;
  &lt;li&gt;Massive amount of literature available and differing SEO policies on gScholar make orienting oneself if the literature challenging.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Marder 2022&lt;/p&gt;
  &lt;blockquote&gt;
    &lt;p&gt;Oftentimes, I finally understood the potential significance of a piece of work while writing the paper.&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Large-scale collaboration can separate the student from the actual piece of work. Doesn’t always work this way.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Takeaways
    &lt;ul&gt;
      &lt;li&gt;You get out what you put in.&lt;/li&gt;
      &lt;li&gt;gScholar SEO biases search results. Needs to be a better way of orienting oneself in the field.&lt;/li&gt;
      &lt;li&gt;Read / write more.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;My opinion:
    &lt;ul&gt;
      &lt;li&gt;I picked this writing up after I saw &lt;a href=&quot;https://twitter.com/drugmonkeyblog/status/1544559316140584961&quot;&gt;this tweet&lt;/a&gt; calling it a “handwringer”.&lt;/li&gt;
      &lt;li&gt;Upon reflection, I don’t find anything here that concerning.&lt;/li&gt;
      &lt;li&gt;Firstly, I don’t agree with the premise that there isn’t as much low-hanging fruit as there used to be. The low-hanging fruit isn’t the same anymore in terms of conducting very basic science and running a simple and quick analysis of the data; it has changed. With the advent of repositories of open data sets and open-source statistical tools / other tools for data analysis, the low-hanging fruit has just shifted to an entirely different format.
        &lt;ul&gt;
          &lt;li&gt;This is mildly concerning for young researchers who hate stats and don’t have any coding experience but at the end of the day, the reason these methods are prominent is that they provide the most efficient interface with science. Undoubtedly, there is an aspect of gatekeeping here. But what other alternative is there? Removing the systems that perpetuate this is atavistic.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Secondly, the point about contemporaneous analysis is a really good one. I just don’t see why analysis should ever take days or weeks to turn around, that’s just ineffective design.
        &lt;ul&gt;
          &lt;li&gt;I realized this &lt;em&gt;very&lt;/em&gt; recently but IMO you should never find yourself just sitting around waiting for analysis to complete.&lt;/li&gt;
          &lt;li&gt;In my own experience, every time I am sitting around waiting for the analysis to complete there is always a simpler way to break either the data or the analysis into parts and analyze each component very quickly. I argue that learning to break complex analyses into small chunks that can be turned around and verified quickly is an essential skill. It also makes this point a non-factor if you are good enough at it.&lt;/li&gt;
          &lt;li&gt;I’ve yet to see a single analysis not amenable to this treatment in some way.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Third, the point about SEO optimization and the pitfalls of modern literature search is &lt;strong&gt;absolutely valid&lt;/strong&gt;. But mitigating this is just not that hard. There are a million ways to do so:
        &lt;ul&gt;
          &lt;li&gt;Collaborative annotated citations&lt;/li&gt;
          &lt;li&gt;Keyword hacking on gScholar&lt;/li&gt;
          &lt;li&gt;Follow citation trails&lt;/li&gt;
          &lt;li&gt;Follow author trails&lt;/li&gt;
          &lt;li&gt;Articles with over 1k citations are categorically prominent works in the field&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;However, on the point about not feeling like an expert because of the overwhelming amount of papers available: this is the big fish small pond problem. When there are only a few journals you &lt;em&gt;feel&lt;/em&gt; like an expert and you &lt;em&gt;feel&lt;/em&gt; like you are engaging with your field but the actual engagement is much less than you perceive. On the other hand, in the new age, you never feel like an expert but you are much more informed than you feel. If you can’t enjoy science without feeling like an expert by dwarfing the literature available then you bite your nose to spite your face. The information hose (the internet) is just going to keep blasting and it is empirically a good thing. New experts just understand how to distill the deluge of papers, like &lt;a href=&quot;https://arxiv-sanity-lite.com/&quot;&gt;arxiv sanity&lt;/a&gt; or online journal clubs.&lt;/li&gt;
      &lt;li&gt;Finally I wholeheartedly agree with the point about appreciating the impact of the work through writing and I think that oppurtunity is now more accessible than ever!
        &lt;ul&gt;
          &lt;li&gt;Writing small articles for arxiv&lt;/li&gt;
          &lt;li&gt;Writing blog posts (like this!)&lt;/li&gt;
          &lt;li&gt;Tweetprints&lt;/li&gt;
          &lt;li&gt;Posting your work on your website&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;So in conclusion:
        &lt;ul&gt;
          &lt;li&gt;I feel that finding the joy in science isn’t &lt;em&gt;harder&lt;/em&gt; per say it’s just different.&lt;/li&gt;
          &lt;li&gt;But the lead message of this paper is still poignant: &lt;strong&gt;you get out what you put in&lt;/strong&gt;.
            &lt;ul&gt;
              &lt;li&gt;If you let the deluge of papers stop you from reading then you are worse off.&lt;/li&gt;
              &lt;li&gt;If you let the big project you are working on prevent you from releasing your own conference workshop paper for example then yes you are being restricted from writing.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;It’s not easy because in my opinion there are some worse pitfalls for young scientists but they are broader concerns for young professionals in general.&lt;/li&gt;
          &lt;li&gt;But I believe that research has not become overall less or more fulfilling. The opportunity is always just a few small steps away. We just need to get out of our own way first.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Living Science: Maintaining the Joy of Discovery by Eve Marder</summary></entry><entry><title type="html">Review 31: Noninvasive Brain–Machine Interfaces for Robotic Devices</title><link href="http://localhost:4000/reviews/review31/" rel="alternate" type="text/html" title="Review 31: Noninvasive Brain–Machine Interfaces for Robotic Devices" /><published>2022-06-11T05:16:13-07:00</published><updated>2022-06-11T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review31</id><content type="html" xml:base="http://localhost:4000/reviews/review31/">&lt;p&gt;&lt;a href=&quot;https://spectrum.ieee.org/brain-implant&quot;&gt;Noninvasive Brain–Machine Interfaces for Robotic Devices&lt;/a&gt; by &lt;a href=&quot;https://scholar.google.com/citations?user=U2N9FlcAAAAJ&amp;amp;hl=en&quot;&gt;Luca Toning&lt;/a&gt; and &lt;a href=&quot;https://www.ece.utexas.edu/people/faculty/jose-del-r-millan&quot;&gt;José del R. Millán&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Tonin, Luca, and José del R. Millán. “Noninvasive brain–machine interfaces for robotic devices.” Annual Review of Control, Robotics, and Autonomous Systems 4 (2021): 191-214.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;First this from the abstract: “. We found that BMIs are used mostly to drive devices for navigation (e.g., telepresence mobile robots), with BMI paradigms based mainly on exogenous stimulation, and the majority of brain-actuated robots adopt a discrete control strategy,”.&lt;/li&gt;
  &lt;li&gt;Introduction
    &lt;ul&gt;
      &lt;li&gt;Main focus of brain-machine interfaces, or BMIs, is to restore motor functions for those with damaged pathways or motor dysfunction.
eg; brain-controlled cursor movement, keyboards + typing, remote-controlled devices.&lt;/li&gt;
      &lt;li&gt;Not just a plug and play engineering problem, we should think about how to generate effective control signals as well.&lt;/li&gt;
      &lt;li&gt;Paper roadmap: introduce closed-loop system -&amp;gt; turn to main modalities of interaction/control -&amp;gt; provide an overview of 86 works over the past 15 years -&amp;gt; lay out challenges and future directions.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The Closed Loop of a Brain-Machine Interface: A Mutual Learning Interaction
    &lt;ul&gt;
      &lt;li&gt;Here is a high level description of Fig 1.
        &lt;ul&gt;
          &lt;li&gt;Brain activity is elicited and recorded.
            &lt;ul&gt;
              &lt;li&gt;Endogenous: user voluntarily engages activity in some mental task.&lt;/li&gt;
              &lt;li&gt;Exogenous: user is presented stimuli and correlates of brain activity are measured during this task.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Features are extracted.&lt;/li&gt;
          &lt;li&gt;Control.
            &lt;ul&gt;
              &lt;li&gt;This block in the flow is complicated. Suffice it to say that this part is a signal handed to a robotic device.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Online feedback.
            &lt;ul&gt;
              &lt;li&gt;User &lt;em&gt;sees&lt;/em&gt; behavior and deems it rewarding / not rewarding.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Rinse and Repeat.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Two key considerations for this loop to work:
        &lt;blockquote&gt;
          &lt;p&gt;Toning 2021&lt;/p&gt;
          &lt;blockquote&gt;
            &lt;p&gt;Two concepts therefore become essential in the design of the BMI closed loop: a fast response by the robot to the user’s intention, in order to allow fine and reactive control over the device (Section 4), and a bidirectional interaction between the robot and BMI, in order to trigger and exploit the robot intelligence and thus support the user in performing complex actions (Section 5).&lt;/p&gt;
          &lt;/blockquote&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;Ultimately this seems like communication bandwidth between the human/animal (affector) and the controlled device (effector).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Invasive and Noninvasive Acquisition Techniques
    &lt;ul&gt;
      &lt;li&gt;Noninvasive BMIs can access either electrocorticogram signals (EEG) or hemodynamic activity (bloodflow) like seen in fMRIs.
        &lt;ul&gt;
          &lt;li&gt;EEG has an advantage temporally but fMRI has an advantage spatially.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Signal Processing and Feature Extraction
    &lt;ul&gt;
      &lt;li&gt;Lots of filtering happens in non-invasive BCI so that we can increase signal to noise ratio.
        &lt;ul&gt;
          &lt;li&gt;Filter DC component.&lt;/li&gt;
          &lt;li&gt;Spatial filters.&lt;/li&gt;
          &lt;li&gt;Low dimensional reductions of data.&lt;/li&gt;
          &lt;li&gt;Hilbert transform, FFT transform, wavelet decomposition.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Feature Selection and Classification Algorithms
    &lt;ul&gt;
      &lt;li&gt;16 channels with 4-48hz resolution result in 340+ features to potentially consider.&lt;/li&gt;
      &lt;li&gt;During calibration channels that are discriminative or particularly relevant to functional neural correlates are selected in feature selection.&lt;/li&gt;
      &lt;li&gt;After online/control phase, the decoder is then used for offline discriminant classification.
        &lt;ul&gt;
          &lt;li&gt;SVM, Gaussian +/ kernel models.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Human-In-The-Loop: Interaction Modalities in Brain-Machine Interfaces
    &lt;ul&gt;
      &lt;li&gt;Exogenous paradigms
        &lt;ul&gt;
          &lt;li&gt;Steady-state evoked potential (SSEP) based BMIs: present several visual stimuli to target (like a flashing light) and the user can guide control by fixing their eyes on a specific target, which corresponds to an action in a remote-controlled robotic device.&lt;/li&gt;
          &lt;li&gt;P300 signals are evoked after some anomalistic pattern is observed. It’s hard to see how users picking out infrequent patterns or letters can lead to goal-directed control of a robotic arm. I’d have to look into the Farwell–Donchin spellers task.&lt;/li&gt;
          &lt;li&gt;Error-related signals can be used to increase robustness for BMI applications.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Endogenous Paradigms
        &lt;ul&gt;
          &lt;li&gt;Event-related localized changes in frequency, or an increment or decrement in EEG.
            &lt;ul&gt;
              &lt;li&gt;$\mu$ and $\beta$ bands of activity specifically related to motor imagination.&lt;/li&gt;
              &lt;li&gt;Event-related synchronization or desynchronization.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Task-specific modulation is represented as a marker on a screen, which is important because the capacity for the user to receive continuous feedback about cursor position.&lt;/li&gt;
          &lt;li&gt;Figure 2 quick jot.
            &lt;ul&gt;
              &lt;li&gt;Surprisingly, relative fisher scores for features were very stable over different frequencies.&lt;/li&gt;
              &lt;li&gt;Also 12hz ($\mu$ band) was particularly identifiable.&lt;/li&gt;
              &lt;li&gt;Quadratic boundary used for foot movement v.s. hand movement discrimination.
                &lt;ul&gt;
                  &lt;li&gt;This is also surprising as the feature representation is projected to a $\mathbb{R}^2$ subspace which is very compact. Yet a basic quadratic discrimator works!&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;Signal trajectory needs to converge past boundary to be classified. In one trajectory, neither hand nor foot is detected.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Control strategies
    &lt;ul&gt;
      &lt;li&gt;BMI control is often combined with a corresponding control strategy from the stimulated device.&lt;/li&gt;
      &lt;li&gt;While most systems use discrete control in continuous v.s. discrete control, there is the potential for both.
        &lt;ul&gt;
          &lt;li&gt;Discrete is slower and has lower bandwidth.&lt;/li&gt;
          &lt;li&gt;Continuous control is interesting but not as studied.
            &lt;ul&gt;
              &lt;li&gt;One of the interesting apps is as a continuous driving signal. The other app is the stabilization of discrete commands.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;EEG patterns are non-stationary.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Robot in the Loop: Sharing the Intelligence
    &lt;ul&gt;
      &lt;li&gt;Since many tasks (eg; robotic arm) reaching with non-invasive (and invasive?) BMI is pretty difficult, the devices are often equipped with (or learn) fine level control and stabilization.&lt;/li&gt;
      &lt;li&gt;Two approaches to machine autonomous control: 1. user looks at a spot and the machine takes responsibility for guiding it there using whatever control sequences it pleases or 2. user can offer more granular directions, like turning a wheelchair using a finite state machine (Iturrate et al. (52) qtd. in Toning 2021).
        &lt;ul&gt;
          &lt;li&gt;I am looking forward to hearing what the challenges for 2 are where. There seems to be a bottleneck in terms of how much bandwidth there is for control, just like in the case of continuous decoding.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Sequential control passed between human and robotic arm during grasping task. Human uses menu-based assistance to guide arm and then uses BMI to complete grasping action.&lt;/li&gt;
      &lt;li&gt;Shared control ultimately seems like a nice future direction since humans can have higher-level control and robot can have lower-level control.&lt;/li&gt;
      &lt;li&gt;Subversion of explicit BMI signaling using detection of error-related signals in BMI.
        &lt;ul&gt;
          &lt;li&gt;An error-based override allows the robot to re-interpret the signal.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Current Applications
    &lt;ul&gt;
      &lt;li&gt;Devices, Interaction Modalities, and Control Strategies
        &lt;ul&gt;
          &lt;li&gt;Here the authors give a nice breakdown of mobile control studies: “ brain-controlled mobile robots for telepresence are the type that is most common in the literature (Figure 4a), representing 38.4% of the reviewed studies, followed by powered wheelchairs (22.1%), robotic arms (19.8%), lower limb and upper limb exoskeletons (9.3% and 7.0%, respectively), and quadcopters (3.5%).” (Toning 2021).&lt;/li&gt;
          &lt;li&gt;See figure:
   &lt;img src=&quot;/assets/images/tonin1.png&quot; alt=&quot;bmi overview&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/li&gt;
          &lt;li&gt;Brain-controlled robotic arms are studied in several different studies.&lt;/li&gt;
          &lt;li&gt;Surprisingly only 16.3% of studies included participants that had motor defecits.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Open Challenges and Future Directions
    &lt;ul&gt;
      &lt;li&gt;Integration between BMI and robots is in early days. Normally, the robot is just seen as an actuator.&lt;/li&gt;
      &lt;li&gt;Overcoming commitment to exogenous systems and developing endogenous and self-paced systems has more deploy-ability but comes with challenges for calibration and user mental capacity to focus on this kind of control.&lt;/li&gt;
      &lt;li&gt;The biggest challenge is that most studies are not conducted in coordination with the end-users.
        &lt;ul&gt;
          &lt;li&gt;Which biases the design of the device and calibration/training strategies.&lt;/li&gt;
          &lt;li&gt;A lot of the time, training phases can take weeks.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Applications in navigation and manipulation may not be the most prioritized use case for the end-user. It would be best to coordinate with patients whom BMI researchers aim to help in order to re-contextualize what their priorities are in order to get better alignment.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Noninvasive Brain–Machine Interfaces for Robotic Devices by Luca Toning and José del R. Millán</summary></entry><entry><title type="html">Review 30: Eavesdropping on the Brain With 10,000 Electrodes</title><link href="http://localhost:4000/reviews/review30/" rel="alternate" type="text/html" title="Review 30: Eavesdropping on the Brain With 10,000 Electrodes" /><published>2022-06-05T05:16:13-07:00</published><updated>2022-06-05T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review30</id><content type="html" xml:base="http://localhost:4000/reviews/review30/">&lt;p&gt;&lt;a href=&quot;https://spectrum.ieee.org/brain-implant&quot;&gt;Eavesdropping on the Brain With 10,000 Electrodes&lt;/a&gt; by &lt;a href=&quot;https://www.imecitf.com/2021/health/speakers/barun-dutta-chief-scientist-sts-imec&quot;&gt;Barun Dutta&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Dutta, Barun. “Eavesdropping on the Brain With 10,000 Electrodes.” IEEE Spectrum (2022)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;This is interesting because this article is released by Barun Dutta, one of the principal investigators of the neuropixels devices.&lt;/li&gt;
  &lt;li&gt;The hook begins with the infamous brain-computer metaphor.
    &lt;ul&gt;
      &lt;li&gt;This “brain is a computer” comparison is tired, but this hook works well anyway because it points to the really astounding fact that the brain only requires 20 watts of power.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The introduction sets the stage for introducing &lt;a href=&quot;https://www.imec-int.com/en&quot;&gt;Imec&lt;/a&gt; importance of large-scale recordings of individual neurons and a freely moving animal. This company does some really awesome things with nano and digital technologies.&lt;/li&gt;
  &lt;li&gt;The name “neuropixels” is explained as a field potential recording system that relies on signal processing, kind of like a camera.&lt;/li&gt;
  &lt;li&gt;We also see that neuropixels aims to tackle some of the issues located physically deeper in the brain.&lt;/li&gt;
  &lt;li&gt;Neuropixels 1.0 has a single shank and 1000 electrodes.&lt;/li&gt;
  &lt;li&gt;Neuropixels 2.0 has four shanks with 1280 electrodes.&lt;/li&gt;
  &lt;li&gt;With 3.0 they claim they are moving along an exponential growth curve for BCI recording.&lt;/li&gt;
  &lt;li&gt;It is encouraging to see Imec’s efforts in materials sciences in CMOS fabrication.
    &lt;ul&gt;
      &lt;li&gt;low impedance electro-ceramic shanks sound more durable and much less likely to have electrical discharge.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;I find this quote surprising:
    &lt;blockquote&gt;
      &lt;p&gt;Dutta (2022)&lt;/p&gt;
      &lt;blockquote&gt;
        &lt;p&gt;“the thousandfold difference in elasticity between CMOS shanks and brain tissue”&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/blockquote&gt;

    &lt;ul&gt;
      &lt;li&gt;because I had no idea that even the most flexible shanks are still this level of magnitude more rigid than brain tissue. This  highlights the importance of these efforts in materials sciences and electrical engineering.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;2D readouts help power stabilization algorithm that allows the long-term tracking of specific neurons.&lt;/li&gt;
  &lt;li&gt;The new neuropixels device also features a smaller head-stage.&lt;/li&gt;
  &lt;li&gt;30 kilohertz sampling rate is very high. I wonder if anyone makes the argument that a higher sampling rate could ever be needed. I think at this resolution one could even analyze fast activating channel dynamics.&lt;/li&gt;
  &lt;li&gt;The “pixel” or neuron recording count is predicted to leap 50,000 - 100,000 neurons.
    &lt;ul&gt;
      &lt;li&gt;Big if true.&lt;/li&gt;
      &lt;li&gt;Neuropixels 1 has 1000 recording sites and then Neuropixels 2 has 6000 recording sites, so a projection of 50k is bold.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Overall, the pace of development is astounding but in my opinion “Moore’s law” is a mischaracterization. Here’s why:
    &lt;ul&gt;
      &lt;li&gt;So far we’ve observed one cycle and there was a 6x increase in recording sites, which is technically in line with the trend. However, this characterization of exponential growth would need to be sustained over multiple cycles… I think it is just too early to call.&lt;/li&gt;
      &lt;li&gt;Also, 1.0 and 2.0 don’t have that much of a difference in recording fidelity. 2.0 gets the increase in recording sites using more shanks and better tracking algorithms.&lt;/li&gt;
      &lt;li&gt;While the advent of these areas of development is notable, I wonder if we see sustained progress in these domains or if new features can be added that will enable increasing recording sites in other ways.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Eavesdropping on the Brain With 10,000 Electrodes by Barun Dutta</summary></entry><entry><title type="html">Review 29: Emergence of Coordinated Neural Dynamics Underlies Neuroprosthetic Learning and Skillful Control</title><link href="http://localhost:4000/reviews/review29/" rel="alternate" type="text/html" title="Review 29: Emergence of Coordinated Neural Dynamics Underlies Neuroprosthetic Learning and Skillful Control" /><published>2022-05-28T05:16:13-07:00</published><updated>2022-05-28T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review29</id><content type="html" xml:base="http://localhost:4000/reviews/review29/">&lt;p&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0896627317300405&quot;&gt;Emergence of Coordinated Neural Dynamics Underlies Neuroprosthetic Learning and Skillful Control&lt;/a&gt; by &lt;a href=&quot;https://www.actingbrain.com/vivek-athalye&quot;&gt;Vivek Athalye&lt;/a&gt; and &lt;a href=&quot;https://www2.eecs.berkeley.edu/Faculty/Homepages/carmena.html&quot;&gt;Jose Carmena&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Athalye, Vivek R., et al. “Emergence of coordinated neural dynamics underlies neuroprosthetic learning and skillful control.” Neuron 93.4 (2017): 955-970.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Pretty cool that this article is OA.&lt;/li&gt;
  &lt;li&gt;This work demonstrates how variance decreases in M1 neuronal population during skillful acquistion using brain machine interface (BMI).&lt;/li&gt;
  &lt;li&gt;Intro
    &lt;ul&gt;
      &lt;li&gt;The fact that movement variability decreases across trials during point and click task suggests that there is some population of neurons generating the activity behind stable control.&lt;/li&gt;
      &lt;li&gt;So they try to identify some of these neurons using a BMI recording device attached to around 15 neurons and use mathematical transforms to get low dimensional representation of neural trajectories.&lt;/li&gt;
      &lt;li&gt;Novel task so subjects must start by exploring the action space. But eventually their performance on the task improves. How does this happen?&lt;/li&gt;
      &lt;li&gt;There are three perspectives introduced:
        &lt;ol&gt;
          &lt;li&gt;Independent neuron learning: controller inputs come directly from each neuron.&lt;/li&gt;
          &lt;li&gt;Constrained network learning: controller inputs come from sets of neurons.&lt;/li&gt;
          &lt;li&gt;Flexible network learning: controller inputs comes from a mix of direct activation and set activation.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;Matrix factor analysis will help disambiguate between these approaches.&lt;/li&gt;
      &lt;li&gt;Experiment parameters:
        &lt;ul&gt;
          &lt;li&gt;Variability time scale is ~ 1 second.&lt;/li&gt;
          &lt;li&gt;Decoder time scale is 100 ms.&lt;/li&gt;
          &lt;li&gt;Center out BMI reaching task.&lt;/li&gt;
          &lt;li&gt;Decoder gives upper limb movements to xy cursor position on a screen.
Signal-specific readout space drives activity.
            &lt;ul&gt;
              &lt;li&gt;signal alignment – 0 being subspaces match and 1 being they are orthogonal between epochs.&lt;/li&gt;
              &lt;li&gt;amount of valid signals – how many readout signals actually have valid positions.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Results
    &lt;ul&gt;
      &lt;li&gt;Authors propose variance changes in control happen between neuron private variance and neuron shared variance.&lt;/li&gt;
      &lt;li&gt;And that these can be composed into two covariance factors and that firing rate be the mean.&lt;/li&gt;
      &lt;li&gt;Then we will have $x = \mathcal{N}(\mu, \Sigma^{total} = \Sigma^{shared} + \Sigma^{private})$&lt;/li&gt;
      &lt;li&gt;There is a visualization of the evolution of cursor trajectory which was striking.&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Success rate, % of correct answers increase over trials and the project (workspace position) begins to become increasingly similar to a converged upon representation.
  &lt;img src=&quot;/assets/images/skillful_fig1.png&quot; alt=&quot;bci schematic&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;
  &lt;img src=&quot;/assets/images/skillful_legend1.png&quot; alt=&quot;bci schematic&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;I’m interested in specifically how they generate this low-dimensional representation. I guess they are probably using PCA and this is how they can calculate orthogonality etc. There are a lot of dimensional reduction methods though. I didn’t check the STAR methods.&lt;/li&gt;
      &lt;li&gt;Private variance: diagonal terms. within neuron variance of spike train.&lt;/li&gt;
      &lt;li&gt;Shared variance: off-diagonal covariance that represents the pairwise similarity between binned spike trains.&lt;/li&gt;
      &lt;li&gt;Shared variance increasingly drives movement across trials.&lt;/li&gt;
      &lt;li&gt;Main shared variance begins to align as epochs increase and success rate increases. This suggests that alignment of shared variance in neuron firing rates drives consolidated learning.&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Private variance also aligns and drives cursor movement but more so in the earlier trials.
  &lt;img src=&quot;/assets/images/skillful_fig2.png&quot; alt=&quot;bci schematic&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;
  &lt;img src=&quot;/assets/images/skillful_legend2.png&quot; alt=&quot;bci schematic&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;As such, the authors suggest that the private variance serves an early exploratory role and the shared variance had more contribution on skillful control in support of flexible network learning hypothesis.&lt;/li&gt;
      &lt;li&gt;Main shared space aligns with readout space making shared variance more effective in producing skillful movements.&lt;/li&gt;
      &lt;li&gt;Magnitude growth and re-alignemnt both increase for main shared variance over epochs.
        &lt;ul&gt;
          &lt;li&gt;re-alignment is the distance between successive subspsaces (I think?).&lt;/li&gt;
          &lt;li&gt;Magnitude growth seems like it’s just the magnitude of the shared variance or the magnitude of the readout variance.
  &lt;img src=&quot;/assets/images/skillful3.png&quot; alt=&quot;bci schematic&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Discussion
    &lt;ul&gt;
      &lt;li&gt;Neuroprosthetic learning studies provide intriguing evidence that the brain can solve the credit assignment problem by specifically adapting neurons that contribute to the global error signal provided by the prosthetic cursor.&lt;/li&gt;
      &lt;li&gt;I’m not so surprised that the magnitude of the shared signal norm increases across trials because the BCI reward feedback is likely to introduce some change in the scale of a variance measure.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;blockquote&gt;
      &lt;p&gt;Athalye et al. 2017&lt;/p&gt;
      &lt;blockquote&gt;
        &lt;p&gt;We hypothesize that the population finds this solution by selecting particular shared inputs that produce goal-achieving activity within a characteristic manifold.&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/blockquote&gt;

    &lt;ul&gt;
      &lt;li&gt;BMI manifold emerged that contained consolidated neural trajectories for skillful control.&lt;/li&gt;
      &lt;li&gt;I &lt;strong&gt;really&lt;/strong&gt; like this final quote for a few future reasearch question:
        &lt;blockquote&gt;
          &lt;p&gt;Athalye et al. 2017&lt;/p&gt;
          &lt;blockquote&gt;
            &lt;p&gt;Future decoders might benefit from more detailed models of neural population dynamics and how they change with learning. Indeed, a recent algorithmic approach yielded significant performance improvement by modeling neural population dynamics underlying natural movements to decode the subject’s intent while moving freely (Kao et al., 2015). Perhaps neural learning can help to generalize this approach to immobile patients, as we found coordinated neural dynamics can be consolidated over training in the absence of overt movement. Given our findings that main shared variance achieves better performance than total activity in simulations (Figures S6B–S6D), a performance-motivated extension would be to design a decoder that is able to denoise neural observations based on learned neural dynamics (Shenoy and Carmena, 2014).&lt;/p&gt;
          &lt;/blockquote&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;In my opinion, each sentence here can be taken apart and used to brainstorm future research directions that are related. There is an interesting web of interesting connections here.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Emergence of Coordinated Neural Dynamics Underlies Neuroprosthetic Learning and Skillful Control by Vivek Athalye and Jose Carmena</summary></entry><entry><title type="html">Review 28: Four ethical priorities for neurotechnologies and AI</title><link href="http://localhost:4000/reviews/review28/" rel="alternate" type="text/html" title="Review 28: Four ethical priorities for neurotechnologies and AI" /><published>2022-05-14T05:16:13-07:00</published><updated>2022-05-14T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review28</id><content type="html" xml:base="http://localhost:4000/reviews/review28/">&lt;p&gt;&lt;a href=&quot;https://www.nature.com/articles/551159a&quot;&gt;Four ethical priorities for neurotechnologies and AI
&lt;/a&gt; by &lt;a href=&quot;https://scholar.google.com/citations?user=G0WcJagAAAAJ&quot;&gt;Rafael Yuste&lt;/a&gt; and &lt;a href=&quot;https://phil.washington.edu/people/sara-goering&quot;&gt;Sara Goering&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Yuste, Rafael, et al. “Four ethical priorities for neurotechnologies and AI.” Nature 551.7679 (2017): 159-163.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;While full integration of neurotechnology into human life may take decades, it is critical to think about the ethical applications now.&lt;/li&gt;
  &lt;li&gt;The morningside group is comprised of neurotech companies, academic labs, and intl. brain projects.&lt;/li&gt;
  &lt;li&gt;The existing ethics guidlines, such as Declariation of Helsinki in 1964, Belmont report, and Asilomar AI report, don’t cover many of the issues that are raised by BCI technology.&lt;/li&gt;
  &lt;li&gt;This is a very cool tidbit:
    &lt;blockquote&gt;
      &lt;p&gt;(Yuste &amp;amp; Goering 2017)&lt;/p&gt;
      &lt;blockquote&gt;
        &lt;p&gt;Meanwhile, researchers at Duke University in Durham, North Carolina, have shown that three monkeys with electrode implants can operate as a ‘brain net’ to move an avatar arm collaboratively.&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;&lt;a href=&quot;https://www.nature.com/articles/srep10767&quot;&gt;Link&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;This BrainNet paper is one I am really interested in reading.&lt;/li&gt;
  &lt;li&gt;DARPA Neural Engineering Project that aims to implant 1 million electrodes and selectively stimulates up to 100k neurons. The University of Freiburg in Germany is using EEG signals to decode motor planning activity to control robots.&lt;/li&gt;
  &lt;li&gt;The four ethical priorities:
    &lt;ul&gt;
      &lt;li&gt;Privacy and consent: This concern has been pervasive throughout all types of recent technological advancements. There are many researchers working on what makes a system secure, but keeping data secure has proven to be a comparably large challenge as well. Often times data breaches that would occur in neurotech may use external data to draw connections that might allow them to identify individuals based on neural activity. Furthermore, many potential exploitative practices can extend from the centralization of neural data. The authors pose multiple mitigation strategies, but I really strongly agree with the strategy of not allowing the centralized storage of human neural data from BMI devices. While this may limit how devices can be developed, for now, it seems like a central safeguard from potentially disastrous data breaches.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Agency / Identity: This concern caught me off guard because I hadn’t considered it much at all until I read this. Simply put, BMI devices can blue the line of how much agency they can attribute to certain actions. In this way, BMI devices can interfere with someone’s sense of identity in a negative way. I also found the potential mitigation strategies here less satisfying, although I don’t have any better ideas. I am in support for drafting a constitution of “neurorights” but I don’t see how this would help those with issues in BMI affected identity. Better yet would be a fast safeguard in each device to immediately shut off its functioning if needed. The reason I advocate for this is that the user should have complete autonomy over when they use the device and when it is inactive. This does open the device up to hacking. Also this kind of on/off switch might not be possible due to negative consequences from terminating the tight feedback loop between device and person. Regardless, I generally advocate that BMI functionality should be treated more like glasses and less like a pacemaker so that users will never feel completely trapped with the BMI.&lt;/li&gt;
  &lt;li&gt;Augmentation: This is a very futuristic concern, but also one that should be considered now. At this point, the weaponization and militaristic augmentation of BMI devices are not major concerns. Though in the future they may be. To steer BMI devices on the right path, the authors argue for the establishment of a neurotechnology geneva convention style agreement about what research and applications can be ethically conducted using BMI devices.&lt;/li&gt;
  &lt;li&gt;Bias: Just like ML systems nowadays are biased by negative aspects of their data, such as hate speech in text datasets or lack of representation in image datasets, BMI devices can further perpetuate societal inequalities. To prevent this, it is necessary to open source data, algorithms, user research groups, and design. Through the proper channels, civil liberties and nonprofit auditors should be able to inspect the scientific practices of companies or groups doing neural engineering. Representation of diverse needs and circumstances should be considered in thorough research feature testing, quality testing, and design. Recently, there have been many failures in preventing biased models and disinformation on major technology platforms, so the future for this will be challenging.&lt;/li&gt;
  &lt;li&gt;Moving forward:
    &lt;ul&gt;
      &lt;li&gt;This kind of review provides great directions for moving forward; including widespread adoption of a Hippocratic oath for neuro engineers and ethical discussion sections for labs. While training certainly helps move employees and individuals in the right direction, in my opinion, the field would benefit from the following: (1) Some kind of agency responsible for oversight of responsible use of BMI devices. (2) Forums / conferences / journals for neuroethics. (3) Some kind of open sourced / democratized code for precedents.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Four ethical priorities for neurotechnologies and AI by Rafael Yuste and Sara Goering</summary></entry><entry><title type="html">Review 27: Parsing learning in networks using brain–machine interfaces</title><link href="http://localhost:4000/reviews/review27/" rel="alternate" type="text/html" title="Review 27: Parsing learning in networks using brain–machine interfaces" /><published>2022-05-14T05:16:13-07:00</published><updated>2022-05-14T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review27</id><content type="html" xml:base="http://localhost:4000/reviews/review27/">&lt;p&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0959438817301642?casa_token=mBc7NGX5SMoAAAAA:_u-U4AxlrusxSveU-DitDvaDjvUhYixFrO7ZuZs4B0iIa6Dy0xmDc6Za4MZYRqBFf8E7IiwcVOQ&quot;&gt;Parsing learning in networks using brain-machine
interfaces&lt;/a&gt; by &lt;a href=&quot;https://people.ece.uw.edu/orsborn_amy/&quot;&gt;Amy Orsborn&lt;/a&gt; and &lt;a href=&quot;https://as.nyu.edu/content/nyu-as/as/faculty/bijan-pesaran.html&quot;&gt;Bijan Pesaran&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Orsborn, Amy L., and Bijan Pesaran. “Parsing learning in networks using brain-machine interfaces.” Current opinion in neurobiology 46 (2017): 76-83.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Introduction
    &lt;ul&gt;
      &lt;li&gt;Motor BMIs: repurpose neural activity to control the movement of a device.
        &lt;ul&gt;
          &lt;li&gt;Give the brain a new functionality that the brain can adapt to use.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;BMIs also allow us to study the mechanisms of learning for neuroscience.&lt;/li&gt;
      &lt;li&gt;Yet, while there is work showing how BMIs can enable learning, the above point about the underlying neural mechanisms is still mostly unknown.&lt;/li&gt;
      &lt;li&gt;These BCI papers all have really great figure 1s.
  &lt;img src=&quot;/assets/images/r27_fig1.png&quot; alt=&quot;bci schematic&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;
        &lt;ul&gt;
          &lt;li&gt;This figure presents three different perspectives on closed-loop Motor BCI systems.
            &lt;ul&gt;
              &lt;li&gt;A: This is the main BCI closed-loop and very similar to the previous review.&lt;/li&gt;
              &lt;li&gt;B: Is interesting because it shows the affector/effector dynamics. It is also interesting because it shows that some nodes from the network should send a signal to the actuator while some nodes indirectly signal by not signaling. Finally, it shows that some external reward drives closed-loop BCI learning – which is important because this shows the progression of closed-loop BCI device is dependent on the perceived reward system in the brain.
                &lt;ul&gt;
                  &lt;li&gt;External reward normally just processed through vision. If you control a cursor on a screen successfully you will see that.&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;C: Shows what points can use learning feedback and what learning/error signal they require to improve. BCI closed-loop system can be improved in strategy/selection of motor plans and in the “internal” model… which I take to mean the decoder.
                &lt;ul&gt;
                  &lt;li&gt;As I start to become more specific in my focus on BCI, this kind of distinction can help inform future reading/research directions.&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Interesting point I did not know:
        &lt;blockquote&gt;
          &lt;p&gt;Orsborn et al. 2017&lt;/p&gt;
          &lt;blockquote&gt;
            &lt;p&gt;“visual information is highly dominant over proprioceptive information” &lt;a href=&quot;https://www.science.org/doi/10.1126/science.143.3606.594&quot;&gt;44&lt;/a&gt;&lt;/p&gt;
          &lt;/blockquote&gt;
        &lt;/blockquote&gt;

        &lt;ul&gt;
          &lt;li&gt;I guess this is probably really context-dependent though.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Combining command nodes for BMI in a different way allows researchers to investigate the relationship between BMI learning and natural learning.&lt;/li&gt;
      &lt;li&gt;Figure 2
        &lt;ul&gt;
          &lt;li&gt;Feedback rate and control rate increases both increase success rate for in &lt;a href=&quot;https://www.nature.com/articles/ncomms13825&quot;&gt;Shanechi et al.&lt;/a&gt;.&lt;/li&gt;
          &lt;li&gt;BMIs can investigate sites of learning around probes. For example, optogenetic stimulation near electrode recording sites can help study neural mechanisms of feedback learning.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The conclusion is very concise so I’ll add this final part here.
        &lt;blockquote&gt;
          &lt;p&gt;Orsborn et al. 2017&lt;/p&gt;
          &lt;blockquote&gt;
            &lt;p&gt;Since BMIs tap into our brain’s innate ability to learn, understanding learning in BMIs will ultimately advance clinical applications of this technology. In the search for effective treatments, we may find that interfaces that harness learning can improve the patient experience compared with those which simply accommodate learning.&lt;/p&gt;
          &lt;/blockquote&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Parsing learning in networks using brain-machine interfaces by Amy Orsborn and Bijan Pesaran</summary></entry></feed>