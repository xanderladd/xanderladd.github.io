<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-03-06T19:23:23-08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Alexander Ladd</title><subtitle>An amazing website.</subtitle><author><name>Alexander Ladd</name><email>zladd@berkeley.edu</email></author><entry><title type="html">Review 16: Predictive Coding, Variational Autoencoders, and Biological Connections Pt 3</title><link href="http://localhost:4000/reviews/review17/" rel="alternate" type="text/html" title="Review 16: Predictive Coding, Variational Autoencoders, and Biological Connections Pt 3" /><published>2022-03-04T04:16:13-08:00</published><updated>2022-03-04T04:16:13-08:00</updated><id>http://localhost:4000/reviews/review17</id><content type="html" xml:base="http://localhost:4000/reviews/review17/">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/2011.07464.pdf&quot;&gt;Predictive Coding, Variational Autoencoders,
and Biological Connections&lt;/a&gt; by &lt;a href=&quot;https://joelouismarino.github.io/&quot;&gt;Joseph Marino&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Marino, Joseph. “Predictive coding, variational autoencoders, and biological connections.” Neural Computation 34.1 (2021): 1-44.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Predictive Coding Continued
    &lt;ul&gt;
      &lt;li&gt;A major difference between predictive coding and inference is that predictive coding calculates gradients with backwards (top-down) projections and inference performs updates bottom up (forward pass).&lt;/li&gt;
      &lt;li&gt;Referring to the previous set of note, these learning updates are computed using:
   \(\nabla_{z}\ell(z, \theta) = W^T (\frac{x - W_z }{\sigma_x}) (\frac{x - \mu_z }{\sigma_z})\)&lt;/li&gt;
      &lt;li&gt;The first team represents a local error $\mathcal{e}_x$ and the second term represents and error over the latent variable $\mathcal{e}_z$.&lt;/li&gt;
      &lt;li&gt;Can expand the preivous equations beyond $\sigma_x$ to be multivariate spatial covariance $\Sigma_X$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Predictive Coding, Variational Autoencoders, and Biological Connections by Joseph Marino</summary></entry><entry><title type="html">Review 16: Predictive Coding, Variational Autoencoders, and Biological Connections Pt 2</title><link href="http://localhost:4000/reviews/review16/" rel="alternate" type="text/html" title="Review 16: Predictive Coding, Variational Autoencoders, and Biological Connections Pt 2" /><published>2022-02-26T04:16:13-08:00</published><updated>2022-02-26T04:16:13-08:00</updated><id>http://localhost:4000/reviews/review16</id><content type="html" xml:base="http://localhost:4000/reviews/review16/">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/2011.07464.pdf&quot;&gt;Predictive Coding, Variational Autoencoders,
and Biological Connections&lt;/a&gt; by &lt;a href=&quot;https://joelouismarino.github.io/&quot;&gt;Joseph Marino&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Marino, Joseph. “Predictive coding, variational autoencoders, and biological connections.” Neural Computation 34.1 (2021): 1-44.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Predictive encoding from the perspective of theoretical neuroscience and machine learning.&lt;/li&gt;
  &lt;li&gt;2.3 Variational Inference
    &lt;ul&gt;
      &lt;li&gt;Previously paper introduces $p_{\theta}(x,\mathbf{z})p_{\theta}(x)$ as latent variable models.&lt;/li&gt;
      &lt;li&gt;To get $p_{\theta}(x) = \int p_{\theta}(x,\mathbf{z})d\mathbf{z}$ is often an intractable integral.&lt;/li&gt;
      &lt;li&gt;Variational inference using evidence lower bound optimization (ELBO) $ \mathcal{L}(\mathbf{x}; q, \theta) \leq log p_{\theta}(\mathbf{x})$.&lt;/li&gt;
      &lt;li&gt;ELBO objective:
  \(log p_{\theta}(\mathbf{x} = \mathcal{L}(\mathbf{x}; z, \theta) + KL(q(\mathbf{z} \mid \mathbf{x}) || p_{\theta}(\mathbf{z} \mid \mathbf{x})  )\)&lt;/li&gt;
      &lt;li&gt;Apporaches to optimizing:
        &lt;ul&gt;
          &lt;li&gt;Alternating minimization (EM) between first and second term of ELBO.&lt;/li&gt;
          &lt;li&gt;Computatiional graphn and differentiaion.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Predictive Coding
    &lt;ul&gt;
      &lt;li&gt;Spatiotemporal
        &lt;ul&gt;
          &lt;li&gt;Gaussian autoregessive model over sequences $x_1 … x_t$:
  \(p(x_t \mid x_{1:T}) = \mathcal{N}(x_t; \mu_{x_{\leq t}}, diag(\sigma_{x_{\leq t}^2}))\)
            &lt;ul&gt;
              &lt;li&gt;introduce $y_t \sim \mathcal(0,I) $ as prediction error: $ x_t =  \mu_{x_{\leq t}} + \sigma_{x_{\leq t}^2} \cdot y_t$&lt;/li&gt;
              &lt;li&gt;whitenting transformation shows how this is actually prediction eror: $ y_t = \frac{x_t - \mu_{x_{\leq t}}}{\sigma_{\theta}(x_{\leq t})} $&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Prediticiton error can be measured over spatial dimensions using  autoregressive transform.
            &lt;ul&gt;
              &lt;li&gt;spatial whitening formula $\mathbf{y} = \Sigma_{\theta}^{-1/2}(x - \mathbf{\mu_{\theta}}) $&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Example of predictive coding: fly optic nerve performs autocorrelation of spatiotemporal signals for dyanmic range.&lt;/li&gt;
          &lt;li&gt;Normalization through inhibitory neurons.&lt;/li&gt;
          &lt;li&gt;Photorecptor inhibition to filter unpredicted motion. Ie; object was still in the background but now it is moving.&lt;/li&gt;
          &lt;li&gt;Lateral inihibhition for spatiotemporal normalization.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Hierarchical
        &lt;ul&gt;
          &lt;li&gt;Six layers of neocortex (I - VI)  organized into columns that communicate through interneurons and long range connections vis pyramidal neurons.&lt;/li&gt;
          &lt;li&gt;Neocortical microcircuit w/ forward / backwards, excitatory / inihbitory projections.&lt;/li&gt;
          &lt;li&gt;Theory: backward projections contain predictions and foward projections have error signal.&lt;/li&gt;
          &lt;li&gt;Mathematical formulation of thalamus as an active blackboard that aims to minimize prediction error by Rao &amp;amp; Ballard (1999).
            &lt;ul&gt;
              &lt;li&gt;$p_{\theta}(x \ mid z) = \mathcal{N}(x; f(Wz), diag(\sigma^2_{x}))$&lt;/li&gt;
              &lt;li&gt;$p_{\theta}(z) = \mathcal{N}(x; \mu_{z}, diag(\sigma^2_{z}))$
                &lt;ul&gt;
                  &lt;li&gt;f = elementwise function, w = weight matrix, $\sigma_{x}^2$ and $\sigma_{z}^2$ are the respective variances for $x$ and $z$.&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;MAP estimate of z is $z^*$ which maximizes $p_{\theta}(z \mid x)$.&lt;/li&gt;
              &lt;li&gt;Formulate that as an optimization problem: \(z^* = argmax_{z} ( log(p_{\theta}(x \mid z)) + log p_{\theta}(z) )\)&lt;/li&gt;
              &lt;li&gt;Each term in the above is convex squared error term so the whole thing can be solved analytically with \(\nabla_{z}\ell(z, \theta) = W^T (\frac{x - W_z }{\sigma_x}) (\frac{x - \mu_z }{\sigma_z})\)
                &lt;ul&gt;
                  &lt;li&gt;We can also use the above gradient to solve for $W$ w/ $\nabla_{W}$&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;Under this construction of $\theta(W,z)$ we get learning rules that aim to be biologically plausible by optimizing against physical occurrances, like firing rate or membrane potential. Extending this, the latent variable model (LVM) can be the particular output of a specific cortical column.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Various forms of evidence for this model in different sensory areas of mice, but ultimately, predictive coding is an incomplete theory because most of these models are oversimplified circuit models.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Predictive Coding, Variational Autoencoders, and Biological Connections by Joseph Marino</summary></entry><entry><title type="html">Review 15: Predictive Coding, Variational Autoencoders, and Biological Connections Pt 1</title><link href="http://localhost:4000/reviews/review15/" rel="alternate" type="text/html" title="Review 15: Predictive Coding, Variational Autoencoders, and Biological Connections Pt 1" /><published>2022-02-18T04:16:13-08:00</published><updated>2022-02-18T04:16:13-08:00</updated><id>http://localhost:4000/reviews/review15</id><content type="html" xml:base="http://localhost:4000/reviews/review15/">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/2011.07464.pdf&quot;&gt;Predictive Coding, Variational Autoencoders,
and Biological Connections&lt;/a&gt; by &lt;a href=&quot;https://joelouismarino.github.io/&quot;&gt;Joseph Marino&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Marino, Joseph. “Predictive coding, variational autoencoders, and biological connections.” Neural Computation 34.1 (2021): 1-44.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Predictive encoding from the perspective of theoretical neuroscience and machine learning.&lt;/li&gt;
  &lt;li&gt;Informal defintion for predictive encoding: Neural circuits as probabilistic models of other neurons.
    &lt;ul&gt;
      &lt;li&gt;Inception of this idea in cirucits for sensory processing, like the retina and visual pathways.&lt;/li&gt;
      &lt;li&gt;Feedbackward connections that apply prediction error signal.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.nature.com/articles/nn0199_79&quot;&gt;Rao, Ballard 1999&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;For neuroscience, cybernetics, hemholtz machine, and predictive encoding are the inspiration for Friston 2005 and 2008 work on free energy and active inference.&lt;/li&gt;
  &lt;li&gt;For machine learning, this earlier work in variational inference and encoder-decoder models, culminates in the variational autoencoder.&lt;/li&gt;
  &lt;li&gt;Lots of overlap conceptually, but much of the research between the two fields is divided.&lt;/li&gt;
  &lt;li&gt;The next section is titled connecting predictive coding and VAEs. I take it that these two concepts form the bridge between the fields.
    &lt;ul&gt;
      &lt;li&gt;Just from the intro I like that this paper points two very similar concepts in two different fields and then describes the relationship between the two. I feel that there the’s potential for a lot of discovery in understanding the union and intersection between these two concepts.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Paper posits two possible correspondences between ML and neuro.
    &lt;ul&gt;
      &lt;li&gt;Dendrites of pyramidal neurons and neuronal networks.&lt;/li&gt;
      &lt;li&gt;Lateral inhibition and normalizing flows.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Background info
    &lt;ul&gt;
      &lt;li&gt;MLE
        &lt;ul&gt;
          &lt;li&gt;How can we find some distribution $p_{data}$ using r.v. samples $\bf{x} \sim \hat{p}_{data}(\bf{x})$?&lt;/li&gt;
          &lt;li&gt;Maximizing &lt;strong&gt;log likelihood&lt;/strong&gt; of samples under that distribution. 
  \(\theta^* \longleftarrow argmax_{\theta} \mathbb{E}_{x \sim p_{data}(\bf{x})} [log(p_{theta}(\bf{x}))]\)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Probabilistic models
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;autoregressive models&lt;/strong&gt;: $ p_{\theta(\bf{x})} = \prod_{j=1}^{m} p(\bf{x}_{j} \mid x_{&amp;lt; j} $&lt;/li&gt;
          &lt;li&gt;Can factor out $\bf{x}$ in above as a series of distributions, from $t=1 … T$&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;Latent variable models (LVMs)&lt;/strong&gt;  with $z$ have the joint distribtion: \(p_{\theta}(\bf{x}, \bf{z}) = p_{theta}(\bf{x} \mid z)p_{theta}(\bf{z})\)&lt;/li&gt;
          &lt;li&gt;$\bf{z}$ is being used here to describe $\bf{x}$, incurs computational cost.&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;flow based LVMs&lt;/strong&gt; \(p_{\theta}(\bf{x}) = p_{\theta}(x) \| det(\frac{\partial{\bf{x}}}{\partial{\bf{z}}}) \|^{-1}\)
            &lt;ul&gt;
              &lt;li&gt;Distilling this down to the idea that there if some function $f_{\theta}$ that can transfrom $f_{\theta}(\bf{x}) = \bf{z}, \ f_{\theta}^{-1}(\bf{z}) = \bf{x}$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Can combine the above techniques for &lt;strong&gt;hierachical LVMs&lt;/strong&gt;, &lt;strong&gt;sequential LVMS&lt;/strong&gt; etc.
            &lt;ul&gt;
              &lt;li&gt;An interesting example is stacking latent variables $ \bf{z}^{1:L} = [ \bf{z}_{1} … \bf{z}_{L} ] $ and \(p_{\theta}(\bf{x},\bf{z}^{1:L}) = p_{\theta}(\bf{x}, \bf{z}^{1:L}) \prod_{\ell=1}^{L} p(\bf{z}^{\ell} \mid z^{\ell+1:L})\)&lt;/li&gt;
              &lt;li&gt;I am confused by the conditional probability $ p(\bf{Z^{\ell}} \mid z^{\ell+1:L})$ and the directionality of the hierarchy. Why wouldn’t it go backwards:  $ p(\bf{Z^{\ell}} \mid z^{1:\ell+1})$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Fitting these models
            &lt;ul&gt;
              &lt;li&gt;Log density of unit normal distribution becomes mean squared error.&lt;/li&gt;
              &lt;li&gt;A simple univariate autoregressive model can be formulated as $ p_{\theta}(x_j \mid x_{&amp;lt; j}) = \mathcal{N}(x_j; \mu_{\theta}(x_{&amp;lt; j}), \sigma^2_{\theta}(x_{&amp;lt; j})) $ .
                &lt;ul&gt;
                  &lt;li&gt;I think there’s a minor notation error here that the $x_{&amp;lt; j}$ should be boldface since it is still a vector.&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;Training using the gradient of log likelikehood: $\nabla_{\theta}\mathbb{E}_{\bf{x} \sim p_{data}}[log p_{\theta}(\bf{x})]$&lt;/li&gt;
              &lt;li&gt;Deep autoregressive and variational models can be broken apart by their latent variable impact on the objective with some interesting results.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Variational Inference
        &lt;ul&gt;
          &lt;li&gt;TODO: Left off here section 2.3&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Predictive Coding, Variational Autoencoders, and Biological Connections by Joseph Marino</summary></entry><entry><title type="html">Review 14: Computation Through Neural Population Dynamics Part 2</title><link href="http://localhost:4000/reviews/review14/" rel="alternate" type="text/html" title="Review 14: Computation Through Neural Population Dynamics Part 2" /><published>2022-02-13T04:16:13-08:00</published><updated>2022-02-13T04:16:13-08:00</updated><id>http://localhost:4000/reviews/review14</id><content type="html" xml:base="http://localhost:4000/reviews/review14/">&lt;p&gt;&lt;a href=&quot;https://www.annualreviews.org/doi/pdf/10.1146/annurev-neuro-092619-094115&quot;&gt;Computation Through Neural Population Dynamics&lt;/a&gt; by &lt;a href=&quot;https://smvyas.github.io/&quot;&gt;Saurabh Vyas&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Citation: Vyas, Saurabh, et al. “Computation through neural population dynamics.” Annual Review of Neuroscience 43 (2020): 249-275.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;see &lt;a href=&quot;https://xanderladd.github.io/reviews/review13/&quot;&gt;part 1&lt;/a&gt; if you haven’t.&lt;/li&gt;
  &lt;li&gt;Picking up where I left off: Population Dynamics Underlying Motor Adaptation.
    &lt;ul&gt;
      &lt;li&gt;To shift focus from motor pattern generation to adaption they use a task where cursor movement is offset by a 45 degree counter-clockwise angle and the subject must learn to adapt to the offset of the cursor to get the cursor to the target.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;washout&lt;/strong&gt;: once this adaptation is made, reversing the cursor movement offset causes errors in the opposite direction.&lt;/li&gt;
      &lt;li&gt;Electrical microstimulation during these trials did not affect performance in the trials but afterward. For ML people: stimulation introduces uncertainty so the system reduces its learning rate to temper this uncertainty.&lt;/li&gt;
      &lt;li&gt;Planning, but not execution allowed humans to learn different curl force field (CF) adaptations, like the one described above, as contextual input. Learning does not require dramatic changes to pattern gen. circuitry, but there is a shift between orthogonal subspaces&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Implications of Manifold Structure on Learning
    &lt;ul&gt;
      &lt;li&gt;Hard to casually attribute movements to patterns of neurons, but BCI direct input to movement is helpful.&lt;/li&gt;
      &lt;li&gt;Linear manifold created by BCI movements in unperturbed trials and then add perturbations that require movement outside of this linear manifold. This results in inside/outside intrinsic manifold.&lt;/li&gt;
      &lt;li&gt;Rearranging of prelearned associations to adapt to outside intrinsic manifold.&lt;/li&gt;
      &lt;li&gt;Redefine manifold based on inside/outside prelearned repertoire.&lt;/li&gt;
      &lt;li&gt;RNN modeling approaches show that significant changes to RNN weights are required for out of manifold dynamics.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dynamical Systems in Cognition
    &lt;ul&gt;
      &lt;li&gt;Motor Timing
        &lt;ul&gt;
          &lt;li&gt;State-dependent networks and ramping neurons as time modulation systems.&lt;/li&gt;
          &lt;li&gt;Ready set go tasks show speed modulation in dorsomedial frontal cortex.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Decision Making and Working Memory
        &lt;ul&gt;
          &lt;li&gt;” Context dependence was not a result of traditional gating but rather of dynamics quenching activity along certain directions in state space, achieved via a contextually dependent state space shift.” - Vyas et al. 2020&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;RNN trajectory tunnels force states into stable trajectories.&lt;/li&gt;
      &lt;li&gt;Key insights are that: a) Delayed association in biological circuits can be performed using transient dynamics and b) different regions of state space can subserve different functional roles.&lt;/li&gt;
      &lt;li&gt;the recombination of actions to accomplish a certain task is an important research direction.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Challenges and Opportunities&lt;/li&gt;
  &lt;li&gt;Remaining questions:
    &lt;ul&gt;
      &lt;li&gt;Where do inputs come from and how do they affect local circuit dynamics?&lt;/li&gt;
      &lt;li&gt;What is I/O for a specific brain region?&lt;/li&gt;
      &lt;li&gt;How do brain regions affect each other?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Optogenetic stimulation as a powerful approach for testing CTD model framework.&lt;/li&gt;
  &lt;li&gt;Three steps:
    &lt;ol&gt;
      &lt;li&gt;Continued development of CTD framework.&lt;/li&gt;
      &lt;li&gt;Further research into methodological approaches towards causal predictions.&lt;/li&gt;
      &lt;li&gt;Providing concrete strategies for updating models.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;The first and last steps are very startup-esque. Build and rebuild kind of thing. The second point is a serious epistemological problem.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Computation Through Neural Population Dynamics by Saurabh Vyas</summary></entry><entry><title type="html">Review 13: Computation Through Neural Population Dynamics Part 1</title><link href="http://localhost:4000/reviews/review13/" rel="alternate" type="text/html" title="Review 13: Computation Through Neural Population Dynamics Part 1" /><published>2022-02-04T04:16:13-08:00</published><updated>2022-02-04T04:16:13-08:00</updated><id>http://localhost:4000/reviews/review13</id><content type="html" xml:base="http://localhost:4000/reviews/review13/">&lt;p&gt;&lt;a href=&quot;https://www.annualreviews.org/doi/pdf/10.1146/annurev-neuro-092619-094115&quot;&gt;Computation Through Neural Population Dynamics&lt;/a&gt; by &lt;a href=&quot;https://smvyas.github.io/&quot;&gt;Saurabh Vyas&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Citation: Vyas, Saurabh, et al. “Computation through neural population dynamics.” Annual Review of Neuroscience 43 (2020): 249-275.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Gonna make this a two-part review since this one is a little longer.&lt;/li&gt;
  &lt;li&gt;The dynamic systems approach to population neuron activity is  interesting. I just recently learned about the field called dynamical systems, which is exciting. I had always thought “dynamical system” was an adjective (and it is), but I never imagined they have their own field of mathematical research.
    &lt;ul&gt;
      &lt;li&gt;formal def. of dynamical system: $\frac{dx}{dt} = f(x(t), u(t)) $.&lt;/li&gt;
      &lt;li&gt;$x$ is the neural population response at time $t$ and $u$ is the external input.&lt;/li&gt;
      &lt;li&gt;pendulum as a brief example of a dynamical system.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Move from introduction to the brain as a dynamical system to discussing neuronal population firing trajectory.
    &lt;ul&gt;
      &lt;li&gt;Here they bring up dimensionality reduction as an efficient method for simplifying the case when you have thousands of neuron trajectories and of course this is a valid approach. However, the statement that “we only lose $x$ amount of variance with PCA, so PCA is good” is one I take with a grain of salt. Most data can have most of its variance accounted for by 10 PCs. I don’t think accounted variance means dim. reduction on neural trajectories is a great idea. On the other hand, it’s not likely we’re gonna start looking at all trajectories and find intuitive understanding, so I’ll stop complaining.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Computation through Dynamics (CTD)&lt;/strong&gt; : dynamics of how neural circuit + input evolve through state space.
    &lt;ul&gt;
      &lt;li&gt;underlying all the things we do!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;CTD mathematical intro
    &lt;ul&gt;
      &lt;li&gt;Deep Learning
        &lt;ul&gt;
          &lt;li&gt;Data modeling: use the internal state to find $f$&lt;/li&gt;
          &lt;li&gt;Task modeling: input / output pairs from a task and we wish to identify $f$ that could have possibly led to these pairs.
            &lt;ul&gt;
              &lt;li&gt;Task modeling seems so much harder!&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;RNNs as the neural network / DL approach to solving the $f$ responsible for dynamical systems.
            &lt;ul&gt;
              &lt;li&gt;glad they used the pendulum example to explain this.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;High Dim. Systems
        &lt;ul&gt;
          &lt;li&gt;Linear dynamical system (LDS) : $\frac{dx}{dt} = L(x(t),u(t)) = Ax(t) + Bu(t)$&lt;/li&gt;
          &lt;li&gt;Linear dynamics around fixed points: attractor, repeller, oscillator.&lt;/li&gt;
          &lt;li&gt;Stable orbits / unstable orbits.&lt;/li&gt;
          &lt;li&gt;LDS around fixed point with input: $\frac{d\delta (s)}{dt} = A(x^*,u^*)\delta x(t) + B(x^*,u^*)\delta u(t) $
            &lt;ul&gt;
              &lt;li&gt;$\delta x(t) = x(t) - x^*$ and same for $\delta u(t)$. This just means they have an initial point denoted by $*$ term.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Linear Subspaces and Manifolds
        &lt;ul&gt;
          &lt;li&gt;2D manifold looks like a pringle.&lt;/li&gt;
          &lt;li&gt;Most of this was reviewed, but I did not understand the purpose of figure 6 showing potent space and null space.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dynamical Systems in Motor Control
    &lt;ul&gt;
      &lt;li&gt;What principles guide the generation of the observed time-varying patterns of motor cortical activity?&lt;/li&gt;
      &lt;li&gt;Delay reaching task as an example of a common experimental paradigm for motor preparation.
        &lt;ul&gt;
          &lt;li&gt;CTD views preparatory activity as an initial condition. Not a necessary condition though; Other initial states can have the same motor movement, but being closer to the right one is advantageous for several reasons that they explain.
            &lt;ul&gt;
              &lt;li&gt;Competing hypothesis presented.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;RNN model to try to produce motor activity given preparatory activity.&lt;/li&gt;
          &lt;li&gt;Null spaces as preparation preclude some activity because it is orthogonal to that initial condition.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Dynamical motifs during movement
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;Condition invariant signal&lt;/strong&gt;: signal that follows timing/onset of cue. Large component of population response.
            &lt;ul&gt;
              &lt;li&gt;Roughly, releases the preparatory state from an attractor-like state to a rotating state.&lt;/li&gt;
              &lt;li&gt;The paper with citation (Sussile 2015) that is a “sufficiency test for the rotations motif” seems really interesting. Simple low dim RNN oscillation produced complex inputs/outputs for prep state –&amp;gt; muscle activity.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;A really interesting point is that maybe these oscillating states are inevitable outcomes of basic neuronal firing properties.
            &lt;ul&gt;
              &lt;li&gt;I don’t think asking “when are these oscillating states informative?” is as clear as asking “how informative are these oscillation states?”.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Two similar states –&amp;gt; same movement == tangling. Then the reverse process is untangling.&lt;/li&gt;
          &lt;li&gt;Low degree of trajectory divergence in supplementary motor area (SMA).&lt;/li&gt;
          &lt;li&gt;Summart lost me a (d) - (f). Feels like I missed those later points somewhere in the reading.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Computation Through Neural Population Dynamics by Saurabh Vyas</summary></entry><entry><title type="html">Review 12: Just Ask for Generalization</title><link href="http://localhost:4000/reviews/review12/" rel="alternate" type="text/html" title="Review 12: Just Ask for Generalization" /><published>2022-01-29T04:16:13-08:00</published><updated>2022-01-29T04:16:13-08:00</updated><id>http://localhost:4000/reviews/review12</id><content type="html" xml:base="http://localhost:4000/reviews/review12/">&lt;p&gt;&lt;a href=&quot;https://evjang.com/2021/10/23/generalization.html&quot;&gt;Just Ask for Generalization&lt;/a&gt; by &lt;a href=&quot;https://evjang.com/&quot;&gt;Eric Jang&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Jang 2021&lt;/p&gt;
  &lt;blockquote&gt;
    &lt;p&gt;Generalizing to what you want may be easier than optimizing directly for what you want. We might even ask for “consciousness”.&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;I read this hook and I was immediately into reading the blog. Saying something like “generalizing for consciousness” is engaging. Although it’s a grand claim from the looks of it, it’s a great way to start by saying &lt;em&gt;something&lt;/em&gt;. I think scientists are so careful about the claims they make, that their hooks become boring even in blogs. This is what blogs are for, let it fly! I’m in.&lt;/li&gt;
  &lt;li&gt;The name “grokking” in the double descent phenomenon is weird. The authors could have chosen such a cooler name.
    &lt;ul&gt;
      &lt;li&gt;This is the idea that if you keep training after training loss has converged you can still get better generalization in test data.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Recently, we’ve seen neural networks and ML have a simple narrative. Lots of data, lots of computing, and lots of parameters (high capacity model) can do some great things.
    &lt;ul&gt;
      &lt;li&gt;The blog shows DALL-E which is really an excellent example of generalization in ML.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Interesting transition into the failure of RL to generalize the same way.&lt;/li&gt;
  &lt;li&gt;Setting up Markov Decision Processes (MDP).
    &lt;ul&gt;
      &lt;li&gt;Distribution of actions in states: $p(a \mid s)$, reward: $p(r_t, s_t)$ and transition probabilities $p(s_{t+1} \mid s_t, a_t)$.&lt;/li&gt;
      &lt;li&gt;Goal to maximize $R(\Theta)$ (reward) where theta is a policy over $t_i=1 \longrightarrow t$.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;In RL we don’t know the optimal policy, so we use the experience of the model.&lt;/li&gt;
  &lt;li&gt;The various ways of doing this involve learning updates with gradients of the expected reward. Can learn by sampling policy parameters (CMA-ES), or by gradient guided actions (PPO).&lt;/li&gt;
  &lt;li&gt;There are lots of sources of variance with RL, like the starting position of the agent, non-determinism in the state action transitions. Using an online learning policy incurs more of this variance and researchers need to have a large minibatch to get stable training outcomes.&lt;/li&gt;
  &lt;li&gt;“Offline RL is not as data absorbent as supervised learning”&lt;/li&gt;
  &lt;li&gt;Decision Transformer as an example of generalization in predicting all possible policy trajectories (not just the good ones)&lt;/li&gt;
  &lt;li&gt;There is a lot that can be learned from simply differentiating good from bad policies and D-REX aims to leverage a perturbation kind of approach towards this.&lt;/li&gt;
  &lt;li&gt;The move to begin making conclusions starts with this really cool “just ask for generalization” table.
    &lt;ul&gt;
      &lt;li&gt;Provides the “generalized” version of each RL optimization problem.&lt;/li&gt;
      &lt;li&gt;There are a few, but “watch try learn” is the most interesting to me. The idea of learning a function that learns &lt;em&gt;how learning policies are learned&lt;/em&gt; seems inefficient at first look but is actually very useful.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;To sum some of this up: the generalized approaches change the single trajectory from initial states to one optimal policy to initial states to multiple trajectories.&lt;/li&gt;
  &lt;li&gt;Now blog circles back to that initial flashy point on consciousness.
    &lt;ul&gt;
      &lt;li&gt;Author recommends reading the recipe for consciouesness with a few strong drinks but I’m hung over so a beer will have to do.&lt;/li&gt;
      &lt;li&gt;(roughly) the idea is that by modeling how other agents imitate eachother using optimal / suboptimal policies will require agents to introspect into other agents and this will create a more convincing form of conscious agent.&lt;/li&gt;
      &lt;li&gt;Can a policy recognize itself? I think this is a fascinating question and another step into a unqiue type of machine intelligence that must construct a detailed intermediate of representations of the world through the state space/policy optimization approach.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Just Ask for Generalization by Eric Jang</summary></entry><entry><title type="html">Review 11: The Bandwagon</title><link href="http://localhost:4000/reviews/review11/" rel="alternate" type="text/html" title="Review 11: The Bandwagon" /><published>2022-01-16T04:16:13-08:00</published><updated>2022-01-16T04:16:13-08:00</updated><id>http://localhost:4000/reviews/review11</id><content type="html" xml:base="http://localhost:4000/reviews/review11/">&lt;p&gt;&lt;a href=&quot;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10567741&quot;&gt;The Bandwagon&lt;/a&gt; by &lt;a href=&quot;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1056774&quot;&gt;Claude E. Shannon&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Citation: Shannon, Claude E. “The bandwagon.” IRE transactions on Information Theory 2.1 (1956): 3.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In the intersection of probability, statistics, and engineering, information theory has become applied ubiquitously throughout a wide range of research. In the 1940s, Dr. Claude Shannon conducted some of the most fundamental contributions to this field and has had the fascinating perspective of experiencing the adoption of these computational methods by computer scientists, physicists, and various engineers. Here he makes some disclaimers about the impact of information theory.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;This perspective is perpendicular to the linear thinking that creators have around their algorithms nowadays that goes like this:
    &lt;ol&gt;
      &lt;li&gt;Design algorithm.&lt;/li&gt;
      &lt;li&gt;Show that it is better than methods $X$, $Y$, and $Z$.
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;Advertise&lt;/strong&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Have lots of other researchers and industries use it.
        &lt;ul&gt;
          &lt;li&gt;&lt;em&gt;clone&lt;/em&gt; and &lt;em&gt;star&lt;/em&gt; on github. Community develops around tool or algo.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Make some $, but also get influence and accolades, which also translate to $ /  other generally desired things.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;I’m not saying that this is always the case or that it’s even a bad thing; Simply that there is a regression towards this trend. All we need to do is look at thing like &lt;a href=&quot;https://www.image-net.org/&quot;&gt;ImageNet&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/AlexNet&quot;&gt;AlexNet&lt;/a&gt;, &lt;a href=&quot;https://openai.com/blog/gpt-3-apps/&quot;&gt;GPT3&lt;/a&gt;, &lt;a href=&quot;https://pytorch.org/&quot;&gt;PyTorch&lt;/a&gt;, &lt;a href=&quot;https://www.tensorflow.org/&quot;&gt;Tensorflow&lt;/a&gt; and now &lt;a href=&quot;https://jax.readthedocs.io/en/latest/&quot;&gt;Jax&lt;/a&gt;. All of these things are awesome! There has been so much growth and development of useful things are these technologies. Taking this example further, cryptocurrency, WEB3, and NFTs all also enjoy this kind of advertising by its contributors.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Conversely, Dr. Claude Shannon makes a case &lt;em&gt;against&lt;/em&gt; widespread adoption in this article. He hits back at the idea that the volume of papers published doesn’t represent the progress in the field. In lieu, he advocates for well thought out and carefully experimented research. This kind of suggestion, along with the description as careful experimentation as tedious and slow is surprisingly honest. Simply using the tool from information theory and applying the word “mutual information” or “entropy” doesn’t give the experimental community very much. Shannon is arguing that researchers do not use his methods as a black box to put in A and get some claim about B. The same sentiment is echoed by &lt;a href=&quot;http://bayes.cs.ucla.edu/jp_home.html&quot;&gt;Judea Pearl&lt;/a&gt; on causality. Concepts in this realm of computational explainability are particularly tedious because of the following metaphor. Code in python can be bound to C and C++ and in the same way, probability, math, and English can be smashed together to make a claim or statement. However, the simplicity of the answer often depends on the question. Certain principles of math or probability aren’t enough to characterize all kinds of wild questions a researcher can ask. I think this is the big warning that Shannon has here. Something along the lines of: “I made some hammers, but don’t go using them to dig a hole or write a good book”. The hammer analogy obfuscates the fact that the methods of information theory are &lt;em&gt;not&lt;/em&gt; a black box. They can be tinkered with in various ways and with the right parameterization and use case, they uncover causal relationships that we doing have any other tools to understand intuitively. And speaking of intuitive understanding of information theory… if you are interested, maybe check out &lt;a href=&quot;https://twitter.com/TivadarDanka/status/1475456688547250176&quot;&gt;this twitter thread&lt;/a&gt; that helps me.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">The Bandwagon by Claude E. Shannon</summary></entry><entry><title type="html">Review 10: Beyond advertising: New infrastructures for publishing integrated research objects</title><link href="http://localhost:4000/reviews/review10/" rel="alternate" type="text/html" title="Review 10: Beyond advertising: New infrastructures for publishing integrated research objects" /><published>2022-01-16T04:16:13-08:00</published><updated>2022-01-16T04:16:13-08:00</updated><id>http://localhost:4000/reviews/review10</id><content type="html" xml:base="http://localhost:4000/reviews/review10/">&lt;p&gt;&lt;a href=&quot;https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009651&quot;&gt;Beyond advertising: New infrastructures for publishing integrated research objects&lt;/a&gt; by &lt;a href=&quot;https://elizabeth-dupre.com/#/cv&quot;&gt;Elizabeth DuPre&lt;/a&gt; et al.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Citation: DuPre, Elizabeth, et al. “Beyond advertising: New infrastructures for publishing integrated research objects.” PLOS Computational Biology 18.1 (2022): e1009651.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Introduction
    &lt;ul&gt;
      &lt;li&gt;Discuss current practices in reviewing and publishing a paper, including new forms of curation like openreview and arxivsantiy. Also includes new practices like website hosting and Twitter paper advertising.&lt;/li&gt;
      &lt;li&gt;Presents problem: Researchers have moved online but have not fully embraced web first workflows.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Hybrid Objects
    &lt;ul&gt;
      &lt;li&gt;Hybrid objects are described as an amalgamation of writing, code, computation, data, and documentation.&lt;/li&gt;
      &lt;li&gt;The authors point out the major problem with hybrid objects, at least in regards to the data, which is a lack of data standards in most data publishing platforms.
        &lt;ul&gt;
          &lt;li&gt;And who can blame these data hosting platforms? If they want people to use them, they need looser data standards than their competitors. On the other hand, enforcing and complying to data standards is &lt;em&gt;huge&lt;/em&gt; problem because there are so many different possible formats to have data in (.json, .csv, .dat, .hdf5, .yaml, and the worst: .txt)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;However, following the most prevalent compliant standard for publishing data sets should aid prospects of publication.
        &lt;ul&gt;
          &lt;li&gt;yes this is quite literally conformist.&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;When it comes to data standards having an ecosystem is a very bad thing&lt;/strong&gt;&lt;/li&gt;
          &lt;li&gt;I think the best way to implement data standards is inheritance. You can make instantiations of some broader standard.&lt;/li&gt;
          &lt;li&gt;Though, this problem is a rabbit hole.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Interactive and integrated research objects
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Claerbout Challenge&lt;/strong&gt; is the problem of sharing your whole code/data and env. It always comes with caveats like dependencies that take forever to install.
        &lt;ul&gt;
          &lt;li&gt;“Code provided for reproducibility” is often not as reproducible as we’d like it to be.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Sharing integrated research objects like notebooks is nice approach for this.&lt;/li&gt;
      &lt;li&gt;But then comes the challenge of hosting such objects. So if you make a notebook, where do you put it so that people can engage. (I think github is fine).&lt;/li&gt;
      &lt;li&gt;But this eLife pilot executable research article looks awesome!
        &lt;ul&gt;
          &lt;li&gt;did not know that existed.
            &lt;blockquote&gt;
              &lt;p&gt;DuPre 2022&lt;/p&gt;
              &lt;blockquote&gt;
                &lt;p&gt;We argue that sustainable development demands open standards with multistakeholder governance and leadership to ensure that resulting specifications are not driven by a single stakeholder.&lt;/p&gt;
              &lt;/blockquote&gt;
            &lt;/blockquote&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;This is word soup, but I totally agree with the sentiment. Open standards need to be equitable for all researchers. Python notebooks are great if you use python, but if you only know matlab or R, these formats could cause you a great deal of trouble.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Combining RMarkdown and Jupyter Notebooks seems like an excellent way to present research.
    &lt;ul&gt;
      &lt;li&gt;Though I might sub out RMarkdown for plain old markdown, or even better Jupyter Notebooks native mathjax (basically latex).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Dupre 2022&lt;/p&gt;
  &lt;blockquote&gt;
    &lt;p&gt;By investing in infrastructure for integrated research objects that heavily rely on open, modular components, we can make strong contributions in individual research domains while still ensuring that these investments can be easily retooled and extended.&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;This is a very good sentiment to have for these platforms. Building such components to be equitable across large and small research groups is a difficult challenge as the authors have pointed out. But yes, &lt;a href=&quot;https://www.neurolibre.org/&quot;&gt;NeuroLibre&lt;/a&gt; and &lt;a href=&quot;https://pangeo.io/&quot;&gt;Pangeo&lt;/a&gt; are steps in the right direction.&lt;/li&gt;
  &lt;li&gt;My only real opinion here is that it doesn’t seem to help a paper if it has these integrated objects. I don’t see many reviewers taking this stuff into account, but there should be an incentive for both authors and reviewers to do so. I think this would create more of a community around these tools and then things can build from there. The problem right now is that it is too attractive to publish and then never touch your code again.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Beyond advertising: New infrastructures for publishing integrated research objects by Elizabeth DuPre et al.</summary></entry><entry><title type="html">Review 9: The Sensory Neuron as a Transformer: Permutation-Invariant Neural Networks for Reinforcement Learning</title><link href="http://localhost:4000/reviews/review9/" rel="alternate" type="text/html" title="Review 9: The Sensory Neuron as a Transformer: Permutation-Invariant Neural Networks for Reinforcement Learning" /><published>2022-01-09T04:16:13-08:00</published><updated>2022-01-09T04:16:13-08:00</updated><id>http://localhost:4000/reviews/review9</id><content type="html" xml:base="http://localhost:4000/reviews/review9/">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/2109.02869.pdf&quot;&gt;The Sensory Neuron as a Transformer: Permutation-Invariant Neural Networks for Reinforcement Learning&lt;/a&gt; by &lt;a href=&quot;https://otoro.net/ml/&quot;&gt;Dr. Ha&lt;/a&gt; and &lt;a href=&quot;https://www.linkedin.com/in/yujin-tang-98b3ab5a/?originalSubdomain=jp&quot;&gt;Yujin Tang&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Citation: Tang, Yujin, and David Ha. “The sensory neuron as a transformer: Permutation-invariant neural networks for reinforcement learning.” Advances in Neural Information Processing Systems 34 (2021).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Today, I am reading a paper in NeurIPS by Dr. David Ha and Dr. Yujin Tang.&lt;/li&gt;
  &lt;li&gt;These reviews are not really reviews but more like casual reading notes. I am writing what pops into my head as I read.&lt;/li&gt;
  &lt;li&gt;The first thing that stands out to me just from reading the introduction is that shuffling around sensory input is generally fatal for most network problems. I doubt most image recognition modules would work at all if one just shuffled around 4x4 pixel blocks in an image.
    &lt;ul&gt;
      &lt;li&gt;I can think of a few problems that begin to crop up here.&lt;/li&gt;
      &lt;li&gt;Firstly, if we think about swapping the pixels in a picture of a cat one by one, how many swaps do we need to make until it is just not a picture of a cat.
        &lt;ul&gt;
          &lt;li&gt;This issue is rectified in the paper because they are trying to complete a task or play a game, which means the objective is still definitively the same regardless of input shuffling.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Secondly, how does one parameterize image shuffling? Say we decide to shuffle around $64 x 64$ squares in an image. If we know the image is $256 x 256$ then it makes sense to define $16$ networks. But we’ve cheated and used some a priori knowledge about the image permutations.
        &lt;ul&gt;
          &lt;li&gt;$\frac{256 \times 256}{64 \times 64} = 16$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;But now I start getting ahead of myself, I’ll keep reading and perhaps these issues aren’t relevant. Onward!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;One more thing in the introduction is really surprising/exciting about this. All these references to cellular automata (CA) and emergent behavior makes me really excited to see how these local networks are going to start forming a coherent policy.&lt;/li&gt;
  &lt;li&gt;Self-organizing network agents, while being a mouthful, does seem like a natural progression. I’m having trouble explaining why. I wanted to write something about NNs working better on local computation, but they do seem to do global computation pretty well too. I’m not sure this is the right distinction to make (whether NNs are better as local agents or singular global agents). Also there’s so much more research for the latter.&lt;/li&gt;
  &lt;li&gt;Meta-learning policies
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;fast weights&lt;/strong&gt;: adapt weights to input.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;associative weights&lt;/strong&gt;: allow RNN weights to be attracted to recent hidden states.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;hypernetworks&lt;/strong&gt;: one network generates the weights for another.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Hebbian learning&lt;/strong&gt;: See more &lt;a href=&quot;https://arxiv.org/abs/2002.10585&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Attention
    &lt;ul&gt;
      &lt;li&gt;similar to previous adaptive weight mechanisms in that it modifies weights based on inputs.&lt;/li&gt;
      &lt;li&gt;Authors cite several examples of attention learning inductive biases.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Method
    &lt;ul&gt;
      &lt;li&gt;A legit permutation invariant (PI) agent doesn’t need to be trained on permutations to recognize them.&lt;/li&gt;
      &lt;li&gt;PI formulation: need a function $f(x): \mathcal{R}^N \longrightarrow \mathcal{R}^M$ s.t. $ f(x[x]) f(x)$ where $s$ is some permutation of the indices ${1 … n}$&lt;/li&gt;
      &lt;li&gt;Self-attention as PE.
        &lt;ul&gt;
          &lt;li&gt;Simplest self attention: $\sigma(QK^T)V$ where $Q,K \in \mathcal{R^{n\times d_{q}}}$ and $V \in \mathcal{R^{n\times d_{v}}}$. Q,V and K are query, value and key matrices respectively.&lt;/li&gt;
          &lt;li&gt;Normally these (Q,K,V) are functions of the input.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;contribution
        &lt;ul&gt;
          &lt;li&gt;authors propose to add an extra layer (called AttentionNeuron) in front of agent’s policy network $\pi$ that accepts observation $o_t$ and previous action $a_{t-1}$ as inputs.&lt;/li&gt;
          &lt;li&gt;The $i$th neuron only has access to $o_t[i]$.&lt;/li&gt;
          &lt;li&gt;each sensory neuron computes messages $f_k(o_t[i], a_{t-1})$ and $f_v(o_t[i])$.&lt;/li&gt;
          &lt;li&gt;These messages are aggregated in &lt;em&gt;global latent code&lt;/em&gt; $m_t$.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;So I think it’s interesting that based off the figure, they don’t model this AttentionNeuron layer as a distinct part of each neuron but rather a layer that receives input from each neuron and aggregates input into $m_t$.
        &lt;ul&gt;
          &lt;li&gt;Computationally, it doesn’t matter if the transformation is affixed to the last layer of each neuron or if it stands alone. But I thought it was illustrative of how the Query, Key and Value matrices are formed.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Key matrix depends on $f_k(o_t, a_{t-1})$ and value matrix depends on $f_v(o_t)$&lt;/li&gt;
      &lt;li&gt;They also have projection matrices $W_k, W_v, W_q$ (which is what gives us PE).&lt;/li&gt;
      &lt;li&gt;Experiments and observation space are
        &lt;ul&gt;
          &lt;li&gt;Cartpole $\mathcal R^5$&lt;/li&gt;
          &lt;li&gt;Ant $\mathcal R^28$&lt;/li&gt;
          &lt;li&gt;Car Racing $\mathcal R^{96x96x4}$&lt;/li&gt;
          &lt;li&gt;Atari Pong $\mathcal R^{84x84x4}$
            &lt;ul&gt;
              &lt;li&gt;Car Racing and Atari Pong have dimension $4$ because they are stacked grayscale RGB values.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;They never use more than 196 activation neurons.&lt;/li&gt;
      &lt;li&gt;Also activation neurons do seem to be a function of observation space.&lt;/li&gt;
      &lt;li&gt;Action space ranges from 1 action, to 8 possible actions.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Brief discussion of design choices.
    &lt;ul&gt;
      &lt;li&gt;I wonder what the motivation is for making $QW_q$ learnable instead of input dependent.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;They didn’t use a projection matrix for the Value matrix ($V$)&lt;/li&gt;
  &lt;li&gt;The don’t use RNNs for high dimensional input, just feed forward neural network (FFN).&lt;/li&gt;
  &lt;li&gt;Results
    &lt;ul&gt;
      &lt;li&gt;CartPoleSwingUpHarder
        &lt;ul&gt;
          &lt;li&gt;They compare against a two layer FFN trained with CMA-ES&lt;/li&gt;
          &lt;li&gt;The benchmark agent is able to balance the pole faster under normal circumstances because their method requires a few burn in steps.&lt;/li&gt;
          &lt;li&gt;But what is really notable here is that various peterbutations of shuffling the input or concatenating a noisy vector to the input don’t affect performance. No retraining required!
            &lt;ul&gt;
              &lt;li&gt;Might’ve liked to see a comparison against retrained benchmark.&lt;/li&gt;
              &lt;li&gt;Yes I know it’s comparing apples to oranges and it probably wouldn’t make sense to put in a paper … but I’m curious.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;PyBullet Ant
        &lt;ul&gt;
          &lt;li&gt;Uses pre-trained models and behavior cloning for the benchmark.&lt;/li&gt;
          &lt;li&gt;From table 4 the most notable insights I picked up:
            &lt;ul&gt;
              &lt;li&gt;BC works better with larger subsequent layers.&lt;/li&gt;
              &lt;li&gt;ES shuffled works well on their agent as is. Slightly underperforms non-shuffled input version (FFN teacher). Shuffled FFN gets a really bad score.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Atari Pong
        &lt;ul&gt;
          &lt;li&gt;** shuffled atari pong :)&lt;/li&gt;
          &lt;li&gt;I like the idea of maintaining a spatial representation of the 2D grid in $m_t$ because it is more interpretable.&lt;/li&gt;
          &lt;li&gt;I see that this agent can take a subset of the screen and the authors suggest that would be interesting to conduct some kind of ablation experiment on. While I agree, I am also interested in what would happen if you blacked out part of the screen, thus forcing the agent to hallucinate what is happening in those shuffled blocks.&lt;/li&gt;
          &lt;li&gt;The occluded agent rarely won when it couldn’t see certain blocks, but when the blocks are added back it does well.&lt;/li&gt;
          &lt;li&gt;This is the generalization advantage.&lt;/li&gt;
          &lt;li&gt;Figure 6 is a great example of why keeping 2d spatial embeddings is a nice design. The separability of embedding states based on state space is cool to look at.
            &lt;ul&gt;
              &lt;li&gt;Sometimes when I read these papers, I wonder how they coded some things in. This is one I am particularly interested on.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Car racing
        &lt;ul&gt;
          &lt;li&gt;As I guessed in the beginning, attention-based mechanisms are crippled by shuffling inputs.
            &lt;ul&gt;
              &lt;li&gt;This is shown in AttentionAgent failure to do anything but an original task.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;I have no idea how netRand + AttentionAgent are combined and I don’t understand them pretty well.&lt;/li&gt;
          &lt;li&gt;That said, it’s clear that is the only way to compete with the presented method given new unseen and shuffled racing maps.&lt;/li&gt;
          &lt;li&gt;Ah I spoke too soon… it’s explained below the figure.&lt;/li&gt;
          &lt;li&gt;I see they just add AttentionAgent layer at the end but unfortunately, I don’t understand enough about these methods to say anything else.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Discussion + Conclusion
    &lt;ul&gt;
      &lt;li&gt;Further uses included dynamic input-output mappings in robots or cross-wired systems.
        &lt;ul&gt;
          &lt;li&gt;This isn’t an entirely broad application – it’s a bit specific to systems that receive shuffled inputs.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;However, I think the most important impact of this paper is that it “provides a lens for understanding a transformer as a self-organizing network” in what I felt was a natural way.
        &lt;ul&gt;
          &lt;li&gt;When I read the title, I imagined the authors would need to make more substantial leaps in connecting transformers with a sensory neuron, but now that I’ve read the paper it feels ok.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;One thing I wonder when reading this paper is: what is the best way to aggregate signals from the individual agents? This paper looked at aggregationthrough neural network layers, but I thought the reshape in the 2D spatial embeddingswas an interesting twist.
    &lt;ul&gt;
      &lt;li&gt;Generally, this paper adds some interesting ingredients to a mixture of local -&amp;gt; global computation using distributed agents.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Another thing I really like about this paper is that it isn’t crazy hard to understand. So many ML papers are steeped in lots of formula and notation and this paper truly tried to clearly communicate the message.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">The Sensory Neuron as a Transformer: Permutation-Invariant Neural Networks for Reinforcement Learning by Dr. Ha and Yujin Tang</summary></entry><entry><title type="html">Review 8: The Future of Artificial Intelligence is Self-Organizing and Self-Assembling</title><link href="http://localhost:4000/reviews/review8/" rel="alternate" type="text/html" title="Review 8: The Future of Artificial Intelligence is Self-Organizing and Self-Assembling" /><published>2022-01-02T13:16:13-08:00</published><updated>2022-01-02T13:16:13-08:00</updated><id>http://localhost:4000/reviews/review8</id><content type="html" xml:base="http://localhost:4000/reviews/review8/">&lt;p&gt;&lt;a href=&quot;https://sebastianrisi.com/self_assembling_ai/9&quot;&gt;The Future of Artificial Intelligence is Self-Organizing and Self-Assembling&lt;/a&gt; by &lt;a href=&quot;https://sebastianrisi.com&quot;&gt;Prof. Sebastian Risi&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Citation: Risi, Sebastian. “The Future of Artificial Intelligence is Self-Organizing and Self-Assembling”. sebastianrisi. com (2021): n. pag. Web.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Today I am reading an interesting blog post by Professor Risi, at the &lt;a href=&quot;https://www.itu.dk/&quot;&gt;IT University of Copenhagen&lt;/a&gt;, about self organizing systems and how they can potentially solve some of the problems in developing generalizable AI.&lt;/li&gt;
  &lt;li&gt;The blog post starts by detailing the incredible scale at which systems self-organize. I can’t help but recall an interesting tweet by &lt;a href=&quot;https://twitter.com/plinz?lang=en&quot;&gt;Joscha Bach&lt;/a&gt; that says something to the effect of “it’s computation all the way down”. My interpretation of this saying is that at every level of these complex systems, there are smaller and smaller constituents responsible for performing preceding simpler and simpler computations. In this way, a single ant can be responsible for finding a piece of food and then remembering the path to bring the food back home. However, the delegation of tasks to these ants allows a complex colony of ants to survive and ants are notoriously good at surviving. The problem with computation all the way down, is that the computation solves a simpler problem, but that doesn’t mean the computation itself is simple. This is why I think Prof. Risi brings up a good point in the first paragraph – if we want the benefit of robustness – we’ll need to find efficient training methods.&lt;/li&gt;
  &lt;li&gt;The difference being drawn out between self-assembly and emergence is fascinating. Here’s why I think so. As an engineer (software engineer for the most part), I’ve started to realize how disastrous “over-engineering” is. The more code I have to write in order to extend some system for a simple problem is often a design flaw I made in the past. Amazingly, emergent systems like ants or swarms of insects don’t have this problem since their genetic code sets them up so well to carry out their &lt;em&gt;local&lt;/em&gt; and &lt;em&gt;global&lt;/em&gt; purposes. Historically, we are pretty damn good engineers, but when it comes to endowing our designs with this kind of adaptability, we often come up short. Our work is constantly being replaced, rebuilt, refactored, repurposed.
    &lt;ul&gt;
      &lt;li&gt;These words are inherent to human creations. Nature never refactors. It may replace or repurpose at times, but in the slowest timescale imaginable. Humans are always rushing to get these things done. To get a new version released, to improve state of the art, to hastily revitalize old infrastructure.&lt;/li&gt;
      &lt;li&gt;One caveat to this point is that humans don’t build systems capable of robust adaptation: art. Great artists build things that seem to be constant sources of beauty (or functionality depending on what you expect out of art). For example, the Mona Lisa has been captivating for hundreds of years. Tchaikovsky’s music doesn’t need any refactoring or &lt;em&gt;remixing&lt;/em&gt;. On the other hand, it’s hard to argue that these things have some emergent behavior.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;I wonder how true it is that neural nets can’t generalize very well. I agree with Prof. Risi’s claim, but I think GPT-3 is an interesting counter-example. Sure it’s a giant net, but it can handily craft human-level responses to questions outside of its training data.&lt;/li&gt;
  &lt;li&gt;I will continue reading but these references are hard to ignore!
    &lt;blockquote&gt;
      &lt;p&gt;Vichniac, 1984; Wolfram, 1984; Langton, 1986 qtd. in Risi 2021&lt;/p&gt;
      &lt;blockquote&gt;
        &lt;p&gt;Cellular Automata can aid in the understanding of biological pattern formations, modeling of lattice-based physical systems in percolation and nucleation, and synthesis of artificial life.&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://xanderladd.github.io/research/benchmarking&quot;&gt;My research&lt;/a&gt; involves evolutionary alorithms. So Neural Cellular Automata (NCAs) seem really interesting to me.
    &lt;ul&gt;
      &lt;li&gt;However, the fact that reassembling the Nordic flag causes non-optimal solutions gives a good idea that conquering challenging optimization landscapes can be a real tough problem.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://openreview.net/forum?id=7fFO4cMBx_9&quot;&gt;Variational Neural Cellular Automata&lt;/a&gt; reminds me I need to learn how VAEs work a bit better!&lt;/li&gt;
  &lt;li&gt;Their &lt;a href=&quot;https://sebastianrisi.com/wp-content/uploads/minecraft_short.mp4&quot;&gt;3D Minecraft NCA tree house morphogenesis video&lt;/a&gt; is really cool. I am amazing by the detail of the reconstruction of their algo. Though I’ve never played minecraft.&lt;/li&gt;
  &lt;li&gt;The really interesting part behind their demonstration of locomotive structures is that the interactions are developed at a local level. This kind of interaction structure is the same kind the brain uses.
    &lt;ul&gt;
      &lt;li&gt;For the most part.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The above is confirmed by Prof. Risi here:
    &lt;blockquote&gt;
      &lt;p&gt;Risi 2021&lt;/p&gt;
      &lt;blockquote&gt;
        &lt;p&gt;For example, instead of optimizing the weight parameters of neural networks directly, only meta-learning synapse-specific Hebbian learning rules allows a network to continuously self-organize its weights during the lifetime of the agent (Najarro &amp;amp; Risi, 2020). We found that starting from completely random weights, evolved Hebbian rules enable an agent to navigate a dynamic 2D-pixel environment; likewise, the approach also allows a simulated 3D quadruped to learn how to walk while adapting to some morphological damage not seen during training and in the absence of any explicit reward or error signal in less than 100 timesteps.&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/blockquote&gt;

    &lt;ul&gt;
      &lt;li&gt;Also, the “not seen during training example” &lt;a href=&quot;https://sebastianrisi.com/wp-content/uploads/ant_hebbian2.mp4&quot;&gt;here&lt;/a&gt; is pretty funny as it just flops around.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The author describes several methods of parameter sharing:
    &lt;ol&gt;
      &lt;li&gt;Iteratively merging learning rules
        &lt;ul&gt;
          &lt;li&gt;based on the “genomic bottleneck” (&lt;a href=&quot;https://www.nature.com/articles/s41467-019-11786-6&quot;&gt;Zador 2019&lt;/a&gt;), they drastically reduce parameters by combining rules. (what is k-means being used on?)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Learning learning rules through self-organization
        &lt;ul&gt;
          &lt;li&gt;OK, so this reference to Krisch and Schmidhuber is a must-read. &lt;a href=&quot;https://arxiv.org/abs/2012.14905&quot;&gt;https://arxiv.org/abs/2012.14905&lt;/a&gt;. Basically, small recurrent networks somehow self-organize and learn a global algorithm. Really want to find out more here.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Learning to be robust to unseen and permutated sensory inputs
        &lt;ul&gt;
          &lt;li&gt;Idea here is to add a global controller or attention mechanism to moderate local interactions. This can provide some robustness against variation.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Now time to discuss training. Prof. Risi says this is hard because:
    &lt;ol&gt;
      &lt;li&gt;There is no entity that is essentially fully in charge of the self-organizing system, no engineer at the helm.&lt;/li&gt;
      &lt;li&gt;These systems are chaotic, it’s hard to analytically guide them to stable states. The solutions are non-deterministic and often degenerate to local minima.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;So what can we do?
    &lt;ul&gt;
      &lt;li&gt;Quality Diversity (Pugh et al. 2016)[https://www.frontiersin.org/articles/10.3389/frobt.2016.00040/full] aims to generate a diverse set of solutions instead of only one satisfying solution.&lt;/li&gt;
      &lt;li&gt;Deep learning + Compositional Pattern Producing Networks (CPPNs; Stanley 2007) &lt;a href=&quot;https://arxiv.org/abs/1908.06663&quot;&gt;Reinke et al. 2020,&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;I got lost here. I don’t know what CPNNs do and unfortunately, I already added enough to my reading list for today.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Overall I thought this blog post did a great job of explaining several distinct pros and cons to distributed learning systems. It seems like these methods are becoming an &lt;em&gt;emerging trend&lt;/em&gt; (nod nod wink wink) in machine learning. I think even Geoff Hinton’s work on GLOM (&lt;a href=&quot;https://arxiv.org/pdf/2102.12627.pdf&quot;&gt;Hinton 2020&lt;/a&gt;) has some resemblance to distributed systems. Ultimately, neural networks have done an excellent job of stacking computational units together, but the opportunity for robustness in diverse and locally structured systems is exciting. It’s awesome to see so many examples tying deep learning networks into this concept of self-organizing systems. Outside of evolutionary algorithms, I don’t know much about this stuff but I’ll be following along!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">The Future of Artificial Intelligence is Self-Organizing and Self-Assembling by Prof. Sebastian Risi</summary></entry></feed>