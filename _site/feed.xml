<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-05-01T03:22:23-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Alexander Ladd</title><subtitle>An amazing website.</subtitle><author><name>Alexander Ladd</name><email>zladd@berkeley.edu</email></author><entry><title type="html">Review 25: Plug-and-play control of a brain–computer interface through neural map stabilization</title><link href="http://localhost:4000/reviews/review25/" rel="alternate" type="text/html" title="Review 25: Plug-and-play control of a brain–computer interface through neural map stabilization" /><published>2022-04-30T05:16:13-07:00</published><updated>2022-04-30T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review25</id><content type="html" xml:base="http://localhost:4000/reviews/review25/">&lt;p&gt;&lt;a href=&quot;https://www.nature.com/articles/s41587-020-0662-5&quot;&gt;Plug-and-play control of a brain–computer interface through neural map stabilization
&lt;/a&gt; by &lt;a href=&quot;https://gangulylab.org/people.html&quot;&gt;Daniel Silversmith&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Silversmith, Daniel B., et al. “Plug-and-play control of a brain–computer interface through neural map stabilization.” Nature Biotechnology 39.3 (2021): 326-335.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Having recently read higher level overviews of BCIs, reading this paper in Nature Biotech will be especially relevant but more specfic.&lt;/li&gt;
  &lt;li&gt;Abstract
    &lt;ul&gt;
      &lt;li&gt;180 channel electrocorticography (ECoG) implant in a paralyzed individual enabled stable monitoring of signals.&lt;/li&gt;
      &lt;li&gt;Long term closed loop adaptataion updates decoder weights over several days, thus updating map and plug and play control.
Intro&lt;/li&gt;
      &lt;li&gt;Currently, 30 min daily recalibration results in variability in peformance and decreased decoding performance in the long-term.&lt;/li&gt;
      &lt;li&gt;ECoG PNP control achieved using interface that updates within session instead via closed loop decoder adaptation (CLDA) and potentially over longer terms (ltCDA).
Results&lt;/li&gt;
      &lt;li&gt;Fig. 1
        &lt;ul&gt;
          &lt;li&gt;ECoG signal comes from a few brain reigions: S1, M1 , PMC, PMV, SMA.&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;Kalman Filter&lt;/strong&gt; decoder weights.&lt;/li&gt;
          &lt;li&gt;There are a few aspects that are clearly different between ltCLDA and daily initializaiton:
            &lt;ul&gt;
              &lt;li&gt;Time to taget increased, though it is hard to tell by how much as I can’t see mean values in the intervals.&lt;/li&gt;
              &lt;li&gt;ITR shows clear increase during ltCDA.&lt;/li&gt;
              &lt;li&gt;Convergence of decoder weights is faster using ltCDA.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Time to target decreases from 18 to 6 seconds with tight error bounds.&lt;/li&gt;
          &lt;li&gt;I do not understand box diagram in fig H. Are the outwward pointing arrows for CNS and KF pipeline outputs?&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Weights are general orthogonal at the start of each dailty initializaiton, so pooling weights over days hurt model performance.&lt;/li&gt;
      &lt;li&gt;ltCDA resulted in stable convergence of decoder weights across sessions instead.&lt;/li&gt;
      &lt;li&gt;Higher half life values (history length used in weight updates) led to better fixed control and more stable weight convergence.&lt;/li&gt;
      &lt;li&gt;Some weights exhibiting low magnitude or common trends may be redundant and enables sparseness.&lt;/li&gt;
      &lt;li&gt;Fig. 2
        &lt;ul&gt;
          &lt;li&gt;A lot more variance in decoder map weights for daily initialization method.&lt;/li&gt;
          &lt;li&gt;As the days go on, the orthoganlity of the weights seems to decrease.&lt;/li&gt;
          &lt;li&gt;mu weights decrease w/ linear trends and gamma2 weights increase w/ linear trend.&lt;/li&gt;
          &lt;li&gt;Sparsity / weight pruning is pretty shocking with the 25% of the weights verison having a very similar time to target.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Fig. 3
        &lt;ul&gt;
          &lt;li&gt;Daily calibration had higher circular sd across channels in preferred direction (PD) task.&lt;/li&gt;
          &lt;li&gt;Decoder weight magnitude correlated to circular SD of PD.&lt;/li&gt;
          &lt;li&gt;gamma2 weights are stable from day 36+ and it is visually confirmed.&lt;/li&gt;
          &lt;li&gt;All weights show some trend toward stable convergence after day 18+, which is really interesting because it suggests long term improvment with ltCLDA method.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Fig. 4
        &lt;ul&gt;
          &lt;li&gt;ltCDA to Fixed Decoder swap at day 206 + 28 recovery.&lt;/li&gt;
          &lt;li&gt;both ltCDA and CLDA after reset seem to have stable weights.&lt;/li&gt;
          &lt;li&gt;Decoder weights angle is rougly 45 degress after reset.
  Fig. 5&lt;/li&gt;
          &lt;li&gt;Point and click task where cursor path and bits per second information rate are tracked.&lt;/li&gt;
          &lt;li&gt;Weights seem much sparser for click map.&lt;/li&gt;
          &lt;li&gt;I wonder how they will look for less convergent features.&lt;/li&gt;
          &lt;li&gt;Neural state needs to cross click threshold.&lt;/li&gt;
          &lt;li&gt;Everyday, after cursor is in target area, stable clicking within 1 sec.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;No significant drop in performance during PnP sessions (plug and play = no recalibration).&lt;/li&gt;
      &lt;li&gt;Decoder reinitialization had 45 degree weight angle change but then converge back to 0.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Discussion
    &lt;ul&gt;
      &lt;li&gt;ltCDA is important example of weights being carried over a long time constant.&lt;/li&gt;
      &lt;li&gt;CLDA basd on coadaptation can rapidly allow skilled control.&lt;/li&gt;
      &lt;li&gt;Task related manifolds can be remarkably stable.&lt;/li&gt;
      &lt;li&gt;Results indicate feasibility of PnP.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Plug-and-play control of a brain–computer interface through neural map stabilization by Daniel Silversmith.</summary></entry><entry><title type="html">Review 24:The brain-reading devices helping paralysed people to move, talk and touch</title><link href="http://localhost:4000/reviews/review24/" rel="alternate" type="text/html" title="Review 24:The brain-reading devices helping paralysed people to move, talk and touch" /><published>2022-04-23T05:16:13-07:00</published><updated>2022-04-23T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review24</id><content type="html" xml:base="http://localhost:4000/reviews/review24/">&lt;p&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-022-01047-w?utm_medium=Social&amp;amp;utm_campaign=nature&amp;amp;utm_source=Twitter#Echobox=1650446178&quot;&gt;The brain-reading devices helping paralysed people to move, talk and touch
&lt;/a&gt; by &lt;a href=&quot;http://www.liamdrew.net/about&quot;&gt;Liam Drew&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Brain-computer interface clinical trials for paralysis where the patient uses thoughts to operate a computer application moving a robotic arm.&lt;/li&gt;
  &lt;li&gt;James Johnson, a volunteer for the new neurotech, reports that he can move a mouse on a screen using BCI.&lt;/li&gt;
  &lt;li&gt;Johnson is 1 of 35 individuals who have had a BCI implanted.
    &lt;ul&gt;
      &lt;li&gt;This number seems surprisingly low. I wouldn’t expect more than 1000 though.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Black Rock Neurotech in Salt Lake City, Utah produces a lot of these devices.&lt;/li&gt;
  &lt;li&gt;2006 Landmark paper where Dr. Leigh Hochberg et al. teach a man to move a cursor using robotic arms and was the first of a multicenter set of trials called BrainGate which continues today.&lt;/li&gt;
  &lt;li&gt;Requires decoding algorithms to match neural data to actions.&lt;/li&gt;
  &lt;li&gt;A major goal is to restore motor independence in people who have lost ability in moving their limbs.&lt;/li&gt;
  &lt;li&gt;Bypass central nervous system by directly stimulating muscles responsible for movement.&lt;/li&gt;
  &lt;li&gt;Decoding algorithm improves and patient capacity to interface with the machine improves as well.&lt;/li&gt;
  &lt;li&gt;Richard Anderson leading clinical trials at caltech.&lt;/li&gt;
  &lt;li&gt;A focus of this research is stabilizing the movements.&lt;/li&gt;
  &lt;li&gt;Dr. Edward Chang works on restoring the ability to communicate at UCSF using BCI.&lt;/li&gt;
  &lt;li&gt;40 characters a minute by Shenoy et al. in cursor benchmark.&lt;/li&gt;
  &lt;li&gt;Turning thoughts into type which uses pattern analysis.&lt;/li&gt;
  &lt;li&gt;Chang lab uses sensors planted on the surface of the brain which have a lower resolution but a non-invasive.&lt;/li&gt;
  &lt;li&gt;All BCI companies are aiming to increase bandwidth of communication signals.&lt;/li&gt;
  &lt;li&gt;There is still a long way to go with the technology.&lt;/li&gt;
  &lt;li&gt;Major limitations right now are how long the device will last, how well it will adapt to each user, and if the device will still be supported or used later on down the road.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">The brain-reading devices helping paralysed people to move, talk and touch by Liam Drew.</summary></entry><entry><title type="html">Review 23: Neuropixels 2.0: A miniaturized high-density probe for stable, long-term brain recordings</title><link href="http://localhost:4000/reviews/review23-copy/" rel="alternate" type="text/html" title="Review 23: Neuropixels 2.0: A miniaturized high-density probe for stable, long-term brain recordings" /><published>2022-04-16T05:16:13-07:00</published><updated>2022-04-16T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review23%20copy</id><content type="html" xml:base="http://localhost:4000/reviews/review23-copy/">&lt;p&gt;&lt;a href=&quot;https://www.biorxiv.org/content/10.1101/2020.10.27.358291v1.full.pdf&quot;&gt;Neuropixels 2.0: A miniaturized high-density probe for stable, long-term
brain recordings&lt;/a&gt; by &lt;a href=&quot;http://www.nicksteinmetz.com/#:~:text=Nick%20Steinmetz,and%20cognition%20across%20the%20brain.&quot;&gt;Nick Steinmetz&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper notes for Neuropixels 2.0
    &lt;ul&gt;
      &lt;li&gt;Notably, this is a pretty big collaboration. The following labs participated:
        &lt;ul&gt;
          &lt;li&gt;O’Keefe Lab at UCL&lt;/li&gt;
          &lt;li&gt;Moser Lab at NTNU&lt;/li&gt;
          &lt;li&gt;Lee Lab at Janelia Research&lt;/li&gt;
          &lt;li&gt;Dudman lab at Janelia Research&lt;/li&gt;
          &lt;li&gt;Hausser Lab at UCL&lt;/li&gt;
          &lt;li&gt;Steinmetz Lab at UW&lt;/li&gt;
          &lt;li&gt;Svoboda Lab at Janelia&lt;/li&gt;
          &lt;li&gt;Carandini/ Harris Lab&lt;/li&gt;
          &lt;li&gt;Hantman Lab&lt;/li&gt;
          &lt;li&gt;Haesler Lab&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Neuropixels new probe :
        &lt;ul&gt;
          &lt;li&gt;has over 5000 sites, features&lt;/li&gt;
          &lt;li&gt;has 2 probes and a head stage&lt;/li&gt;
          &lt;li&gt;records at 786 sites at once&lt;/li&gt;
          &lt;li&gt;weighs over 1 gram&lt;/li&gt;
          &lt;li&gt;enables recording from over &amp;gt; 10000 recording sites during free behavior in mice&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Stably recording neurons over days / weeks during long terms processes like learning and memory is challenging, but important for understanding neural coding.&lt;/li&gt;
      &lt;li&gt;Many attempts to record from devices that are flexible and less than $\mu$m in size.
        &lt;ul&gt;
          &lt;li&gt;Paper states that downside to these approaches are: make insertion difficult and do not scale at large numbers of recording sites per shank.&lt;/li&gt;
          &lt;li&gt;I don’t understand how small flexible devices could make insertion more difficult.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;More rigid and larger devices (Utah array, wire tetrodes, silicon probes) record high-quality signals for 8 weeks. However, no consistent recordings of individual neurons over the scale of months.&lt;/li&gt;
      &lt;li&gt;Neuropixels: dense coverage along a line, another array: across a plane.&lt;/li&gt;
      &lt;li&gt;algorithm stabilizes device to brain motion post hoc.&lt;/li&gt;
      &lt;li&gt;two recording channels be simultaneously recorded in the same channel with noise penalty in snr.
        &lt;ul&gt;
          &lt;li&gt;At this point, I realized that there is a lot of past literature about these recording probes that I am missing. This feels like watching avengers before watching all the prequel movies.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Results
        &lt;ul&gt;
          &lt;li&gt;4 shanks, 1280 sites per shank, 5120 total sites.&lt;/li&gt;
          &lt;li&gt;single wide band 14-bit data stream.&lt;/li&gt;
          &lt;li&gt;Hardware switches can swap recording streams enabling recording from thousands of streams/experiment.&lt;/li&gt;
          &lt;li&gt;can cover a plan of 750 x 720 $\mu$m during recording.&lt;/li&gt;
          &lt;li&gt;Fig. 1
            &lt;ul&gt;
              &lt;li&gt;Neuropixels 2.0 is much less wide than the previous version.&lt;/li&gt;
              &lt;li&gt;Shows LFP recording and spike waveform recording (overlapping channels).&lt;/li&gt;
              &lt;li&gt;Probe rasters and reproduced raster of dorsal striatum firing pattern across ten trials.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;7 / 8  probes recovered in working condition.&lt;/li&gt;
          &lt;li&gt;max time recording from implant: 309 days.&lt;/li&gt;
          &lt;li&gt;Fig 2.
            &lt;ul&gt;
              &lt;li&gt;the proportion of spikes has a decaying distribution over the # of days after implant. A similar trend is shown in C. and D.&lt;/li&gt;
              &lt;li&gt;hippocampus has a high proportion of firing neurons.&lt;/li&gt;
              &lt;li&gt;comparison of spike recording stats between labs that used the device.
                &lt;ul&gt;
                  &lt;li&gt;I think this plot is hard to interpret because I know there are different conditions for each lab so plot does not necessarily show apples to apples.&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Paper claims brain motion leads to progressively less spikes during the duration of a recording.&lt;/li&gt;
          &lt;li&gt;But they have an unsupervised learning algorithm to adjust for motion post hoc and re-detect spikes. This method increases recording stability (3E).&lt;/li&gt;
          &lt;li&gt;Fig 3.
            &lt;ul&gt;
              &lt;li&gt;The results from this stabilization procedure a visually very convincing.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Now they expand the timescale alignment to long intervals.
            &lt;ul&gt;
              &lt;li&gt;successful tracking across days, and weeks (figure 4). 83% tracking accuracy after 9 weeks.&lt;/li&gt;
              &lt;li&gt;wonder what that accuracy is across more than three months? But tracking 83% of neurons seems really good.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Average signals from two sites along a recording line and then decompose them.&lt;/li&gt;
          &lt;li&gt;Fig 4
            &lt;ul&gt;
              &lt;li&gt;bank 1 and bank 2 separated to two sets of neurons and the switch helps record mapping between banks using mismatch.&lt;/li&gt;
              &lt;li&gt;when both banks are recording noise is lower.&lt;/li&gt;
              &lt;li&gt;3 configurations: both banks on, bank 1 on, bank 2 on.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Neuropixels 2.0: A miniaturized high-density probe for stable, long-term brain recordings by Nick Steinmetz.</summary></entry><entry><title type="html">Review 21: Cracking the Neural Code in Humans</title><link href="http://localhost:4000/reviews/review21/" rel="alternate" type="text/html" title="Review 21: Cracking the Neural Code in Humans" /><published>2022-04-02T05:16:13-07:00</published><updated>2022-04-02T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review21</id><content type="html" xml:base="http://localhost:4000/reviews/review21/">&lt;p&gt;&lt;a href=&quot;https://www.simonsfoundation.org/2022/03/29/cracking-the-neural-code-in-humans/&quot;&gt;Cracking the Neural Code in Humans
&lt;/a&gt; by &lt;a href=&quot;https://www.simonsfoundation.org/people/emily-singer/&quot;&gt;Emily Singer&lt;/a&gt; at the Simons Foundation.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Neuropixels: high resolution brain recording from implanted electrodes.&lt;/li&gt;
  &lt;li&gt;Until recently Neuropixel devices are only used on primates and rodents, but now they can be used in people thanks to Dr. Paulk and Dr. Cash at &lt;a href=&quot;https://cashlab.mgh.harvard.edu/people/&quot;&gt;Cashlab&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Neural recordings for brain computer interfaces are researched in clinical trials due to the risks associated with implantable electrodes.&lt;/li&gt;
  &lt;li&gt;However further development of the decoding that can be performed at various resolutions helps inform new and more effective BCI.&lt;/li&gt;
  &lt;li&gt;Short, fast, and simple tasks may help understand neural coding at a more basic level.&lt;/li&gt;
  &lt;li&gt;Primary application is that the user would control a robotic arm or robotic device that responds to decoded brain activity.&lt;/li&gt;
  &lt;li&gt;Utah microelectrode array as the leading measurement device for 7 years.&lt;/li&gt;
  &lt;li&gt;RNN Decoder translates Neural activity from 200 neurons into characters at rate of 90 characters per minute.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Shenoy 2022&lt;/p&gt;
  &lt;blockquote&gt;
    &lt;p&gt;Your brain is actually issuing more information per second when you handwrite than when you make a straight line. That increased complexity made it easier to quickly decode the intended letter — and offers new opportunities for exploring neural coding,”&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Dr. Pandarinath researchers fast finger movements, unlike commonly researched reaching and grasping movements.&lt;/li&gt;
  &lt;li&gt;Dr. Stavisky and Dr. Shenoy are able to reliably deocde speech related neural activity from handknob area in people who can’t move their hands but can still speak.&lt;/li&gt;
  &lt;li&gt;Still the question of what machinery is used for what task is outstanding. It will be hard to map areas even between common tasks like walking and running.&lt;/li&gt;
  &lt;li&gt;Lower dimension manifolds for interpreting neural recodings.&lt;/li&gt;
  &lt;li&gt;Neuropixels code and data are public.&lt;/li&gt;
  &lt;li&gt;Dr. Paulk says diversity of waveforms produced is a new and surprising result.&lt;/li&gt;
  &lt;li&gt;There still exist significant engineering challenges around neuropixels, like how to stablize the device and transmit data.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Cracking the Neural Code in Humans by Emily Singer at the Simons Foundation.</summary></entry><entry><title type="html">Review 20: Trends in Computational Neuroscience: Cosyne 2022</title><link href="http://localhost:4000/reviews/review20/" rel="alternate" type="text/html" title="Review 20: Trends in Computational Neuroscience: Cosyne 2022" /><published>2022-03-25T05:16:13-07:00</published><updated>2022-03-25T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review20</id><content type="html" xml:base="http://localhost:4000/reviews/review20/">&lt;p&gt;&lt;a href=&quot;https://saberatalukder.com/cosyne_2022_computational_and_systems_neuroscience_in_review.html&quot;&gt;Trends in Computational Neuroscience: Cosyne 2022
&lt;/a&gt; by &lt;a href=&quot;https://saberatalukder.com/index.html&quot;&gt;Sabera Talukder&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I couldn’t go to Cosyne but it’s a workshop/conference I’d like to go to one day so I wanted to get the inside scoop of what gets discussed.&lt;/li&gt;
  &lt;li&gt;Fortunately, this blog kept me in the loop, so that’s pretty cool.&lt;/li&gt;
  &lt;li&gt;Notes:&lt;/li&gt;
  &lt;li&gt;Major Trends
    &lt;ul&gt;
      &lt;li&gt;Behavior
        &lt;ul&gt;
          &lt;li&gt;Especially w.r.t. software, data analysis pipelines and pose tracking estimation.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Comparing ANNs to Biologically realistic NN
        &lt;ul&gt;
          &lt;li&gt;I didn’t have FOMO hearing about behavior, but now I do.&lt;/li&gt;
          &lt;li&gt;One-to-one biological to neural network comparison.&lt;/li&gt;
          &lt;li&gt;Generative modeling neural data with latent representation.
            &lt;ul&gt;
              &lt;li&gt;This one has important impact on neuroengineering.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Biological rules with ML tasks.
            &lt;ul&gt;
              &lt;li&gt;This is one is interesting because I’d like to see how well biologically realistic credit assignment matches up against SOTA methods for MNIST.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;network similarity: how can you tell the distance between two nets?&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Dimensionality Reduction
        &lt;ul&gt;
          &lt;li&gt;This one trend shows that PCA, UMAP, and tSNE can be improved upon to get low dim. representations that do not warp local and/or global distance. Ah, the curse of dimensionality.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Data Scaling
        &lt;ul&gt;
          &lt;li&gt;How to curate / record / assay large experiments for high throughput data?&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;I liked the writing / blog style because it was interesting to read and broke the monotony from reading papers.&lt;/li&gt;
  &lt;li&gt;It was also a concise read so I could read the whole thing instead of skimming. Also packed with a bunch of info about applications of key themes.&lt;/li&gt;
  &lt;li&gt;To me, it’s really exciting to see a conference where ANNs are compared to biological NNs because I find the two topics: generative modeling and biological nets on ML tasks to be interesting because of their relation to eachother. Both tasks seem to be two sides of the neural network coin. For the generative modeling task we are applying nets to better understand the brain and in the ML task we are trying to borrow the brain to make better ML models.&lt;/li&gt;
  &lt;li&gt;Can’t wait to see how these topics unfold in future conferences since I think they’ll have important impact on brain computer interfaces and autonomous control in robotics.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Trends in Computational Neuroscience: Cosyne 2022 by Sabera Talukder</summary></entry><entry><title type="html">Review 19: Let us never speak of these values again.</title><link href="http://localhost:4000/reviews/review19/" rel="alternate" type="text/html" title="Review 19: Let us never speak of these values again." /><published>2022-03-20T05:16:13-07:00</published><updated>2022-03-20T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review19</id><content type="html" xml:base="http://localhost:4000/reviews/review19/">&lt;p&gt;&lt;a href=&quot;https://www.argmin.net/2022/02/23/standard-errors/&quot;&gt;Let us never speak of these values again.&lt;/a&gt; by &lt;a href=&quot;https://www.argmin.net/&quot;&gt;Ben Recht&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;This blog covers the utiliy of statistical signifigance measures like effect size and p value.&lt;/li&gt;
  &lt;li&gt;The range of success of claims is predicated off of a ratio of effect size to standard error.&lt;/li&gt;
  &lt;li&gt;Exposes that fact that signifigance is weighted by the spread of probability denisty. Meaning that if there is a slightly favorable outcome with a small PDF and one with a more favorable average outcome but larger PDF, the former may be favored by the p-value.&lt;/li&gt;
  &lt;li&gt;Simple approximations can distort this p-value. Esp. when it comes to averageing across groups.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;Most practicing scientists would be better off not knowing what a p-value is.&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;This leads to the philosophical problem here: how can we really trust the effect size is valid. This is made challenging by varying levels of validity:
    &lt;ul&gt;
      &lt;li&gt;study design is valid?&lt;/li&gt;
      &lt;li&gt;hypothesis testing is valid?&lt;/li&gt;
      &lt;li&gt;claims are valid?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;I think the third bullet is especially hard. How can you best gurantee performance on an unsen input/output?&lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Let us never speak of these values again. by Ben Recht</summary></entry><entry><title type="html">Review 18: Deep Learning Is Hitting a Wall</title><link href="http://localhost:4000/reviews/review18/" rel="alternate" type="text/html" title="Review 18: Deep Learning Is Hitting a Wall" /><published>2022-03-13T05:16:13-07:00</published><updated>2022-03-13T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review18</id><content type="html" xml:base="http://localhost:4000/reviews/review18/">&lt;p&gt;&lt;a href=&quot;https://nautil.us/deep-learning-is-hitting-a-wall-14467/&quot;&gt;Deep Learning is Hitting a Wall&lt;/a&gt; by &lt;a href=&quot;https://en.wikipedia.org/wiki/Gary_Marcus&quot;&gt;Gary Marcus&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Marcus, Gary. “Deep Learning is Hitting a Wall” natuil.us (2022).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I’ve been writing all day and I am struggling, but reading this is a breath of fresh air. It is well written and easy to read.&lt;/li&gt;
  &lt;li&gt;Marcus claims the AI/ML hype from 2005-2016 has overpromised.&lt;/li&gt;
  &lt;li&gt;We can see it is deployed all the time in low risk and mundane tasks, but we don’t see it often deployed in high risk situations.
    &lt;ul&gt;
      &lt;li&gt;Self-driving being the mos ubiqitiously deployed ML but it requires human oversight.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Large ML language models show  examples of failing to form any underlying conceptual understanding of what the words in the prompt/generation structure mean.&lt;/li&gt;
  &lt;li&gt;Many have touted ML scaling laws, stating that more data and larger models with continue to improve.
    &lt;ul&gt;
      &lt;li&gt;This improvement may be bounded.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Explicit symbol manipulation has been benished from the kingdom of AI.&lt;/li&gt;
  &lt;li&gt;I like that the author focuses on trustworthiness and relibility models instead of accuracy. At the end of the day, humans don’t care about RMSE, we care about the impact it has on  our lives.&lt;/li&gt;
  &lt;li&gt;Background on symbolic AI as codes to represent information. Like bits for example.
    &lt;ul&gt;
      &lt;li&gt;More background about symbol manipulation through explaining computer programs, variable assignment etc.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Google search as a great example of effective symbolic AI.&lt;/li&gt;
  &lt;li&gt;The autor discuss the background of deep learning rise to fame over symbolic AI involving several key points in the 80s-2010s where certain leading researchers eschewed statements and made claims about which approach has the most merits.&lt;/li&gt;
  &lt;li&gt;Some motivations for moving back to some ideas in symbol based AI:
    &lt;ul&gt;
      &lt;li&gt;Recipe argument: so many things we do are procedural, conditioned. Symbolic AI can better represent this knowledge.&lt;/li&gt;
      &lt;li&gt;Black box: this is the famous DL is a black box argument. I think of this argument as technical debt. You build something capable of doing great things but can’t explicitly explain why it works.&lt;/li&gt;
      &lt;li&gt;Silo arguement: most of the AI capabilities from image detection to NLP are siloed to their own domain. Integrating knowledge from mutiple domains can lead to more general forms of intelligence.&lt;/li&gt;
      &lt;li&gt;Neural networks can’t do addition.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;I think these arguments are well reseasoned and I don’t eschew symbolic AI by any means. However, the question in my mind, is how much symbolism from symbolic AI needs to be introduced.
    &lt;blockquote&gt;
      &lt;p&gt;qtd.  Marcus 2022&lt;/p&gt;
      &lt;blockquote&gt;
        &lt;p&gt;Artur Garcez and Luis Lamb wrote a manifesto for hybrid models in 2009, called Neural-Symbolic Cognitive Reasoning.&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;Added to my reading list&lt;/li&gt;
  &lt;li&gt;New developments in Symbolic AI
    &lt;ul&gt;
      &lt;li&gt;Alphafold&lt;/li&gt;
      &lt;li&gt;AlphaGO&lt;/li&gt;
      &lt;li&gt;Deepmind chess&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Cognition and intelligence is many things and trying to fit them all into feedfoward net w/ backprop is not rational.&lt;/li&gt;
  &lt;li&gt;End with quote:&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;qtd.  Marcus 2022&lt;/p&gt;
  &lt;blockquote&gt;
    &lt;p&gt;With all the challenges in ethics and computation, and the knowledge needed from fields like linguistics, psychology, anthropology, and neuroscience, and not just mathematics and computer science, it will take a village to raise to an AI. We should never forget that the human brain is perhaps the most complicated system in the known universe; if we are to build something roughly its equal, open-hearted collaboration will be key&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Deep Learning is Hitting a Wall by Gary Marcus</summary></entry><entry><title type="html">Review 17: Predictive Coding, Variational Autoencoders, and Biological Connections Pt 3</title><link href="http://localhost:4000/reviews/review17/" rel="alternate" type="text/html" title="Review 17: Predictive Coding, Variational Autoencoders, and Biological Connections Pt 3" /><published>2022-03-04T04:16:13-08:00</published><updated>2022-03-04T04:16:13-08:00</updated><id>http://localhost:4000/reviews/review17</id><content type="html" xml:base="http://localhost:4000/reviews/review17/">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/2011.07464.pdf&quot;&gt;Predictive Coding, Variational Autoencoders,
and Biological Connections&lt;/a&gt; by &lt;a href=&quot;https://joelouismarino.github.io/&quot;&gt;Joseph Marino&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Marino, Joseph. “Predictive coding, variational autoencoders, and biological connections.” Neural Computation 34.1 (2021): 1-44.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Predictive Coding Continued
    &lt;ul&gt;
      &lt;li&gt;A major difference between predictive coding and inference is that predictive coding calculates gradients with backwards (top-down) projections and inference performs updates bottom up (forward pass).&lt;/li&gt;
      &lt;li&gt;Referring to the previous set of note, these learning updates are computed using:
   \(\nabla_{z}\ell(z, \theta) = W^T (\frac{x - W_z }{\sigma_x}) (\frac{x - \mu_z }{\sigma_z})\)&lt;/li&gt;
      &lt;li&gt;The first team represents a local error $\mathcal{e}_x$ and the second term represents and error over the latent variable $\mathcal{e}_z$. These terms modulate the gain of each error. The paper mentions that they are related to attention and cites Feldman &amp;amp; Friston, 2010. Without any background, I can’t see obviously how the error over the latent variable $z$ could be related to attention.&lt;/li&gt;
      &lt;li&gt;Can expand the preivous equations beyond $\sigma_x$ to be multivariate spatial covariance $\Sigma_X$.&lt;/li&gt;
      &lt;li&gt;Empirical support for predictive coding.
        &lt;ul&gt;
          &lt;li&gt;Fitting retinal cell ganglion cells processes using spatial whitening kernel.&lt;/li&gt;
          &lt;li&gt;Hierachial: top down signals can alter traditional receptive fields.&lt;/li&gt;
          &lt;li&gt;Sensory cortex as engaged in hierarchical prediction of spatial / temporal domain.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Variational Auteoencoders
    &lt;ul&gt;
      &lt;li&gt;Deep network latent variable models trained using variational inference.
        &lt;ul&gt;
          &lt;li&gt;Breaking this down:
            &lt;ul&gt;
              &lt;li&gt;deep network - stacked layers of units / artifical neurons that perform linear transformations to the signal as it feeds forward.&lt;/li&gt;
              &lt;li&gt;latent variable -  some random variables (noramlly denoted as $z$) which will be part of the model parameterizaiton. To me, an interesting intuition to thinking about latent variables is that they create a low dimensional subspace that bottlenecks the information from higher dimensional inputs / layers.&lt;/li&gt;
              &lt;li&gt;using variational inference - this one was covered in the previous blog.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Optimizing conditional likelihood of latent variable requires differentiating the latent variable. This is tricky because the latent variable is sampled from a  normal distribution. How can we tune the parameters of this distribution &lt;em&gt;and&lt;/em&gt; the network? To do this we need to use the reparameterization trick. For brevity I am not going to cover in this blog. This allows us to train a network that gives latent variable vector $\mathbf{z}$, thus an autoencoder.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Connections and Comparisions
    &lt;ul&gt;
      &lt;li&gt;Main connection: both are hierachcial latent variable models.
        &lt;ul&gt;
          &lt;li&gt;Also, both preditive coding and VAEs rely on nonlinear connections between levels and covariance relationship between levels.
            &lt;ul&gt;
              &lt;li&gt;IMO, this is the really impressive part about VAE and why it’s so relevant for Neuroscience. It is well known that human NNs have nonlinear synaptic connectivty, but I think it’s less clear (at least for the layman) that levels of cortical connectiviy might covary. But we know, especically from researching attention, that this is true. This is why VAE’s are becoming my favorite brain inspired ML model! Although, credit assignment is still an outstanding issue.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Inference: both methods perform inference but using diffeent optimization techniques (predictive: gradient, vae: amortized). (see last two reviews and previous section about optimizing VAE)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Author aligns VAE and cortical network on the level of a network of pyramidal neuron dendrites.
        &lt;ul&gt;
          &lt;li&gt;I don’t know why this alignment is against dendrites. Why not against the entire neuron (axon, soma, etc.)&lt;/li&gt;
          &lt;li&gt;Ok acutally I do think I know why: it’s because these networks mainly integrate signal. Or at least it’s easier to make the comparison they are integrating signal rather than integrating the signal and propogating it.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Normalizing flows, which is mentioned in the paper, but not this blog, is compared to lateral neurons / lateral inhibition.
        &lt;ul&gt;
          &lt;li&gt;I am generally making this note for myself to remember this.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Predictive Coding, Variational Autoencoders, and Biological Connections by Joseph Marino</summary></entry><entry><title type="html">Review 16: Predictive Coding, Variational Autoencoders, and Biological Connections Pt 2</title><link href="http://localhost:4000/reviews/review16/" rel="alternate" type="text/html" title="Review 16: Predictive Coding, Variational Autoencoders, and Biological Connections Pt 2" /><published>2022-02-26T04:16:13-08:00</published><updated>2022-02-26T04:16:13-08:00</updated><id>http://localhost:4000/reviews/review16</id><content type="html" xml:base="http://localhost:4000/reviews/review16/">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/2011.07464.pdf&quot;&gt;Predictive Coding, Variational Autoencoders,
and Biological Connections&lt;/a&gt; by &lt;a href=&quot;https://joelouismarino.github.io/&quot;&gt;Joseph Marino&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Marino, Joseph. “Predictive coding, variational autoencoders, and biological connections.” Neural Computation 34.1 (2021): 1-44.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Predictive encoding from the perspective of theoretical neuroscience and machine learning.&lt;/li&gt;
  &lt;li&gt;2.3 Variational Inference
    &lt;ul&gt;
      &lt;li&gt;Previously paper introduces $p_{\theta}(x,\mathbf{z})p_{\theta}(x)$ as latent variable models.&lt;/li&gt;
      &lt;li&gt;To get $p_{\theta}(x) = \int p_{\theta}(x,\mathbf{z})d\mathbf{z}$ is often an intractable integral.&lt;/li&gt;
      &lt;li&gt;Variational inference using evidence lower bound optimization (ELBO) $ \mathcal{L}(\mathbf{x}; q, \theta) \leq log p_{\theta}(\mathbf{x})$.&lt;/li&gt;
      &lt;li&gt;ELBO objective:
  \(log p_{\theta}(\mathbf{x} = \mathcal{L}(\mathbf{x}; z, \theta) + KL(q(\mathbf{z} \mid \mathbf{x}) || p_{\theta}(\mathbf{z} \mid \mathbf{x})  )\)&lt;/li&gt;
      &lt;li&gt;Apporaches to optimizing:
        &lt;ul&gt;
          &lt;li&gt;Alternating minimization (EM) between first and second term of ELBO.&lt;/li&gt;
          &lt;li&gt;Computatiional graphn and differentiaion.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Predictive Coding
    &lt;ul&gt;
      &lt;li&gt;Spatiotemporal
        &lt;ul&gt;
          &lt;li&gt;Gaussian autoregessive model over sequences $x_1 … x_t$:
  \(p(x_t \mid x_{1:T}) = \mathcal{N}(x_t; \mu_{x_{\leq t}}, diag(\sigma_{x_{\leq t}^2}))\)
            &lt;ul&gt;
              &lt;li&gt;introduce $y_t \sim \mathcal(0,I) $ as prediction error: $ x_t =  \mu_{x_{\leq t}} + \sigma_{x_{\leq t}^2} \cdot y_t$&lt;/li&gt;
              &lt;li&gt;whitenting transformation shows how this is actually prediction eror: $ y_t = \frac{x_t - \mu_{x_{\leq t}}}{\sigma_{\theta}(x_{\leq t})} $&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Prediticiton error can be measured over spatial dimensions using  autoregressive transform.
            &lt;ul&gt;
              &lt;li&gt;spatial whitening formula $\mathbf{y} = \Sigma_{\theta}^{-1/2}(x - \mathbf{\mu_{\theta}}) $&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Example of predictive coding: fly optic nerve performs autocorrelation of spatiotemporal signals for dyanmic range.&lt;/li&gt;
          &lt;li&gt;Normalization through inhibitory neurons.&lt;/li&gt;
          &lt;li&gt;Photorecptor inhibition to filter unpredicted motion. Ie; object was still in the background but now it is moving.&lt;/li&gt;
          &lt;li&gt;Lateral inihibhition for spatiotemporal normalization.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Hierarchical
        &lt;ul&gt;
          &lt;li&gt;Six layers of neocortex (I - VI)  organized into columns that communicate through interneurons and long range connections vis pyramidal neurons.&lt;/li&gt;
          &lt;li&gt;Neocortical microcircuit w/ forward / backwards, excitatory / inihbitory projections.&lt;/li&gt;
          &lt;li&gt;Theory: backward projections contain predictions and foward projections have error signal.&lt;/li&gt;
          &lt;li&gt;Mathematical formulation of thalamus as an active blackboard that aims to minimize prediction error by Rao &amp;amp; Ballard (1999).
            &lt;ul&gt;
              &lt;li&gt;$p_{\theta}(x \ mid z) = \mathcal{N}(x; f(Wz), diag(\sigma^2_{x}))$&lt;/li&gt;
              &lt;li&gt;$p_{\theta}(z) = \mathcal{N}(x; \mu_{z}, diag(\sigma^2_{z}))$
                &lt;ul&gt;
                  &lt;li&gt;f = elementwise function, w = weight matrix, $\sigma_{x}^2$ and $\sigma_{z}^2$ are the respective variances for $x$ and $z$.&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;MAP estimate of z is $z^*$ which maximizes $p_{\theta}(z \mid x)$.&lt;/li&gt;
              &lt;li&gt;Formulate that as an optimization problem: \(z^* = argmax_{z} ( log(p_{\theta}(x \mid z)) + log p_{\theta}(z) )\)&lt;/li&gt;
              &lt;li&gt;Each term in the above is convex squared error term so the whole thing can be solved analytically with \(\nabla_{z}\ell(z, \theta) = W^T (\frac{x - W_z }{\sigma_x}) (\frac{x - \mu_z }{\sigma_z})\)
                &lt;ul&gt;
                  &lt;li&gt;We can also use the above gradient to solve for $W$ w/ $\nabla_{W}$&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;Under this construction of $\theta(W,z)$ we get learning rules that aim to be biologically plausible by optimizing against physical occurrances, like firing rate or membrane potential. Extending this, the latent variable model (LVM) can be the particular output of a specific cortical column.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Various forms of evidence for this model in different sensory areas of mice, but ultimately, predictive coding is an incomplete theory because most of these models are oversimplified circuit models.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Predictive Coding, Variational Autoencoders, and Biological Connections by Joseph Marino</summary></entry><entry><title type="html">Review 15: Predictive Coding, Variational Autoencoders, and Biological Connections Pt 1</title><link href="http://localhost:4000/reviews/review15/" rel="alternate" type="text/html" title="Review 15: Predictive Coding, Variational Autoencoders, and Biological Connections Pt 1" /><published>2022-02-18T04:16:13-08:00</published><updated>2022-02-18T04:16:13-08:00</updated><id>http://localhost:4000/reviews/review15</id><content type="html" xml:base="http://localhost:4000/reviews/review15/">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/2011.07464.pdf&quot;&gt;Predictive Coding, Variational Autoencoders,
and Biological Connections&lt;/a&gt; by &lt;a href=&quot;https://joelouismarino.github.io/&quot;&gt;Joseph Marino&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Marino, Joseph. “Predictive coding, variational autoencoders, and biological connections.” Neural Computation 34.1 (2021): 1-44.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Predictive encoding from the perspective of theoretical neuroscience and machine learning.&lt;/li&gt;
  &lt;li&gt;Informal defintion for predictive encoding: Neural circuits as probabilistic models of other neurons.
    &lt;ul&gt;
      &lt;li&gt;Inception of this idea in cirucits for sensory processing, like the retina and visual pathways.&lt;/li&gt;
      &lt;li&gt;Feedbackward connections that apply prediction error signal.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.nature.com/articles/nn0199_79&quot;&gt;Rao, Ballard 1999&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;For neuroscience, cybernetics, hemholtz machine, and predictive encoding are the inspiration for Friston 2005 and 2008 work on free energy and active inference.&lt;/li&gt;
  &lt;li&gt;For machine learning, this earlier work in variational inference and encoder-decoder models, culminates in the variational autoencoder.&lt;/li&gt;
  &lt;li&gt;Lots of overlap conceptually, but much of the research between the two fields is divided.&lt;/li&gt;
  &lt;li&gt;The next section is titled connecting predictive coding and VAEs. I take it that these two concepts form the bridge between the fields.
    &lt;ul&gt;
      &lt;li&gt;Just from the intro I like that this paper points two very similar concepts in two different fields and then describes the relationship between the two. I feel that there the’s potential for a lot of discovery in understanding the union and intersection between these two concepts.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Paper posits two possible correspondences between ML and neuro.
    &lt;ul&gt;
      &lt;li&gt;Dendrites of pyramidal neurons and neuronal networks.&lt;/li&gt;
      &lt;li&gt;Lateral inhibition and normalizing flows.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Background info
    &lt;ul&gt;
      &lt;li&gt;MLE
        &lt;ul&gt;
          &lt;li&gt;How can we find some distribution $p_{data}$ using r.v. samples $\bf{x} \sim \hat{p}_{data}(\bf{x})$?&lt;/li&gt;
          &lt;li&gt;Maximizing &lt;strong&gt;log likelihood&lt;/strong&gt; of samples under that distribution. 
  \(\theta^* \longleftarrow argmax_{\theta} \mathbb{E}_{x \sim p_{data}(\bf{x})} [log(p_{theta}(\bf{x}))]\)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Probabilistic models
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;autoregressive models&lt;/strong&gt;: $ p_{\theta(\bf{x})} = \prod_{j=1}^{m} p(\bf{x}_{j} \mid x_{&amp;lt; j} $&lt;/li&gt;
          &lt;li&gt;Can factor out $\bf{x}$ in above as a series of distributions, from $t=1 … T$&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;Latent variable models (LVMs)&lt;/strong&gt;  with $z$ have the joint distribtion: \(p_{\theta}(\bf{x}, \bf{z}) = p_{theta}(\bf{x} \mid z)p_{theta}(\bf{z})\)&lt;/li&gt;
          &lt;li&gt;$\bf{z}$ is being used here to describe $\bf{x}$, incurs computational cost.&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;flow based LVMs&lt;/strong&gt; \(p_{\theta}(\bf{x}) = p_{\theta}(x) \| det(\frac{\partial{\bf{x}}}{\partial{\bf{z}}}) \|^{-1}\)
            &lt;ul&gt;
              &lt;li&gt;Distilling this down to the idea that there if some function $f_{\theta}$ that can transfrom $f_{\theta}(\bf{x}) = \bf{z}, \ f_{\theta}^{-1}(\bf{z}) = \bf{x}$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Can combine the above techniques for &lt;strong&gt;hierachical LVMs&lt;/strong&gt;, &lt;strong&gt;sequential LVMS&lt;/strong&gt; etc.
            &lt;ul&gt;
              &lt;li&gt;An interesting example is stacking latent variables $ \bf{z}^{1:L} = [ \bf{z}_{1} … \bf{z}_{L} ] $ and \(p_{\theta}(\bf{x},\bf{z}^{1:L}) = p_{\theta}(\bf{x}, \bf{z}^{1:L}) \prod_{\ell=1}^{L} p(\bf{z}^{\ell} \mid z^{\ell+1:L})\)&lt;/li&gt;
              &lt;li&gt;I am confused by the conditional probability $ p(\bf{Z^{\ell}} \mid z^{\ell+1:L})$ and the directionality of the hierarchy. Why wouldn’t it go backwards:  $ p(\bf{Z^{\ell}} \mid z^{1:\ell+1})$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Fitting these models
            &lt;ul&gt;
              &lt;li&gt;Log density of unit normal distribution becomes mean squared error.&lt;/li&gt;
              &lt;li&gt;A simple univariate autoregressive model can be formulated as $ p_{\theta}(x_j \mid x_{&amp;lt; j}) = \mathcal{N}(x_j; \mu_{\theta}(x_{&amp;lt; j}), \sigma^2_{\theta}(x_{&amp;lt; j})) $ .
                &lt;ul&gt;
                  &lt;li&gt;I think there’s a minor notation error here that the $x_{&amp;lt; j}$ should be boldface since it is still a vector.&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;Training using the gradient of log likelikehood: $\nabla_{\theta}\mathbb{E}_{\bf{x} \sim p_{data}}[log p_{\theta}(\bf{x})]$&lt;/li&gt;
              &lt;li&gt;Deep autoregressive and variational models can be broken apart by their latent variable impact on the objective with some interesting results.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Variational Inference
        &lt;ul&gt;
          &lt;li&gt;TODO: Left off here section 2.3&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Predictive Coding, Variational Autoencoders, and Biological Connections by Joseph Marino</summary></entry></feed>