<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-05-22T22:33:37-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Alexander Ladd</title><subtitle>An amazing website.</subtitle><author><name>Alexander Ladd</name><email>zladd@berkeley.edu</email></author><entry><title type="html">Review 28: Four ethical priorities for neurotechnologies and AI</title><link href="http://localhost:4000/reviews/review28/" rel="alternate" type="text/html" title="Review 28: Four ethical priorities for neurotechnologies and AI" /><published>2022-05-14T05:16:13-07:00</published><updated>2022-05-14T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review28</id><content type="html" xml:base="http://localhost:4000/reviews/review28/">&lt;p&gt;&lt;a href=&quot;https://www.nature.com/articles/551159a&quot;&gt;Four ethical priorities for neurotechnologies and AI
&lt;/a&gt; by &lt;a href=&quot;https://scholar.google.com/citations?user=G0WcJagAAAAJ&quot;&gt;Rafael Yuste&lt;/a&gt; and &lt;a href=&quot;https://phil.washington.edu/people/sara-goering&quot;&gt;Sara Goering&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Yuste, Rafael, et al. “Four ethical priorities for neurotechnologies and AI.” Nature 551.7679 (2017): 159-163.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;While full integration of neurotechnology into human life may take decades, it is critical to think about the ethical applications now.&lt;/li&gt;
  &lt;li&gt;The morningside group is comprised of neurotech companies, academic labs, and intl. brain projects.&lt;/li&gt;
  &lt;li&gt;The existing ethics guidlines, such as Declariation of Helsinki in 1964, Belmont report, and Asilomar AI report, don’t cover many of the issues that are raised by BCI technology.&lt;/li&gt;
  &lt;li&gt;This is a very cool tidbit:
    &lt;blockquote&gt;
      &lt;p&gt;(Yuste &amp;amp; Goering 2017)&lt;/p&gt;
      &lt;blockquote&gt;
        &lt;p&gt;Meanwhile, researchers at Duke University in Durham, North Carolina, have shown that three monkeys with electrode implants can operate as a ‘brain net’ to move an avatar arm collaboratively.&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;&lt;a href=&quot;https://www.nature.com/articles/srep10767&quot;&gt;Link&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;This BrainNet paper is one I am really interested in reading.&lt;/li&gt;
  &lt;li&gt;DARPA Neural Engineering Project that aims to implant 1 million electrodes and selectively stimulates up to 100k neurons. The University of Freiburg in Germany is using EEG signals to decode motor planning activity to control robots.&lt;/li&gt;
  &lt;li&gt;The four ethical priorities:
    &lt;ul&gt;
      &lt;li&gt;Privacy and consent: This concern has been pervasive throughout all types of recent technological advancements. There are many researchers working on what makes a system secure, but keeping data secure has proven to be a comparably large challenge as well. Often times data breaches that would occur in neurotech may use external data to draw connections that might allow them to identify individuals based on neural activity. Furthermore, many potential exploitative practices can extend from the centralization of neural data. The authors pose multiple mitigation strategies, but I really strongly agree with the strategy of not allowing the centralized storage of human neural data from BMI devices. While this may limit how devices can be developed, for now, it seems like a central safeguard from potentially disastrous data breaches.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Agency / Identity: This concern caught me off guard because I hadn’t considered it much at all until I read this. Simply put, BMI devices can blue the line of how much agency they can attribute to certain actions. In this way, BMI devices can interfere with someone’s sense of identity in a negative way. I also found the potential mitigation strategies here less satisfying, although I don’t have any better ideas. I am in support for drafting a constitution of “neurorights” but I don’t see how this would help those with issues in BMI affected identity. Better yet would be a fast safeguard in each device to immediately shut off its functioning if needed. The reason I advocate for this is that the user should have complete autonomy over when they use the device and when it is inactive. This does open the device up to hacking. Also this kind of on/off switch might not be possible due to negative consequences from terminating the tight feedback loop between device and person. Regardless, I generally advocate that BMI functionality should be treated more like glasses and less like a pacemaker so that users will never feel completely trapped with the BMI.&lt;/li&gt;
  &lt;li&gt;Augmentation: This is a very futuristic concern, but also one that should be considered now. At this point, the weaponization and militaristic augmentation of BMI devices are not major concerns. Though in the future they may be. To steer BMI devices on the right path, the authors argue for the establishment of a neurotechnology geneva convention style agreement about what research and applications can be ethically conducted using BMI devices.&lt;/li&gt;
  &lt;li&gt;Bias: Just like ML systems nowadays are biased by negative aspects of their data, such as hate speech in text datasets or lack of representation in image datasets, BMI devices can further perpetuate societal inequalities. To prevent this, it is necessary to open source data, algorithms, user research groups, and design. Through the proper channels, civil liberties and nonprofit auditors should be able to inspect the scientific practices of companies or groups doing neural engineering. Representation of diverse needs and circumstances should be considered in thorough research feature testing, quality testing, and design. Recently, there have been many failures in preventing biased models and disinformation on major technology platforms, so the future for this will be challenging.&lt;/li&gt;
  &lt;li&gt;Moving forward:
    &lt;ul&gt;
      &lt;li&gt;This kind of review provides great directions for moving forward; including widespread adoption of a Hippocratic oath for neuro engineers and ethical discussion sections for labs. While training certainly helps move employees and individuals in the right direction, in my opinion, the field would benefit from the following: (1) Some kind of agency responsible for oversight of responsible use of BMI devices. (2) Forums / conferences / journals for neuroethics. (3) Some kind of open sourced / democratized code for precedents.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Four ethical priorities for neurotechnologies and AI by Rafael Yuste and Sara Goering</summary></entry><entry><title type="html">Review 27: Parsing learning in networks using brain–machine interfaces</title><link href="http://localhost:4000/reviews/review27/" rel="alternate" type="text/html" title="Review 27: Parsing learning in networks using brain–machine interfaces" /><published>2022-05-14T05:16:13-07:00</published><updated>2022-05-14T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review27</id><content type="html" xml:base="http://localhost:4000/reviews/review27/">&lt;p&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0959438817301642?casa_token=mBc7NGX5SMoAAAAA:_u-U4AxlrusxSveU-DitDvaDjvUhYixFrO7ZuZs4B0iIa6Dy0xmDc6Za4MZYRqBFf8E7IiwcVOQ&quot;&gt;Parsing learning in networks using brain-machine
interfaces&lt;/a&gt; by &lt;a href=&quot;https://people.ece.uw.edu/orsborn_amy/&quot;&gt;Amy Orsborn&lt;/a&gt; and &lt;a href=&quot;https://as.nyu.edu/content/nyu-as/as/faculty/bijan-pesaran.html&quot;&gt;Bijan Pesaran&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Orsborn, Amy L., and Bijan Pesaran. “Parsing learning in networks using brain-machine interfaces.” Current opinion in neurobiology 46 (2017): 76-83.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Introduction
    &lt;ul&gt;
      &lt;li&gt;Motor BMIs: repurpose neural activity to control the movement of a device.
        &lt;ul&gt;
          &lt;li&gt;Give the brain a new functionality that the brain can adapt to use.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;BMIs also allow us to study the mechanisms of learning for neuroscience.&lt;/li&gt;
      &lt;li&gt;Yet, while there is work showing how BMIs can enable learning, the above point about the underlying neural mechanisms is still mostly unknown.&lt;/li&gt;
      &lt;li&gt;These BCI papers all have really great figure 1s.
  &lt;img src=&quot;/assets/images/r27_fig1.png&quot; alt=&quot;bci schematic&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;
        &lt;ul&gt;
          &lt;li&gt;This figure presents three different perspectives on closed-loop Motor BCI systems.
            &lt;ul&gt;
              &lt;li&gt;A: This is the main BCI closed-loop and very similar to the previous review.&lt;/li&gt;
              &lt;li&gt;B: Is interesting because it shows the affector/effector dynamics. It is also interesting because it shows that some nodes from the network should send a signal to the actuator while some nodes indirectly signal by not signaling. Finally, it shows that some external reward drives closed-loop BCI learning – which is important because this shows the progression of closed-loop BCI device is dependent on the perceived reward system in the brain.
                &lt;ul&gt;
                  &lt;li&gt;External reward normally just processed through vision. If you control a cursor on a screen successfully you will see that.&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;C: Shows what points can use learning feedback and what learning/error signal they require to improve. BCI closed-loop system can be improved in strategy/selection of motor plans and in the “internal” model… which I take to mean the decoder.
                &lt;ul&gt;
                  &lt;li&gt;As I start to become more specific in my focus on BCI, this kind of distinction can help inform future reading/research directions.&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Interesting point I did not know:
        &lt;blockquote&gt;
          &lt;p&gt;Orsborn et al. 2017&lt;/p&gt;
          &lt;blockquote&gt;
            &lt;p&gt;“visual information is highly dominant over proprioceptive information” &lt;a href=&quot;https://www.science.org/doi/10.1126/science.143.3606.594&quot;&gt;44&lt;/a&gt;&lt;/p&gt;
          &lt;/blockquote&gt;
        &lt;/blockquote&gt;

        &lt;ul&gt;
          &lt;li&gt;I guess this is probably really context-dependent though.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Combining command nodes for BMI in a different way allows researchers to investigate the relationship between BMI learning and natural learning.&lt;/li&gt;
      &lt;li&gt;Figure 2
        &lt;ul&gt;
          &lt;li&gt;Feedback rate and control rate increases both increase success rate for in &lt;a href=&quot;https://www.nature.com/articles/ncomms13825&quot;&gt;Shanechi et al.&lt;/a&gt;.&lt;/li&gt;
          &lt;li&gt;BMIs can investigate sites of learning around probes. For example, optogenetic stimulation near electrode recording sites can help study neural mechanisms of feedback learning.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The conclusion is very concise so I’ll add this final part here.
        &lt;blockquote&gt;
          &lt;p&gt;Orsborn et al. 2017&lt;/p&gt;
          &lt;blockquote&gt;
            &lt;p&gt;Since BMIs tap into our brain’s innate ability to learn, understanding learning in BMIs will ultimately advance clinical applications of this technology. In the search for effective treatments, we may find that interfaces that harness learning can improve the patient experience compared with those which simply accommodate learning.&lt;/p&gt;
          &lt;/blockquote&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Parsing learning in networks using brain-machine interfaces by Amy Orsborn and Bijan Pesaran</summary></entry><entry><title type="html">Review 26: A control-theoretic approach to brain-computer interface design</title><link href="http://localhost:4000/reviews/review26/" rel="alternate" type="text/html" title="Review 26: A control-theoretic approach to brain-computer interface design" /><published>2022-05-07T05:16:13-07:00</published><updated>2022-05-07T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review26</id><content type="html" xml:base="http://localhost:4000/reviews/review26/">&lt;p&gt;&lt;a href=&quot;https://smithlab.net/~schase/docs/zhang_acc_2016.pdf&quot;&gt;A control-theoretic approach to brain-computer interface design&lt;/a&gt; by Yin Zhang and &lt;a href=&quot;https://www.cmu.edu/bme/People/Faculty/profile/schase.html&quot;&gt;Steven Chase&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Zhang, Yin, and Steven M. Chase. “A control-theoretic approach to brain-computer interface design.” 2016 American Control Conference (ACC). IEEE, 2016.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A challenge in brain computer interface (BCI) design is mapping from population activity to BCI actuation.&lt;/li&gt;
  &lt;li&gt;This paper proposes using optimal control theory to formulate and improve BCI usability.&lt;/li&gt;
  &lt;li&gt;Main algorithmic proposals for mapping population activity to behavior:
    &lt;ol&gt;
      &lt;li&gt;linear estimators&lt;/li&gt;
      &lt;li&gt;Kalman filters&lt;/li&gt;
      &lt;li&gt;Particle filters&lt;/li&gt;
      &lt;li&gt;Neural net decoders&lt;/li&gt;
      &lt;li&gt;point process filters&lt;/li&gt;
      &lt;li&gt;kernel based techniques.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;That is a lot of potential approaches. The nuances of the application would be required in order to sort them out.&lt;/li&gt;
  &lt;li&gt;MLE approach to BCI
    &lt;ul&gt;
      &lt;li&gt;Velocity kalman filter defined as: $\mathbf{y_t} = B\mathbf{v_t}^* + \mathbf{\epsilon_t
  }$ where $\mathbf{y_t}$ are $n$ neuron’s firing rates and $\mathbf{v_t}$ is the velocity of a prosethetic effector.
        &lt;ul&gt;
          &lt;li&gt;This is clear mathematically but I don’t know what a prosthetic effector is.&lt;/li&gt;
          &lt;li&gt;It seems like some implant that would drive neuron firing rates.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;A second assumption is that this velocity changes smoothly over time.&lt;/li&gt;
      &lt;li&gt;Using these two assumptions: BCI control reduces to Bayesian inference over how this velocity results in firing rates.
        &lt;ul&gt;
          &lt;li&gt;I thought there would be more here since after this level of inference you’d still have to infer the previous problem of spike activity mapping to actions.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Using the above equations and the a posteriori estimate of $p(\mathbf{v_t} \mid y_1 … y_t)$, one can create a time dependent state update rule for a BCI controlled cursor position $\mathbf{p_t}$ using $\mathbf{v_t}$.
        &lt;ul&gt;
          &lt;li&gt;notation here is confusing because I thought y was in $\mathbb{R}^n$ as a firing frequency for n neurons. I take it the authors mean to use the 1 - t as $y$ at some previous recording time t.&lt;/li&gt;
          &lt;li&gt;This also answered my previous point about mpaping from $\mathbf{v_t}$ to actual actions.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;While estimation based decoder control has remarkable progress in enabling cursor speed w/ in a factor of 2 of a natural limb, there are still some aspects that can be improved:
        &lt;ol&gt;
          &lt;li&gt;Only decoders that correspond to simple physical systems work well.&lt;/li&gt;
          &lt;li&gt;Estimation framework assumes static tuning but performance in closed-loop systems over time is often very different and offline decoders may not work well in long term.&lt;/li&gt;
          &lt;li&gt;Biomemtic decoders are not guaranteed optimal. Translating signals in terms of basic human motor movements are not necessairly the best way to solve control problems.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;Authors make 3 assumptions about the brain as optimal controller:
        &lt;ol&gt;
          &lt;li&gt;The brain is emitting control signals that minimize some cost function.&lt;/li&gt;
          &lt;li&gt;Primary cortex activity is a direct representation of these signals.&lt;/li&gt;
          &lt;li&gt;End goal result of learning is to produce the optimal control signals of a given effector.
            &lt;ul&gt;
              &lt;li&gt;These assumptions have helped me understand a lot of what the paper is previously trying to build to.&lt;/li&gt;
              &lt;li&gt;Mainly, what I see now that I did not before is why the signal estimation approach is limiting and why understanding motor cotrex signals as effector signals is so important. I believe this is because control theory allows a framework for much more specific definitions of control when the goal is reconstructing effector signals instead of predicting movement. Predicting movement is often a more vague problem for a decoder while fine-grained analysis of how brain signals enable optimal control in reaching for example is much more specific.
&lt;img src=&quot;/assets/images/bci_schematic.png&quot; alt=&quot;bci schematic&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;I really like this figure since it is a straightforward diagram of the control model here.&lt;/li&gt;
      &lt;li&gt;It shows where that control signals feed into the plant for state updates in decoder.&lt;/li&gt;
      &lt;li&gt;$x$ as cursor state, $u$ as control signal, and $J(u)$ as cost function for signal $u$.&lt;/li&gt;
      &lt;li&gt;Optimal cost is $J^*  = J^(u^*)$, plant parameters are $\phi$&lt;/li&gt;
      &lt;li&gt;$\phi$ determines the usefulness of BCI based on how it minimizes cost function.&lt;/li&gt;
      &lt;li&gt;Not so sure what $H_p$ and $H_v$ mean as spring like properties of the plant and viscous properties. Are these from control theory?&lt;/li&gt;
      &lt;li&gt;BCI plant system dyanmics
&lt;img src=&quot;/assets/images/r26_e1.png&quot; alt=&quot;bci schematic&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Quadratic cost function used  in motor learning studies
&lt;img src=&quot;/assets/images/r26_e2.png&quot; alt=&quot;bci schematic&quot; width=&quot;500&quot; align=&quot;center&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Normally I like to use latex to write out he equations in the paper but I don’t wan’t to the \bmatrix formatting today.&lt;/li&gt;
      &lt;li&gt;First solve forward control problem of optimizing $H_p$ and $H_t$.&lt;/li&gt;
      &lt;li&gt;Linear quadratic regulator gives minmial cost under optimal policy: $J*(H_p,H_t) = tr(P_0,X_0)$.
        &lt;ul&gt;
          &lt;li&gt;are $H_p$ and $H_t$ suppoed to be $H_p^&lt;em&gt;$ and $H_t^&lt;/em&gt;$, the optimal conditions in order to get J*?
            &lt;blockquote&gt;
              &lt;p&gt;Zhang 2016 on simulation results for this paper:&lt;/p&gt;
              &lt;blockquote&gt;
                &lt;p&gt;In one sense, these results might seem trivial: the optimal 2D linear BCI plant is an integrator that provides no resistance on the inputs. This is an intuitive solution given
that we assumed no bias in the control signals and further assumed a minimal effort constraint. In another sense, the results are quite surprising: the optimal dynamics identified through this approach to BCI design are qualitatively different from those of the typical BCI decoder, the VKF. In fact, the parameters identified with our method fall outside of the allowable parameters of a VKF.&lt;/p&gt;
              &lt;/blockquote&gt;
            &lt;/blockquote&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">A control-theoretic approach to brain-computer interface design by Yin Zhang and Steven Chase</summary></entry><entry><title type="html">Review 25: Plug-and-play control of a brain-computer interface through neural map stabilization</title><link href="http://localhost:4000/reviews/review25/" rel="alternate" type="text/html" title="Review 25: Plug-and-play control of a brain-computer interface through neural map stabilization" /><published>2022-04-30T05:16:13-07:00</published><updated>2022-04-30T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review25</id><content type="html" xml:base="http://localhost:4000/reviews/review25/">&lt;p&gt;&lt;a href=&quot;https://www.nature.com/articles/s41587-020-0662-5&quot;&gt;Plug-and-play control of a brain-computer interface through neural map stabilization
&lt;/a&gt; by &lt;a href=&quot;https://gangulylab.org/people.html&quot;&gt;Daniel Silversmith&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Silversmith, Daniel B., et al. “Plug-and-play control of a brain-computer interface through neural map stabilization.” Nature Biotechnology 39.3 (2021): 326-335.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Having recently read higher-level overviews of BCIs, reading this paper in Nature Biotech will be especially relevant but more specific.&lt;/li&gt;
  &lt;li&gt;Abstract
    &lt;ul&gt;
      &lt;li&gt;180 channel electrocorticography (ECoG) implant in a paralyzed individual enabled stable monitoring of signals.&lt;/li&gt;
      &lt;li&gt;Long-term closed loop adaptation updates decoder weights over several days, thus updating map and plug and play control.
Intro&lt;/li&gt;
      &lt;li&gt;Currently, 30 min daily recalibration results in variability in performance and decreased decoding performance in the long-term.&lt;/li&gt;
      &lt;li&gt;ECoG PNP control was achieved using an interface that updates within-session instead via closed-loop decoder adaptation (CLDA) and potentially over longer terms (ltCDA).
Results&lt;/li&gt;
      &lt;li&gt;Fig. 1
        &lt;ul&gt;
          &lt;li&gt;ECoG signal comes from a few brain regions: S1, M1 , PMC, PMV, SMA.&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;Kalman Filter&lt;/strong&gt; decoder weights.&lt;/li&gt;
          &lt;li&gt;There are a few aspects that are different between ltCLDA and daily initialization:
            &lt;ul&gt;
              &lt;li&gt;Time to taget increased, though it is hard to tell by how much as I can’t see mean values in the intervals.&lt;/li&gt;
              &lt;li&gt;ITR shows clear increase during ltCDA.&lt;/li&gt;
              &lt;li&gt;Convergence of decoder weights is faster using ltCDA.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Time to target decreases from 18 to 6 seconds with tight error bounds.&lt;/li&gt;
          &lt;li&gt;I do not understand box diagram in fig H. Are the outwward pointing arrows for CNS and KF pipeline outputs?&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Weights are general orthogonal at the start of each dailty initializaiton, so pooling weights over days hurt model performance.&lt;/li&gt;
      &lt;li&gt;ltCDA resulted in stable convergence of decoder weights across sessions instead.&lt;/li&gt;
      &lt;li&gt;Higher half-life values (history length used in weight updates) led to better fixed control and more stable weight convergence.&lt;/li&gt;
      &lt;li&gt;Some weights exhibiting low magnitude or common trends may be redundant and enables sparseness.&lt;/li&gt;
      &lt;li&gt;Fig. 2
        &lt;ul&gt;
          &lt;li&gt;A lot more variance in decoder map weights for daily initialization method.&lt;/li&gt;
          &lt;li&gt;As the days go on, the orthogonality of the weights seems to decrease.&lt;/li&gt;
          &lt;li&gt;mu weights decrease w/ linear trends and gamma2 weights increase w/ linear trend.&lt;/li&gt;
          &lt;li&gt;Sparsity/weight pruning is pretty shocking with the 25% of the weights verison having a very similar time to target.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Fig. 3
        &lt;ul&gt;
          &lt;li&gt;Daily calibration had higher circular sd across channels in preferred direction (PD) task.&lt;/li&gt;
          &lt;li&gt;Decoder weight magnitude correlated to circular SD of PD.&lt;/li&gt;
          &lt;li&gt;gamma2 weights are stable from day 36+ and it is visually confirmed.&lt;/li&gt;
          &lt;li&gt;All weights show some trend toward stable convergence after day 18+, which is really interesting because it suggests long-term improvement with ltCLDA method.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Fig. 4
        &lt;ul&gt;
          &lt;li&gt;ltCDA to Fixed Decoder swap at day 206 + 28 recovery.&lt;/li&gt;
          &lt;li&gt;both ltCDA and CLDA after reset seem to have stable weights.&lt;/li&gt;
          &lt;li&gt;Decoder weights angle is roughly 45 degrees after reset.
  Fig. 5&lt;/li&gt;
          &lt;li&gt;Point and click task where cursor path and bits per second information rate are tracked.&lt;/li&gt;
          &lt;li&gt;Weights seem much sparser for click map.&lt;/li&gt;
          &lt;li&gt;I wonder how they will look for less convergent features.&lt;/li&gt;
          &lt;li&gt;Neural state needs to cross click threshold.&lt;/li&gt;
          &lt;li&gt;Everyday, after the cursor is in target area, stable clicking within 1 sec.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;No significant drop in performance during PnP sessions (plug and play = no recalibration).&lt;/li&gt;
      &lt;li&gt;Decoder reinitialization had 45-degree weight angle change but then converge back to 0.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Discussion
    &lt;ul&gt;
      &lt;li&gt;ltCDA is an important example of weights being carried over a long time constant.&lt;/li&gt;
      &lt;li&gt;CLDA based on coadaptation can rapidly allow skilled control.&lt;/li&gt;
      &lt;li&gt;Task-related manifolds can be remarkably stable.&lt;/li&gt;
      &lt;li&gt;Results indicate the feasibility of PnP.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Plug-and-play control of a brain-computer interface through neural map stabilization by Daniel Silversmith.</summary></entry><entry><title type="html">Review 24:The brain-reading devices helping paralysed people to move, talk and touch</title><link href="http://localhost:4000/reviews/review24/" rel="alternate" type="text/html" title="Review 24:The brain-reading devices helping paralysed people to move, talk and touch" /><published>2022-04-23T05:16:13-07:00</published><updated>2022-04-23T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review24</id><content type="html" xml:base="http://localhost:4000/reviews/review24/">&lt;p&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-022-01047-w?utm_medium=Social&amp;amp;utm_campaign=nature&amp;amp;utm_source=Twitter#Echobox=1650446178&quot;&gt;The brain-reading devices helping paralysed people to move, talk and touch
&lt;/a&gt; by &lt;a href=&quot;http://www.liamdrew.net/about&quot;&gt;Liam Drew&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Brain-computer interface clinical trials for paralysis where the patient uses thoughts to operate a computer application moving a robotic arm.&lt;/li&gt;
  &lt;li&gt;James Johnson, a volunteer for the new neurotech, reports that he can move a mouse on a screen using BCI.&lt;/li&gt;
  &lt;li&gt;Johnson is 1 of 35 individuals who have had a BCI implanted.
    &lt;ul&gt;
      &lt;li&gt;This number seems surprisingly low. I wouldn’t expect more than 1000 though.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Black Rock Neurotech in Salt Lake City, Utah produces a lot of these devices.&lt;/li&gt;
  &lt;li&gt;2006 Landmark paper where Dr. Leigh Hochberg et al. teach a man to move a cursor using robotic arms and was the first of a multicenter set of trials called BrainGate which continues today.&lt;/li&gt;
  &lt;li&gt;Requires decoding algorithms to match neural data to actions.&lt;/li&gt;
  &lt;li&gt;A major goal is to restore motor independence in people who have lost ability in moving their limbs.&lt;/li&gt;
  &lt;li&gt;Bypass central nervous system by directly stimulating muscles responsible for movement.&lt;/li&gt;
  &lt;li&gt;Decoding algorithm improves and patient capacity to interface with the machine improves as well.&lt;/li&gt;
  &lt;li&gt;Richard Anderson leading clinical trials at caltech.&lt;/li&gt;
  &lt;li&gt;A focus of this research is stabilizing the movements.&lt;/li&gt;
  &lt;li&gt;Dr. Edward Chang works on restoring the ability to communicate at UCSF using BCI.&lt;/li&gt;
  &lt;li&gt;40 characters a minute by Shenoy et al. in cursor benchmark.&lt;/li&gt;
  &lt;li&gt;Turning thoughts into type which uses pattern analysis.&lt;/li&gt;
  &lt;li&gt;Chang lab uses sensors planted on the surface of the brain which have a lower resolution but a non-invasive.&lt;/li&gt;
  &lt;li&gt;All BCI companies are aiming to increase bandwidth of communication signals.&lt;/li&gt;
  &lt;li&gt;There is still a long way to go with the technology.&lt;/li&gt;
  &lt;li&gt;Major limitations right now are how long the device will last, how well it will adapt to each user, and if the device will still be supported or used later on down the road.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">The brain-reading devices helping paralysed people to move, talk and touch by Liam Drew.</summary></entry><entry><title type="html">Review 23: Neuropixels 2.0: A miniaturized high-density probe for stable, long-term brain recordings</title><link href="http://localhost:4000/reviews/review23/" rel="alternate" type="text/html" title="Review 23: Neuropixels 2.0: A miniaturized high-density probe for stable, long-term brain recordings" /><published>2022-04-16T05:16:13-07:00</published><updated>2022-04-16T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review23</id><content type="html" xml:base="http://localhost:4000/reviews/review23/">&lt;p&gt;&lt;a href=&quot;https://www.biorxiv.org/content/10.1101/2020.10.27.358291v1.full.pdf&quot;&gt;Neuropixels 2.0: A miniaturized high-density probe for stable, long-term
brain recordings&lt;/a&gt; by &lt;a href=&quot;http://www.nicksteinmetz.com/#:~:text=Nick%20Steinmetz,and%20cognition%20across%20the%20brain.&quot;&gt;Nick Steinmetz&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper notes for Neuropixels 2.0
    &lt;ul&gt;
      &lt;li&gt;Notably, this is a pretty big collaboration. The following labs participated:
        &lt;ul&gt;
          &lt;li&gt;O’Keefe Lab at UCL&lt;/li&gt;
          &lt;li&gt;Moser Lab at NTNU&lt;/li&gt;
          &lt;li&gt;Lee Lab at Janelia Research&lt;/li&gt;
          &lt;li&gt;Dudman lab at Janelia Research&lt;/li&gt;
          &lt;li&gt;Hausser Lab at UCL&lt;/li&gt;
          &lt;li&gt;Steinmetz Lab at UW&lt;/li&gt;
          &lt;li&gt;Svoboda Lab at Janelia&lt;/li&gt;
          &lt;li&gt;Carandini/ Harris Lab&lt;/li&gt;
          &lt;li&gt;Hantman Lab&lt;/li&gt;
          &lt;li&gt;Haesler Lab&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Neuropixels new probe :
        &lt;ul&gt;
          &lt;li&gt;has over 5000 sites, features&lt;/li&gt;
          &lt;li&gt;has 2 probes and a head stage&lt;/li&gt;
          &lt;li&gt;records at 786 sites at once&lt;/li&gt;
          &lt;li&gt;weighs over 1 gram&lt;/li&gt;
          &lt;li&gt;enables recording from over &amp;gt; 10000 recording sites during free behavior in mice&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Stably recording neurons over days / weeks during long terms processes like learning and memory is challenging, but important for understanding neural coding.&lt;/li&gt;
      &lt;li&gt;Many attempts to record from devices that are flexible and less than $\mu$m in size.
        &lt;ul&gt;
          &lt;li&gt;Paper states that downside to these approaches are: make insertion difficult and do not scale at large numbers of recording sites per shank.&lt;/li&gt;
          &lt;li&gt;I don’t understand how small flexible devices could make insertion more difficult.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;More rigid and larger devices (Utah array, wire tetrodes, silicon probes) record high-quality signals for 8 weeks. However, no consistent recordings of individual neurons over the scale of months.&lt;/li&gt;
      &lt;li&gt;Neuropixels: dense coverage along a line, another array: across a plane.&lt;/li&gt;
      &lt;li&gt;algorithm stabilizes device to brain motion post hoc.&lt;/li&gt;
      &lt;li&gt;two recording channels be simultaneously recorded in the same channel with noise penalty in snr.
        &lt;ul&gt;
          &lt;li&gt;At this point, I realized that there is a lot of past literature about these recording probes that I am missing. This feels like watching avengers before watching all the prequel movies.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Results
        &lt;ul&gt;
          &lt;li&gt;4 shanks, 1280 sites per shank, 5120 total sites.&lt;/li&gt;
          &lt;li&gt;single wide band 14-bit data stream.&lt;/li&gt;
          &lt;li&gt;Hardware switches can swap recording streams enabling recording from thousands of streams/experiment.&lt;/li&gt;
          &lt;li&gt;can cover a plan of 750 x 720 $\mu$m during recording.&lt;/li&gt;
          &lt;li&gt;Fig. 1
            &lt;ul&gt;
              &lt;li&gt;Neuropixels 2.0 is much less wide than the previous version.&lt;/li&gt;
              &lt;li&gt;Shows LFP recording and spike waveform recording (overlapping channels).&lt;/li&gt;
              &lt;li&gt;Probe rasters and reproduced raster of dorsal striatum firing pattern across ten trials.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;7 / 8  probes recovered in working condition.&lt;/li&gt;
          &lt;li&gt;max time recording from implant: 309 days.&lt;/li&gt;
          &lt;li&gt;Fig 2.
            &lt;ul&gt;
              &lt;li&gt;the proportion of spikes has a decaying distribution over the # of days after implant. A similar trend is shown in C. and D.&lt;/li&gt;
              &lt;li&gt;hippocampus has a high proportion of firing neurons.&lt;/li&gt;
              &lt;li&gt;comparison of spike recording stats between labs that used the device.
                &lt;ul&gt;
                  &lt;li&gt;I think this plot is hard to interpret because I know there are different conditions for each lab so plot does not necessarily show apples to apples.&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Paper claims brain motion leads to progressively less spikes during the duration of a recording.&lt;/li&gt;
          &lt;li&gt;But they have an unsupervised learning algorithm to adjust for motion post hoc and re-detect spikes. This method increases recording stability (3E).&lt;/li&gt;
          &lt;li&gt;Fig 3.
            &lt;ul&gt;
              &lt;li&gt;The results from this stabilization procedure a visually very convincing.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Now they expand the timescale alignment to long intervals.
            &lt;ul&gt;
              &lt;li&gt;successful tracking across days, and weeks (figure 4). 83% tracking accuracy after 9 weeks.&lt;/li&gt;
              &lt;li&gt;wonder what that accuracy is across more than three months? But tracking 83% of neurons seems really good.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Average signals from two sites along a recording line and then decompose them.&lt;/li&gt;
          &lt;li&gt;Fig 4
            &lt;ul&gt;
              &lt;li&gt;bank 1 and bank 2 separated to two sets of neurons and the switch helps record mapping between banks using mismatch.&lt;/li&gt;
              &lt;li&gt;when both banks are recording noise is lower.&lt;/li&gt;
              &lt;li&gt;3 configurations: both banks on, bank 1 on, bank 2 on.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Neuropixels 2.0: A miniaturized high-density probe for stable, long-term brain recordings by Nick Steinmetz.</summary></entry><entry><title type="html">Review 21: Cracking the Neural Code in Humans</title><link href="http://localhost:4000/reviews/review21/" rel="alternate" type="text/html" title="Review 21: Cracking the Neural Code in Humans" /><published>2022-04-02T05:16:13-07:00</published><updated>2022-04-02T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review21</id><content type="html" xml:base="http://localhost:4000/reviews/review21/">&lt;p&gt;&lt;a href=&quot;https://www.simonsfoundation.org/2022/03/29/cracking-the-neural-code-in-humans/&quot;&gt;Cracking the Neural Code in Humans
&lt;/a&gt; by &lt;a href=&quot;https://www.simonsfoundation.org/people/emily-singer/&quot;&gt;Emily Singer&lt;/a&gt; at the Simons Foundation.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Neuropixels: high resolution brain recording from implanted electrodes.&lt;/li&gt;
  &lt;li&gt;Until recently Neuropixel devices are only used on primates and rodents, but now they can be used in people thanks to Dr. Paulk and Dr. Cash at &lt;a href=&quot;https://cashlab.mgh.harvard.edu/people/&quot;&gt;Cashlab&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Neural recordings for brain computer interfaces are researched in clinical trials due to the risks associated with implantable electrodes.&lt;/li&gt;
  &lt;li&gt;However further development of the decoding that can be performed at various resolutions helps inform new and more effective BCI.&lt;/li&gt;
  &lt;li&gt;Short, fast, and simple tasks may help understand neural coding at a more basic level.&lt;/li&gt;
  &lt;li&gt;Primary application is that the user would control a robotic arm or robotic device that responds to decoded brain activity.&lt;/li&gt;
  &lt;li&gt;Utah microelectrode array as the leading measurement device for 7 years.&lt;/li&gt;
  &lt;li&gt;RNN Decoder translates Neural activity from 200 neurons into characters at rate of 90 characters per minute.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Shenoy 2022&lt;/p&gt;
  &lt;blockquote&gt;
    &lt;p&gt;Your brain is actually issuing more information per second when you handwrite than when you make a straight line. That increased complexity made it easier to quickly decode the intended letter — and offers new opportunities for exploring neural coding,”&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Dr. Pandarinath researchers fast finger movements, unlike commonly researched reaching and grasping movements.&lt;/li&gt;
  &lt;li&gt;Dr. Stavisky and Dr. Shenoy are able to reliably deocde speech related neural activity from handknob area in people who can’t move their hands but can still speak.&lt;/li&gt;
  &lt;li&gt;Still the question of what machinery is used for what task is outstanding. It will be hard to map areas even between common tasks like walking and running.&lt;/li&gt;
  &lt;li&gt;Lower dimension manifolds for interpreting neural recodings.&lt;/li&gt;
  &lt;li&gt;Neuropixels code and data are public.&lt;/li&gt;
  &lt;li&gt;Dr. Paulk says diversity of waveforms produced is a new and surprising result.&lt;/li&gt;
  &lt;li&gt;There still exist significant engineering challenges around neuropixels, like how to stablize the device and transmit data.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Cracking the Neural Code in Humans by Emily Singer at the Simons Foundation.</summary></entry><entry><title type="html">Review 20: Trends in Computational Neuroscience: Cosyne 2022</title><link href="http://localhost:4000/reviews/review20/" rel="alternate" type="text/html" title="Review 20: Trends in Computational Neuroscience: Cosyne 2022" /><published>2022-03-25T05:16:13-07:00</published><updated>2022-03-25T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review20</id><content type="html" xml:base="http://localhost:4000/reviews/review20/">&lt;p&gt;&lt;a href=&quot;https://saberatalukder.com/cosyne_2022_computational_and_systems_neuroscience_in_review.html&quot;&gt;Trends in Computational Neuroscience: Cosyne 2022
&lt;/a&gt; by &lt;a href=&quot;https://saberatalukder.com/index.html&quot;&gt;Sabera Talukder&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I couldn’t go to Cosyne but it’s a workshop/conference I’d like to go to one day so I wanted to get the inside scoop of what gets discussed.&lt;/li&gt;
  &lt;li&gt;Fortunately, this blog kept me in the loop, so that’s pretty cool.&lt;/li&gt;
  &lt;li&gt;Notes:&lt;/li&gt;
  &lt;li&gt;Major Trends
    &lt;ul&gt;
      &lt;li&gt;Behavior
        &lt;ul&gt;
          &lt;li&gt;Especially w.r.t. software, data analysis pipelines and pose tracking estimation.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Comparing ANNs to Biologically realistic NN
        &lt;ul&gt;
          &lt;li&gt;I didn’t have FOMO hearing about behavior, but now I do.&lt;/li&gt;
          &lt;li&gt;One-to-one biological to neural network comparison.&lt;/li&gt;
          &lt;li&gt;Generative modeling neural data with latent representation.
            &lt;ul&gt;
              &lt;li&gt;This one has important impact on neuroengineering.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Biological rules with ML tasks.
            &lt;ul&gt;
              &lt;li&gt;This is one is interesting because I’d like to see how well biologically realistic credit assignment matches up against SOTA methods for MNIST.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;network similarity: how can you tell the distance between two nets?&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Dimensionality Reduction
        &lt;ul&gt;
          &lt;li&gt;This one trend shows that PCA, UMAP, and tSNE can be improved upon to get low dim. representations that do not warp local and/or global distance. Ah, the curse of dimensionality.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Data Scaling
        &lt;ul&gt;
          &lt;li&gt;How to curate / record / assay large experiments for high throughput data?&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;I liked the writing / blog style because it was interesting to read and broke the monotony from reading papers.&lt;/li&gt;
  &lt;li&gt;It was also a concise read so I could read the whole thing instead of skimming. Also packed with a bunch of info about applications of key themes.&lt;/li&gt;
  &lt;li&gt;To me, it’s really exciting to see a conference where ANNs are compared to biological NNs because I find the two topics: generative modeling and biological nets on ML tasks to be interesting because of their relation to eachother. Both tasks seem to be two sides of the neural network coin. For the generative modeling task we are applying nets to better understand the brain and in the ML task we are trying to borrow the brain to make better ML models.&lt;/li&gt;
  &lt;li&gt;Can’t wait to see how these topics unfold in future conferences since I think they’ll have important impact on brain computer interfaces and autonomous control in robotics.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Trends in Computational Neuroscience: Cosyne 2022 by Sabera Talukder</summary></entry><entry><title type="html">Review 19: Let us never speak of these values again.</title><link href="http://localhost:4000/reviews/review19/" rel="alternate" type="text/html" title="Review 19: Let us never speak of these values again." /><published>2022-03-20T05:16:13-07:00</published><updated>2022-03-20T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review19</id><content type="html" xml:base="http://localhost:4000/reviews/review19/">&lt;p&gt;&lt;a href=&quot;https://www.argmin.net/2022/02/23/standard-errors/&quot;&gt;Let us never speak of these values again.&lt;/a&gt; by &lt;a href=&quot;https://www.argmin.net/&quot;&gt;Ben Recht&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;This blog covers the utiliy of statistical signifigance measures like effect size and p value.&lt;/li&gt;
  &lt;li&gt;The range of success of claims is predicated off of a ratio of effect size to standard error.&lt;/li&gt;
  &lt;li&gt;Exposes that fact that signifigance is weighted by the spread of probability denisty. Meaning that if there is a slightly favorable outcome with a small PDF and one with a more favorable average outcome but larger PDF, the former may be favored by the p-value.&lt;/li&gt;
  &lt;li&gt;Simple approximations can distort this p-value. Esp. when it comes to averageing across groups.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;Most practicing scientists would be better off not knowing what a p-value is.&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;This leads to the philosophical problem here: how can we really trust the effect size is valid. This is made challenging by varying levels of validity:
    &lt;ul&gt;
      &lt;li&gt;study design is valid?&lt;/li&gt;
      &lt;li&gt;hypothesis testing is valid?&lt;/li&gt;
      &lt;li&gt;claims are valid?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;I think the third bullet is especially hard. How can you best gurantee performance on an unsen input/output?&lt;/li&gt;
&lt;/ul&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Let us never speak of these values again. by Ben Recht</summary></entry><entry><title type="html">Review 18: Deep Learning Is Hitting a Wall</title><link href="http://localhost:4000/reviews/review18/" rel="alternate" type="text/html" title="Review 18: Deep Learning Is Hitting a Wall" /><published>2022-03-13T05:16:13-07:00</published><updated>2022-03-13T05:16:13-07:00</updated><id>http://localhost:4000/reviews/review18</id><content type="html" xml:base="http://localhost:4000/reviews/review18/">&lt;p&gt;&lt;a href=&quot;https://nautil.us/deep-learning-is-hitting-a-wall-14467/&quot;&gt;Deep Learning is Hitting a Wall&lt;/a&gt; by &lt;a href=&quot;https://en.wikipedia.org/wiki/Gary_Marcus&quot;&gt;Gary Marcus&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Marcus, Gary. “Deep Learning is Hitting a Wall” natuil.us (2022).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I’ve been writing all day and I am struggling, but reading this is a breath of fresh air. It is well written and easy to read.&lt;/li&gt;
  &lt;li&gt;Marcus claims the AI/ML hype from 2005-2016 has overpromised.&lt;/li&gt;
  &lt;li&gt;We can see it is deployed all the time in low risk and mundane tasks, but we don’t see it often deployed in high risk situations.
    &lt;ul&gt;
      &lt;li&gt;Self-driving being the mos ubiqitiously deployed ML but it requires human oversight.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Large ML language models show  examples of failing to form any underlying conceptual understanding of what the words in the prompt/generation structure mean.&lt;/li&gt;
  &lt;li&gt;Many have touted ML scaling laws, stating that more data and larger models with continue to improve.
    &lt;ul&gt;
      &lt;li&gt;This improvement may be bounded.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Explicit symbol manipulation has been benished from the kingdom of AI.&lt;/li&gt;
  &lt;li&gt;I like that the author focuses on trustworthiness and relibility models instead of accuracy. At the end of the day, humans don’t care about RMSE, we care about the impact it has on  our lives.&lt;/li&gt;
  &lt;li&gt;Background on symbolic AI as codes to represent information. Like bits for example.
    &lt;ul&gt;
      &lt;li&gt;More background about symbol manipulation through explaining computer programs, variable assignment etc.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Google search as a great example of effective symbolic AI.&lt;/li&gt;
  &lt;li&gt;The autor discuss the background of deep learning rise to fame over symbolic AI involving several key points in the 80s-2010s where certain leading researchers eschewed statements and made claims about which approach has the most merits.&lt;/li&gt;
  &lt;li&gt;Some motivations for moving back to some ideas in symbol based AI:
    &lt;ul&gt;
      &lt;li&gt;Recipe argument: so many things we do are procedural, conditioned. Symbolic AI can better represent this knowledge.&lt;/li&gt;
      &lt;li&gt;Black box: this is the famous DL is a black box argument. I think of this argument as technical debt. You build something capable of doing great things but can’t explicitly explain why it works.&lt;/li&gt;
      &lt;li&gt;Silo arguement: most of the AI capabilities from image detection to NLP are siloed to their own domain. Integrating knowledge from mutiple domains can lead to more general forms of intelligence.&lt;/li&gt;
      &lt;li&gt;Neural networks can’t do addition.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;I think these arguments are well reseasoned and I don’t eschew symbolic AI by any means. However, the question in my mind, is how much symbolism from symbolic AI needs to be introduced.
    &lt;blockquote&gt;
      &lt;p&gt;qtd.  Marcus 2022&lt;/p&gt;
      &lt;blockquote&gt;
        &lt;p&gt;Artur Garcez and Luis Lamb wrote a manifesto for hybrid models in 2009, called Neural-Symbolic Cognitive Reasoning.&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;Added to my reading list&lt;/li&gt;
  &lt;li&gt;New developments in Symbolic AI
    &lt;ul&gt;
      &lt;li&gt;Alphafold&lt;/li&gt;
      &lt;li&gt;AlphaGO&lt;/li&gt;
      &lt;li&gt;Deepmind chess&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Cognition and intelligence is many things and trying to fit them all into feedfoward net w/ backprop is not rational.&lt;/li&gt;
  &lt;li&gt;End with quote:&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;qtd.  Marcus 2022&lt;/p&gt;
  &lt;blockquote&gt;
    &lt;p&gt;With all the challenges in ethics and computation, and the knowledge needed from fields like linguistics, psychology, anthropology, and neuroscience, and not just mathematics and computer science, it will take a village to raise to an AI. We should never forget that the human brain is perhaps the most complicated system in the known universe; if we are to build something roughly its equal, open-hearted collaboration will be key&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;</content><author><name>xander</name></author><category term="reviews" /><summary type="html">Deep Learning is Hitting a Wall by Gary Marcus</summary></entry></feed>